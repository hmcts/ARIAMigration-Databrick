{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f246cd4-e5b1-4045-a441-9e556f0b4ae6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "List Available Secret Scopes in Databricks"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.secrets.listScopes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "755b8454-371c-441f-a7e3-8a55968a6b37",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "List Secrets from Ingest00 Meta002 Sbox Scope"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.secrets.list(scope='ingest00-meta002-sbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4df633b6-4c93-45c5-8c5c-e73c1647b16d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Check and Mount Azure Blob Storage Container (RAW)"
    }
   },
   "outputs": [],
   "source": [
    "container_name = 'raw'\n",
    "storage_account_name = 'ingest00rawsbox'\n",
    "\n",
    "# List of required secrets\n",
    "required_secrets = [\n",
    "    \"RAW-SAS-TOKEN\"\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "for secret in required_secrets:\n",
    "    foldername = 'ARIADM'           # secret.split('-')[0]\n",
    "    mount_point = f\"/mnt/{container_name}\"\n",
    "    source_url = f\"wasbs://{container_name}@{storage_account_name}.blob.core.windows.net/\"\n",
    "\n",
    "    # Ensure mount_info is accessed correctly\n",
    "    mounts = dbutils.fs.mounts()\n",
    "    \n",
    "    if not any(mount_point in (mount_info.mountPoint if isinstance(mount_info, tuple) else mount_info['mountPoint']) for mount_info in mounts):\n",
    "        try:\n",
    "            dbutils.fs.mount(\n",
    "                source=source_url,\n",
    "                mount_point=mount_point,\n",
    "                extra_configs={f\"fs.azure.sas.{container_name}.{storage_account_name}.blob.core.windows.net\": dbutils.secrets.get(scope='ingest00-meta002-sbox', key=secret)}\n",
    "            )\n",
    "            print(f\"Container '{container_name}' mounted successfully at '{mount_point}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error mounting container at '{mount_point}': {e}\")\n",
    "    else:\n",
    "        print(f\"Mount point '{mount_point}' already exists.\")\n",
    "\n",
    "    # Access the specific folder\n",
    "    folder_path = f\"{mount_point}/{foldername}\"\n",
    "\n",
    "    # List files in the folder to verify\n",
    "    try:\n",
    "        files = dbutils.fs.ls(folder_path)\n",
    "        display(files)\n",
    "        print(f\"Folder '{foldername}' accessed successfully at '{folder_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing folder '{foldername}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a621e056-b746-4663-8038-95e9ff6c4c4c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Check and Mount Azure Blob Storage Container (LANDING)"
    }
   },
   "outputs": [],
   "source": [
    "container_name = 'landing'\n",
    "storage_account_name = 'ingest00landingsbox'\n",
    "\n",
    "# List of required secrets\n",
    "required_secrets = [\n",
    "    \"LANDING-SAS-TOKEN\"\n",
    "]\n",
    "for secret in required_secrets:\n",
    "    foldername = secret.split('-')[0]\n",
    "    mount_point = f\"/mnt/{container_name}\"\n",
    "\n",
    "    # Ensure mount_info is accessed correctly\n",
    "    mounts = dbutils.fs.mounts()\n",
    "    \n",
    "    if not any(mount_point in (mount_info.mountPoint if isinstance(mount_info, tuple) else mount_info['mountPoint']) for mount_info in mounts):\n",
    "        try:\n",
    "            dbutils.fs.mount(\n",
    "                source=source_url,\n",
    "                mount_point=mount_point,\n",
    "                extra_configs={f\"fs.azure.sas.{container_name}.{storage_account_name}.blob.core.windows.net\": dbutils.secrets.get(scope='ingest00-meta002-sbox', key=secret)}\n",
    "            )\n",
    "            print(f\"Container '{container_name}' mounted successfully at '{mount_point}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error mounting container at '{mount_point}': {e}\")\n",
    "    else:\n",
    "        print(f\"Mount point '{mount_point}' already exists.\")\n",
    "\n",
    "    # Access the specific folder\n",
    "    folder_path = f\"{mount_point}\"\n",
    "\n",
    "    # List files in the folder to verify\n",
    "    try:\n",
    "        files = dbutils.fs.ls(folder_path)\n",
    "        display(files)\n",
    "        print(f\"Folder '{foldername}' accessed successfully at '{folder_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing folder '{foldername}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5edf3ffd-b595-4d7c-bb66-c18e18720935",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Check and Mount Azure Blob Storage Container (CURATED)"
    }
   },
   "outputs": [],
   "source": [
    "storage_account_name = \"ingest00curatedsbox\"\n",
    "\n",
    "# List of containers\n",
    "containers = [\"gold\", \"silver\", \"bronze\"]\n",
    "foldername = 'ARIADM'\n",
    "\n",
    "# Corresponding secrets (must be in the same order as containers)\n",
    "secrets = [\"GOLD-SAS-TOKEN\", \"SILVER-SAS-TOKEN\", \"BRONZE-SAS-TOKEN\"]\n",
    "\n",
    "# Iterate over both lists using zip\n",
    "for container_name, secret_key in zip(containers, secrets):\n",
    "    mount_point = f\"/mnt/{container_name}\"\n",
    "    source_url = f\"wasbs://{container_name}@{storage_account_name}.blob.core.windows.net/\"\n",
    "\n",
    "    # Ensure mount_info is accessed correctly\n",
    "    mounts = dbutils.fs.mounts()\n",
    "\n",
    "    if not any(mount_point in (mount_info.mountPoint if isinstance(mount_info, tuple) else mount_info[\"mountPoint\"]) for mount_info in mounts):\n",
    "        try:\n",
    "            dbutils.fs.mount(\n",
    "                source=source_url,\n",
    "                mount_point=mount_point,\n",
    "                extra_configs={f\"fs.azure.sas.{container_name}.{storage_account_name}.blob.core.windows.net\": \n",
    "                               dbutils.secrets.get(scope=\"ingest00-meta002-sbox\", key=secret_key)}\n",
    "            )\n",
    "            print(f\"Container '{container_name}' mounted successfully at '{mount_point}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error mounting container '{container_name}' at '{mount_point}': {e}\")\n",
    "    else:\n",
    "        print(f\"Mount point '{mount_point}' already exists.\")\n",
    "\n",
    "    # Access the specific folder\n",
    "    folder_path = f\"{mount_point}\"\n",
    "\n",
    "    # List files in the folder to verify\n",
    "    try:\n",
    "        files = dbutils.fs.ls(folder_path)\n",
    "        display(files)\n",
    "        print(f\"Folder '{foldername}' accessed successfully at '{folder_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing folder '{foldername}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa185f47-c57c-4ada-8db2-1d1b54c9d42f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.exit(\"Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01710e2d-b226-4088-a22c-125e0743ecd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18de12f3-c228-49be-9210-030f8f04970d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Autoloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "211a66d4-41fd-4045-80df-2c0a6a09f582",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/mnt/landing/IU_Original\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4edb1d68-9dbd-4fda-adb8-8a19c9997e23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "checkpoint_location = \"dbfs:/mnt/landing/IU_Original/schema/\"\n",
    "target_table = \"dbfs:/mnt/landing/IU_Original/target/\"\n",
    "\n",
    "dbutils.fs.rm(target_table, recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a19ff8ee-1d15-49a4-b9a7-43b0b8f7dc50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.put(\"dbfs:/mnt/landing/IU_Original/response/appeals_1_1cf6f5b1b00ed2b52c23c83afe48efe3_1_iu.rsp\", \"\"\"\n",
    "{\"operation\": \"input_upload\", \"timestamp\": \"2023-02-16T12:59:15.884621\", \"status\": 1, \"exception_description\": null, \"error_status\": null, \"filename\": \"_HP2_manifest\", \"submission_folder\": \"/dropzone/BOOKSDB/submission\", \"file_hash\": \"1cf6f5b1b00ed2b52c23c83afe48efe3\"}\n",
    "\"\"\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de900da5-a296-460d-b960-17def26650e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Define the schema based on your JSON structure\n",
    "schema = StructType([\n",
    "    StructField(\"operation\", StringType(), True),\n",
    "    StructField(\"timestamp\", TimestampType(), True),\n",
    "    StructField(\"status\", IntegerType(), True),\n",
    "    StructField(\"exception_description\", StringType(), True),\n",
    "    StructField(\"error_status\", StringType(), True),\n",
    "    StructField(\"filename\", StringType(), True),\n",
    "    StructField(\"submission_folder\", StringType(), True),\n",
    "    StructField(\"file_hash\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Define paths\n",
    "source_directory = \"dbfs:/mnt/landing/IU_Original/response/\"\n",
    "schema_location = \"dbfs:/mnt/landing/IU_Original/schema/\"\n",
    "checkpoint_location = \"dbfs:/mnt/landing/IU_Original/schema/\"\n",
    "target_table = \"dbfs:/mnt/landing/IU_Original/target/\"\n",
    "\n",
    "# Define Auto Loader config with schema\n",
    "autoloader_config = {\n",
    "    \"cloudFiles.format\": \"json\",\n",
    "    \"cloudFiles.schemaLocation\": checkpoint_location,\n",
    "    \"cloudFiles.fileNamePattern\": \"*.rsp\",\n",
    "    \"cloudFiles.includeExistingFiles\": \"true\",\n",
    "    \"cloudFiles.validateOptions\": \"false\",\n",
    "    \"cloudFiles.useNotifications\": \"false\"  # ✅ Disable notifications\n",
    "}\n",
    "\n",
    "# autoloader_config = {\n",
    "#     \"cloudFiles.format\": \"json\",\n",
    "#     \"cloudFiles.schemaLocation\": checkpoint_location,\n",
    "#     \"cloudFiles.fileNamePattern\": \"*_iu.rsp\",  # ✅ Match only files ending with _iu.rsp\n",
    "#     \"cloudFiles.includeExistingFiles\": \"true\",\n",
    "#     \"cloudFiles.validateOptions\": \"false\",\n",
    "#     \"cloudFiles.useNotifications\": \"false\"  # ✅ Polling mode (no subscriptionId needed)\n",
    "# }\n",
    "\n",
    "# autoloader_config = {\n",
    "#     \"cloudFiles.format\": \"json\",\n",
    "#     \"cloudFiles.schemaLocation\": checkpoint_location,\n",
    "#     \"cloudFiles.fileNamePattern\": \".*_iu\\\\.rsp$\",  # ✅ Ensures filename ends strictly with _iu.rsp\n",
    "#     \"cloudFiles.includeExistingFiles\": \"true\",\n",
    "#     \"cloudFiles.validateOptions\": \"false\",\n",
    "#     \"cloudFiles.useNotifications\": \"false\"  # ✅ Polling mode (no subscriptionId needed)\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "def batch_process():\n",
    "    df = (\n",
    "        spark.readStream\n",
    "        .format(\"cloudFiles\")\n",
    "        .options(**autoloader_config)\n",
    "        .schema(schema) # ✅ Specify schema explicitly\n",
    "        .load(source_directory)\n",
    "        .select(\"*\", \n",
    "                col(\"_metadata.file_path\").alias(\"_FILE_PATH\"), \n",
    "                col(\"_metadata.file_modification_time\").alias(\"_FILE_MODIFICATION_TIME\")\n",
    "               )\n",
    "    )\n",
    "\n",
    "    query = (\n",
    "        df.writeStream\n",
    "        .option(\"checkpointLocation\", checkpoint_location)\n",
    "        .trigger(availableNow=True)\n",
    "        .format(\"delta\")\n",
    "        .outputMode(\"append\")\n",
    "        .option(\"path\", target_table)\n",
    "        .start()\n",
    "    )\n",
    "\n",
    "    query.awaitTermination()\n",
    "\n",
    "# Run batch processing\n",
    "batch_process()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Processing: Azure Blob Storage Mount and Secret Management",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
