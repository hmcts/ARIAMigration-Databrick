parameters:
  pythonVersion: ''
  env: ''
  mainRepositoryName: ''
  databricksInstance: ''
  databricksClusterId: ''
  wheelName: 'ARIAFUNCITONS-0.0.1-py3-none-any.whl'


steps:
- task: DownloadPipelineArtifact@2
  displayName: 'Download wheel artifact'
  inputs:
    buildType: 'current'
    artifactName: 'python-wheel'
    targetPath: '$(Pipeline.Workspace)/python-wheel'

- task: AzureCLI@2
  displayName: 'Install Databricks CLI and Upload Wheel'
  condition: succeeded()
  inputs:
    azureSubscription: 'DTS-DATAINGEST-${{ upper(parameters.env) }}'
    scriptType: bash
    scriptLocation: inlineScript
    inlineScript: |
      set -e
      source working_dir/bin/activate
      export PYTHONPATH="${PYTHONPATH}:/./"
      pip install databricks-cli
      export DATABRICKS_HOST=${{ parameters.databricksInstance }}
      export DATABRICKS_TOKEN=$(AUTH-AccessToken-sbox)
      databricks fs cp $(Pipeline.Workspace)/python-wheel/${{ parameters.wheelName }} dbfs:/FileStore/shared_wheels/${{ parameters.wheelName }} --overwrite
      databricks libraries install --cluster-id ${{ parameters.databricksClusterId }} --whl dbfs:/FileStore/shared_wheels/${{ parameters.wheelName }}
    workingDirectory: '$(System.DefaultWorkingDirectory)'