resources:
  jobs:
    wheel-job:
      name: wheel-job
      job_clusters:
        - job_cluster_key: DAB_job_cluster
          new_cluster:
            spark_version: 14.3.x-scala2.12
            node_type_id: Standard_D8ds_v5
            num_workers: 2

      tasks:
        - task_key: run-my-wheel
          job_cluster_key: DAB_job_cluster
          python_wheel_task:
            entry_point: main
            package_name: shared_functions
          libraries: #seperate devops step to copy file into workspace
            - whl: "dbfs:/FileStore/shared_wheels/shared_functions-0.0.1-py3-none-any.whl"

        - task_key: validate_packages
          job_cluster_key: DAB_job_cluster
          notebook_task: 
            notebook_path: "/Workspace/Users/andrew.mcdevitt@hmcts.net/test-packages-wheel"
            source: WORKSPACE
        - task_key: DLT_creation_of_content
          depends_on:
            - task_key: validate_packages
          pipeline_task:
            pipeline_id: ${resources.pipelines.pipeline_pl_ariadm_arm_fta.id}
            full_refresh: false

        - task_key: publish_HTML_JSON_to_eh
          job_cluster_key: DAB_job_cluster
          depends_on:
            - task_key: DLT_creation_of_content
          notebook_task:
            notebook_path: "/Workspace/live/ARCHIVE/APPEALS/ARIA_ADLS_TO_EVENTHUBS_GENRIC"
            base_parameters: #Will we remove these mounts and use SP once up and running? or do we need tf to provision
              gold_mount: /mnt/ingest00curatedsboxgold/ARIADM/ARM/APPEALS/ARIAFTA/
              topic: evh-apl-pub-dev-uks-dlrm-01
              dropzone_mount: /mnt/dropzoneariafta/APPEALS/ARIAFTA/
              file_types: html,json
            source: WORKSPACE