{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18504bdf-794e-4966-b290-b635328c3ed0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Active Appeals CCD MVP Payment Pending (Silver Layer)\n",
    "<table style='float:left;'>\n",
    "   <tbody>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><b>Name: </b></td>\n",
    "         <td>SILVER_TO_GOLD__PAYMENT_PENDING_JSON</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><b>Description: </b></td>\n",
    "         <td>Notebook dedicated for the payment pending, not common for any other active appeal states.</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><b>First Created: </b></td>\n",
    "         <td>July-2025</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <th style='text-align: left;'><b>Changelog (JIRA ref/initials/date):</b></th>\n",
    "         <th>Comments</th>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-667\">ARIADM-667</a>/NSA/JUL-2025</td>\n",
    "         <td>Create Silver Staging tables: stg_main_payment_pending_validation, stg_valid_payment_pending_records, stg_invalid_payment_pending_quarantine_records</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-668\">ARIADM-668</a>/NSA/JUL-2025</td>\n",
    "         <td>appealType 1:1 & defaults mappings</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-670\">ARIADM-670</a>/NSA/JUL-2025</td>\n",
    "         <td>appealType logic mappings</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-672\">ARIADM-672</a>/NSA/JUL-2025</td>\n",
    "         <td>caseData 1:1 & defaults mappings</td>\n",
    "      </tr>\n",
    "       <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-669\">ARIADM-669</a>/NSA/JUL-2025</td>\n",
    "         <td>appealType 1:1 - Data quality & constriant checks implementation</td>\n",
    "      </tr>\n",
    "       <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-671\">ARIADM-671</a>/NSA/JUL-2025</td>\n",
    "         <td>appealType logic - Data quality & constriant checks implementation</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-707\">ARIADM-707</a>/NSA/JUL-2025</td>\n",
    "         <td>caseData logic mappings - Hearing Centre</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-674\">ARIADM-674</a>/NSA/JUL-2025</td>\n",
    "         <td>caseData logic mappings</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-673\">ARIADM-673</a>/NSA/JUL-2025</td>\n",
    "         <td>caseData 1:1 - Data quality & constriant checks implementation</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-675\">ARIADM-675</a>/NSA/JUL-2025</td>\n",
    "         <td>caseData logic mappings - Data quality & constriant checks implementation</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-707\">ARIADM-707</a>/NSA/JUL-2025</td>\n",
    "         <td>caseData logic mappings - Hearing Centre</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-708\">ARIADM-708</a>/NSA/JUL-2025</td>\n",
    "         <td>caseData logic mappings - Hearing Centre - Data quality & constriant checks implementation</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-857\">ARIADM-857</a>/NSA/JUL-2025</td>\n",
    "         <td>Update Active Bronze Notebook to Include Column Aliasing Rules in Bronze Tables</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-767\">ARIADM-767</a>/AM/JUL-2025</td>\n",
    "         <td>Include 1:1 mapping of legalRepDetails ticket 767</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-768\">ARIADM-768</a>/AM/JUL-2025</td>\n",
    "         <td>Include validation for legalRepDetails ticket 768</td>\n",
    "      </tr>\n",
    "       <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-755\">ARIADM-755</a>/NSA/JUL-2025</td>\n",
    "         <td>appellantDetails 1:1 mappings</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-756\">ARIADM-756</a>/NSA/JUL-2025</td>\n",
    "         <td>appellantDetails 1:1 mappings -  - Data quality & constriant checks implementation</td>\n",
    "      </tr>\n",
    "   </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6b49dac-308d-447a-8532-b56207d5350c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47cb7071-a7f5-4143-aff8-d956deb54805",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ace5af5-8756-453e-b843-032a5c8baaba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config = spark.read.option(\"multiline\", \"true\").json(\"dbfs:/configs/config.json\")\n",
    "env_name = config.first()[\"env\"].strip().lower()\n",
    "lz_key = config.first()[\"lz_key\"].strip().lower()\n",
    "\n",
    "print(f\"env_code: {lz_key}\")  # This won't be redacted\n",
    "print(f\"env_name: {env_name}\")  # This won't be redacted\n",
    "\n",
    "KeyVault_name = f\"ingest{lz_key}-meta002-{env_name}\"\n",
    "print(f\"KeyVault_name: {KeyVault_name}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fce9d72-a29e-4db7-910a-d6b0d235c297",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Service principal credentials\n",
    "client_id = dbutils.secrets.get(KeyVault_name, \"SERVICE-PRINCIPLE-CLIENT-ID\")\n",
    "client_secret = dbutils.secrets.get(KeyVault_name, \"SERVICE-PRINCIPLE-CLIENT-SECRET\")\n",
    "tenant_id = dbutils.secrets.get(KeyVault_name, \"SERVICE-PRINCIPLE-TENANT-ID\")\n",
    "\n",
    "# Storage account names\n",
    "curated_storage = f\"ingest{lz_key}curated{env_name}\"\n",
    "checkpoint_storage = f\"ingest{lz_key}xcutting{env_name}\"\n",
    "raw_storage = f\"ingest{lz_key}raw{env_name}\"\n",
    "landing_storage = f\"ingest{lz_key}landing{env_name}\"\n",
    "external_storage = f\"ingest{lz_key}external{env_name}\"\n",
    "\n",
    "\n",
    "# Spark config for curated storage (Delta table)\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{curated_storage}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{curated_storage}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{curated_storage}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{curated_storage}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{curated_storage}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n",
    "\n",
    "# Spark config for checkpoint storage\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{checkpoint_storage}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{checkpoint_storage}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{checkpoint_storage}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{checkpoint_storage}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{checkpoint_storage}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n",
    "\n",
    "# Spark config for checkpoint storage\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{raw_storage}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{raw_storage}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{raw_storage}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{raw_storage}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{raw_storage}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n",
    "\n",
    "# Spark config for checkpoint storage\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{landing_storage}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{landing_storage}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{landing_storage}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{landing_storage}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{landing_storage}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n",
    "\n",
    "\n",
    "# Spark config for checkpoint storage\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{external_storage}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{external_storage}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{external_storage}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{external_storage}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{external_storage}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1b86460-a200-4c6b-9bf1-382b6bc1e8db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6d53e3e-0282-4481-959b-3f6fbadab65f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AppealState = \"paymentPending\"\n",
    "\n",
    "# Setting variables for use in subsequent cells\n",
    "bronze_path = f\"abfss://bronze@ingest{lz_key}curated{env_name}.dfs.core.windows.net/ARIADM/ACTIVE/CCD/APPEALS/\"\n",
    "silver_path = f\"abfss://silver@ingest{lz_key}curated{env_name}.dfs.core.windows.net/ARIADM/ACTIVE/CCD/APPEALS/\"\n",
    "audit_path = f\"abfss://silver@ingest{lz_key}curated{env_name}.dfs.core.windows.net/ARIADM/ACTIVE/CCD/APPEALS/AUDIT/{AppealState}\"\n",
    "gold_outputs = f\"ARIADM/ACTIVE/CCD/APPEALS/{AppealState}\"\n",
    "\n",
    "\n",
    "\n",
    "# Print all variables\n",
    "variables = {\n",
    "    # \"read_hive\": read_hive,\n",
    "    \n",
    "    \"bronze_path\": bronze_path,\n",
    "    \"silver_path\": silver_path,\n",
    "    \"audit_path\": audit_path,\n",
    "    \"gold_outputs\": gold_outputs,\n",
    "    \"key_vault\": KeyVault_name,\n",
    "    \"AppealState\": AppealState\n",
    "\n",
    "}\n",
    "\n",
    "display(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a2e4c75-b6e3-403f-99f8-ca27a6e03b05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## PaymentPending: Silver DLT staging table for gold transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9dc2f07-0f34-46eb-a4fc-73e29b7966e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transformation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b88d0ab2-727d-44c8-ac47-f7ae52c0a531",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: appealType"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, lit, array\n",
    "\n",
    "# AppealType grouping\n",
    "def appealType(silver_m1):\n",
    "    conditions = (col(\"dv_representation\").isin('LR', 'AIP')) & (col(\"lu_appealType\").isNotNull())\n",
    "\n",
    "    df = silver_m1.select(\n",
    "        col(\"CaseNo\"),\n",
    "        when(\n",
    "            conditions,\n",
    "            col(\"lu_appealType\")\n",
    "        ).otherwise(None).alias(\"appealType\"),\n",
    "        when(\n",
    "            conditions,\n",
    "            col(\"lu_hmctsCaseCategory\")\n",
    "        ).otherwise(None).alias(\"hmctsCaseCategory\"),\n",
    "        when(\n",
    "            conditions,\n",
    "            col(\"CaseNo\")\n",
    "        ).otherwise(None).alias(\"appealReferenceNumber\"),\n",
    "        when(\n",
    "            conditions,\n",
    "            col(\"lu_appealTypeDescription\")\n",
    "        ).otherwise(None).alias(\"appealTypeDescription\"),\n",
    "        when(\n",
    "            conditions,\n",
    "            col(\"lu_caseManagementCategory\")\n",
    "        ).otherwise(None).alias(\"caseManagementCategory\"),\n",
    "        when(\n",
    "            ((col(\"dv_representation\") == \"AIP\") & (col(\"lu_appealType\").isNotNull())),\n",
    "            lit(\"Yes\")\n",
    "        ).otherwise(lit(None)).alias(\"isAppealReferenceNumberAvailable\"),\n",
    "        when(\n",
    "            conditions,\n",
    "            lit(\"\")\n",
    "        ).otherwise(lit(None)).alias(\"ccdReferenceNumberForDisplay\")\n",
    "    )\n",
    "\n",
    "    common_inputFields = [lit(\"dv_representation\"), lit(\"lu_appealType\")]\n",
    "    common_inputValues = [col(\"audit.dv_representation\"), col(\"audit.lu_appealType\")]\n",
    "\n",
    "    df_audit = silver_m1.alias(\"audit\").join(df.alias(\"content\"), [\"CaseNo\"], \"left\").select(\n",
    "        col(\"CaseNo\"),\n",
    "\n",
    "        #Audit appealType\n",
    "        array(struct(*common_inputFields)).alias(\"appealType_inputFields\"),\n",
    "        array(struct(*common_inputValues)).alias(\"appealType_inputValues\"),\n",
    "        col(\"content.appealType\"),\n",
    "        lit(\"yes\").alias(\"appealType_Transformation\"),\n",
    "\n",
    "        #Audit appealReferenceNumber\n",
    "        array(struct(*common_inputFields, lit(\"CaseNo\"))).alias(\"appealReferenceNumber_inputfields\"),\n",
    "        array(struct(*common_inputValues, col(\"CaseNo\"))).alias(\"appealReferenceNumber_inputvalues\"),\n",
    "        col(\"content.appealReferenceNumber\"),\n",
    "        lit(\"no\").alias(\"appealReferenceNumber_Transformation\"),\n",
    "\n",
    "        #Audit hmctsCaseCategory\n",
    "        array(struct(*common_inputFields, lit(\"lu_hmctsCaseCategory\"))).alias(\"hmctsCaseCategory_inputfields\"),\n",
    "        array(struct(*common_inputValues, col(\"audit.lu_hmctsCaseCategory\"))).alias(\"hmctsCaseCategory_inputvalues\"),\n",
    "        col(\"content.hmctsCaseCategory\"),\n",
    "        lit(\"yes\").alias(\"hmctsCaseCategory_Transformation\"),\n",
    "\n",
    "        #Audit appealTypeDescription\n",
    "        array(struct(*common_inputFields, lit(\"lu_appealTypeDescription\"))).alias(\"appealTypeDescription_inputFields\"),\n",
    "        array(struct(*common_inputValues, col(\"audit.lu_appealTypeDescription\"))).alias(\"appealTypeDescription_inputValues\"),\n",
    "        col(\"content.appealTypeDescription\"),\n",
    "        lit(\"yes\").alias(\"appealTypeDescription_Transformation\"),\n",
    "\n",
    "        #Audit caseManagementCategory\n",
    "        array(struct(*common_inputFields, lit(\"lu_caseManagementCategory\"))).alias(\"caseManagementCategory_inputFields\"),\n",
    "        array(struct(*common_inputValues, col(\"audit.lu_caseManagementCategory\"))).alias(\"caseManagementCategory_inputValues\"),\n",
    "        col(\"content.caseManagementCategory\"),\n",
    "        lit(\"yes\").alias(\"caseManagementCategory_Transformation\"),\n",
    "\n",
    "\n",
    "        #Audit isAppealReferenceNumberAvailable\n",
    "        array(struct(*common_inputFields)).alias(\"isAppealReferenceNumberAvailable_inputFields\"),\n",
    "        array(struct(*common_inputValues)).alias(\"isAppealReferenceNumberAvailable_inputValues\"),\n",
    "        col(\"content.isAppealReferenceNumberAvailable\"),\n",
    "        lit(\"yes\").alias(\"isAppealReferenceNumberAvailable_Transformation\"),\n",
    "\n",
    "        #Audit isAppealReferenceNumberAvailable\n",
    "        array(struct(*common_inputFields)).alias(\"ccdReferenceNumberForDisplay_inputFields\"),\n",
    "        array(struct(*common_inputValues)).alias(\"ccdReferenceNumberForDisplay_inputValues\"),\n",
    "        col(\"content.ccdReferenceNumberForDisplay\"),\n",
    "        lit(\"yes\").alias(\"ccdReferenceNumberForDisplay_Transformation\")\n",
    "\n",
    "    )\n",
    "    \n",
    "    return df, df_audit\n",
    "\n",
    "# silver_m1 = spark.table(\"ariadm_active_appeals.silver_appealcase_detail\").filter(col(\"dv_targetState\") == lit(AppealState)).distinct()\n",
    "# df, df_audit = appealType(silver_m1)\n",
    "# display(df_audit)\n",
    "# df_audit.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "281bbd63-a6bd-4048-839a-a48e62714025",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: caseData"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list, struct, when, lit, col, max as spark_max, date_format, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# caseData grouping\n",
    "def caseData(silver_m1, silver_m3):\n",
    "    # silver_m1 = silver_m1.filter( ((col(\"representation\").isin('LR', 'AIP')) & (col(\"appealType\").isNotNull())))\n",
    "\n",
    "    # Filter silver_m3 to get rows with max StatusId and Outcome is not null\n",
    "    # Define window partitioned by CaseNo and ordered by descending StatusId\n",
    "    window_spec = Window.partitionBy(\"CaseNo\").orderBy(col(\"StatusId\").desc())\n",
    "\n",
    "    # Add row_number to get the row with the highest StatusId per CaseNo\n",
    "    silver_m3_ranked = silver_m3.withColumn(\"row_num\", row_number().over(window_spec))\n",
    "\n",
    "    # Filter the top-ranked rows where Outcome is not null\n",
    "    silver_m3_filtered = silver_m3_ranked.filter(\n",
    "        (col(\"row_num\") == 1) & (col(\"Outcome\").isNotNull())\n",
    "    ).select(\n",
    "        col(\"CaseNo\"),\n",
    "        lit(\"Yes\").alias(\"recordedOutOfTimeDecision\"), col(\"Outcome\")\n",
    "    )\n",
    "\n",
    "    conditions = (col(\"dv_representation\").isin('LR', 'AIP')) & (col(\"lu_appealType\").isNotNull())\n",
    "\n",
    "    df = silver_m1.alias(\"m1\").join(\n",
    "        silver_m3_filtered.alias(\"m3\"),\n",
    "        on=\"CaseNo\",\n",
    "        how=\"left\"\n",
    "    ).withColumn(\n",
    "        \"appellantsRepresentation\", when(((col(\"m1.dv_representation\") == \"LR\") &  (col(\"lu_appealType\").isNotNull())), \"No\").when(((col(\"m1.dv_representation\") == \"AIP\") & (col(\"lu_appealType\").isNotNull())), \"Yes\").otherwise(None)\n",
    "    ).withColumn(\n",
    "        \"submissionOutOfTime\", when(col(\"OutOfTimeIssue\") == 1, lit(\"Yes\")).otherwise(lit(\"No\"))\n",
    "    ).withColumn(\n",
    "        \"adminDeclaration1\", lit([\"hasDeclared\"])\n",
    "    ).withColumn(\n",
    "        \"appealWasNotSubmittedReason\", when(((col(\"m1.dv_representation\") == \"LR\") & (col(\"lu_appealType\").isNotNull())), \"This is an ARIA Migrated Case.\").otherwise(None)\n",
    "    ).withColumn(\n",
    "        \"applicationOutOfTimeExplanation\", when(col(\"OutOfTimeIssue\") == 1, \"This is a migrated ARIA case. Please refer to the documents.\").otherwise(None)\n",
    "    ).withColumn(\n",
    "        \"appealSubmissionDate\", date_format(col(\"m1.DateLodged\"), \"yyyy-MM-dd\")\n",
    "    ).withColumn(\n",
    "        \"appealSubmissionInternalDate\", date_format(col(\"m1.DateLodged\"), \"yyyy-MM-dd\")\n",
    "    ).withColumn(\n",
    "        \"tribunalReceivedDate\", date_format(col(\"m1.DateAppealReceived\"), \"yyyy-MM-dd\")\n",
    "    ).select(\n",
    "        \"CaseNo\", \n",
    "        col(\"appellantsRepresentation\"),\n",
    "        when(conditions, col(\"submissionOutOfTime\")).otherwise(None).alias(\"submissionOutOfTime\"),\n",
    "        when(conditions, col(\"m3.recordedOutOfTimeDecision\")).otherwise(None).alias(\"recordedOutOfTimeDecision\"),\n",
    "        when(conditions, col(\"applicationOutOfTimeExplanation\")).otherwise(None).alias(\"applicationOutOfTimeExplanation\"), \n",
    "        when(conditions, col(\"lu_hearingCentre\")).otherwise(None).alias(\"hearingCentre\"),\n",
    "        when(conditions, col(\"lu_staffLocation\")).otherwise(None).alias(\"staffLocation\"),\n",
    "        when(conditions, col(\"lu_caseManagementLocation\")).otherwise(None).alias(\"caseManagementLocation\"),\n",
    "        when(conditions, col(\"dv_hearingCentreDynamicList\")).otherwise(None).alias(\"hearingCentreDynamicList\"),\n",
    "        when(conditions, col(\"dv_caseManagementLocationRefData\")).otherwise(None).alias(\"caseManagementLocationRefData\"),\n",
    "        when(conditions, col(\"lu_selectedHearingCentreRefData\")).otherwise(None).alias(\"selectedHearingCentreRefData\"),\n",
    "        col(\"appealWasNotSubmittedReason\"),\n",
    "        when(conditions, col(\"adminDeclaration1\")).otherwise(None).alias(\"adminDeclaration1\"),    \n",
    "        when(conditions, col(\"appealSubmissionDate\")).otherwise(None).alias(\"appealSubmissionDate\"), \n",
    "        when(conditions, col(\"appealSubmissionInternalDate\")).otherwise(None).alias(\"appealSubmissionInternalDate\"),\n",
    "        when(conditions, col(\"tribunalReceivedDate\")).otherwise(None).alias(\"tribunalReceivedDate\"),\n",
    "        when(conditions, lit([]).cast(\"array<int>\")).otherwise(None).alias(\"caseLinks\"), \n",
    "        when(conditions, lit(\"No\")).otherwise(None).alias(\"hasOtherAppeals\")\n",
    "    )\n",
    "\n",
    "    common_inputFields = [lit(\"dv_representation\"), lit(\"lu_appealType\")]\n",
    "    common_inputValues = [col(\"audit.dv_representation\"), col(\"audit.lu_appealType\")]\n",
    "\n",
    "    df_audit = silver_m1.alias(\"audit\").join(df.alias(\"content\"), [\"CaseNo\"],\"left\") \\\n",
    "                        .join(silver_m3_filtered.alias(\"m3\"), [\"CaseNo\"],\"left\").select(\n",
    "\n",
    "    col(\"CaseNo\"),\n",
    "\n",
    "    #Audit appellantsRepresentation\n",
    "    array(struct(*common_inputFields)).alias(\"appellantsRepresentation_inputFields\"),\n",
    "    array(struct(*common_inputValues)).alias(\"appellantsRepresentation_inputValues\"),\n",
    "    col(\"content.appellantsRepresentation\"),\n",
    "    lit(\"yes\").alias(\"appellantsRepresentation_Transformation\"),\n",
    "\n",
    "    #Audit submissionOutOfTime\n",
    "    array(struct(*common_inputFields,lit(\"OutOfTimeIssue\"))).alias(\"submissionOutOfTime_inputFields\"),\n",
    "    array(struct(*common_inputValues,col(\"audit.OutOfTimeIssue\"))).alias(\"submissionOutOfTime_inputValues\"),\n",
    "    col(\"content.submissionOutOfTime\"),\n",
    "    lit(\"yes\").alias(\"submissionOutOfTime_Transformation\"),\n",
    "\n",
    "    #Audit recordedOutOfTimeDecision\n",
    "    array(struct(*common_inputFields,lit(\"Outcome\"))).alias(\"recordedOutOfTimeDecision_inputFields\"),\n",
    "    array(struct(*common_inputValues,col(\"m3.Outcome\"))).alias(\"recordedOutOfTimeDecision_inputValues\"),\n",
    "    col(\"content.recordedOutOfTimeDecision\"),\n",
    "    lit(\"yes\").alias(\"recordedOutOfTimeDecision_Transformation\"),\n",
    "\n",
    "    #Audit applicationOutOfTimeExplanation\n",
    "    array(struct(*common_inputFields,lit(\"OutOfTimeIssue\"))).alias(\"applicationOutOfTimeExplanation_inputFields\"),\n",
    "    array(struct(*common_inputValues,col(\"audit.OutOfTimeIssue\"))).alias(\"applicationOutOfTimeExplanation_inputValues\"),\n",
    "    col(\"content.applicationOutOfTimeExplanation\"),\n",
    "    lit(\"yes\").alias(\"applicationOutOfTimeExplanation_Transformation\"),\n",
    "\n",
    "    #Audit hearingCentre\n",
    "    array(struct(*common_inputFields,lit(\"lu_hearingCentre\"))).alias(\"hearingCentre_inputFields\"),\n",
    "    array(struct(*common_inputValues,col(\"audit.lu_hearingCentre\"))).alias(\"hearingCentre_inputValues\"),\n",
    "    col(\"content.hearingCentre\"),\n",
    "    lit(\"yes\").alias(\"hearingCentre_Transformation\"),\n",
    "\n",
    "    #Audit staffLocation\n",
    "    array(struct(*common_inputFields,lit(\"lu_staffLocation\"))).alias(\"staffLocation_inputFields\"),\n",
    "    array(struct(*common_inputValues,col(\"audit.lu_staffLocation\"))).alias(\"staffLocation_inputValues\"),\n",
    "    col(\"content.staffLocation\"),\n",
    "    lit(\"yes\").alias(\"staffLocation_Transformation\"),\n",
    "\n",
    "    #Audit caseManagementLocation\n",
    "    array(struct(*common_inputFields,lit(\"lu_hearingCentre\"))).alias(\"caseManagementLocation_inputFields\"),\n",
    "    array(struct(*common_inputValues,col(\"audit.lu_caseManagementLocation\"))).alias(\"caseManagementLocation_inputValues\"),\n",
    "    col(\"content.caseManagementLocation\"),\n",
    "    lit(\"yes\").alias(\"caseManagementLocation_Transformation\"),\n",
    "\n",
    "    #Audit hearingCentreDynamicList\n",
    "    array(struct(*common_inputFields,lit(\"dv_hearingCentreDynamicList\"))).alias(\"hearingCentreDynamicList_inputFields\"),\n",
    "    array(struct(*common_inputValues,col(\"audit.dv_hearingCentreDynamicList\"))).alias(\"hearingCentreDynamicList_inputValues\"),\n",
    "    col(\"content.hearingCentreDynamicList\"),\n",
    "    lit(\"yes\").alias(\"hearingCentreDynamicList_Transformation\"),\n",
    "\n",
    "    #Audit caseManagementLocationRefData\n",
    "    array(struct(*common_inputFields,lit(\"dv_caseManagementLocationRefData\"))).alias(\"caseManagementLocationRefData_inputFields\"),\n",
    "    array(struct(*common_inputValues,col(\"audit.dv_caseManagementLocationRefData\"))).alias(\"caseManagementLocationRefData_inputValues\"),\n",
    "    col(\"content.caseManagementLocationRefData\"),\n",
    "    lit(\"yes\").alias(\"caseManagementLocationRefData_Transformation\"),\n",
    "\n",
    "    #Audit selectedHearingCentreRefData\n",
    "    array(struct(*common_inputFields,lit(\"lu_selectedHearingCentreRefData\"))).alias(\"selectedHearingCentreRefData_inputFields\"),\n",
    "    array(struct(*common_inputValues,col(\"audit.lu_selectedHearingCentreRefData\"))).alias(\"selectedHearingCentreRefData_inputValues\"),\n",
    "    col(\"content.selectedHearingCentreRefData\"),\n",
    "    lit(\"yes\").alias(\"selectedHearingCentreRefData_Transformation\"),\n",
    "\n",
    "    #Audit appealWasNotSubmittedReason\n",
    "    array(struct(*common_inputFields)).alias(\"appealWasNotSubmittedReason_inputFields\"),\n",
    "    array(struct(*common_inputValues)).alias(\"appealWasNotSubmittedReason_inputValues\"),\n",
    "    col(\"content.appealWasNotSubmittedReason\"),\n",
    "    lit(\"yes\").alias(\"appealWasNotSubmittedReason_Transformation\"),\n",
    "\n",
    "    # Audit adminDeclaration1\n",
    "    array(struct(*common_inputFields)).alias(\"adminDeclaration1_inputFields\"),\n",
    "    array(struct(*common_inputValues)).alias(\"adminDeclaration1_inputValues\"),\n",
    "    col(\"content.adminDeclaration1\"),\n",
    "    lit(\"yes\").alias(\"adminDeclaration1_Transformation\"),\n",
    "\n",
    "    # Audit appealSubmissionDate\n",
    "    array(struct(*common_inputFields,lit(\"DateLodged\"))).alias(\"appealSubmissionDate_inputFields\"),\n",
    "    array(struct(*common_inputValues,col(\"audit.DateLodged\"))).alias(\"appealSubmissionDate_inputValues\"),\n",
    "    col(\"content.appealSubmissionDate\"),\n",
    "    lit(\"yes\").alias(\"appealSubmissionDate_Transformation\"),\n",
    "\n",
    "    # Audit appealSubmissionInternalDate\n",
    "    array(struct(*common_inputFields,lit(\"DateLodged\"))).alias(\"appealSubmissionInternalDate_inputFields\"),\n",
    "    array(struct(*common_inputValues,col(\"audit.DateLodged\"))).alias(\"appealSubmissionInternalDate_inputValues\"),\n",
    "    col(\"content.appealSubmissionInternalDate\"),\n",
    "    lit(\"yes\").alias(\"appealSubmissionInternalDate_Transformation\"),\n",
    "\n",
    "    # Audit tribunalReceivedDate\n",
    "    array(struct(*common_inputFields,lit(\"DateLodged\"))).alias(\"tribunalReceivedDate_inputFields\"),\n",
    "    array(struct(*common_inputValues,col(\"audit.DateLodged\"))).alias(\"tribunalReceivedDate_inputValues\"),\n",
    "    col(\"content.tribunalReceivedDate\"),\n",
    "    lit(\"yes\").alias(\"tribunalReceivedDate_Transformation\"),\n",
    "\n",
    "    # Audit caseLinks\n",
    "    array(struct(*common_inputFields)).alias(\"caseLinks_inputFields\"),\n",
    "    array(struct(*common_inputValues)).alias(\"caseLinks_inputValues\"),\n",
    "    col(\"content.caseLinks\"),\n",
    "    lit(\"yes\").alias(\"caseLinks_Transformation\"),\n",
    "\n",
    "    # Audit hasOtherAppeals\n",
    "    array(struct(*common_inputFields)).alias(\"hasOtherAppeals_inputFields\"),\n",
    "    array(struct(*common_inputValues)).alias(\"hasOtherAppeals_inputValues\"),\n",
    "    col(\"content.hasOtherAppeals\"),\n",
    "    lit(\"yes\").alias(\"hasOtherAppeals_Transformation\"),\n",
    "\n",
    "    )\n",
    "\n",
    "    return df, df_audit\n",
    "\n",
    "# silver_m5 = spark.table(\"ariadm_active_appeals.silver_link_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "# silver_m1 = spark.table(\"ariadm_active_appeals.silver_appealcase_detail\").filter(col(\"dv_targetState\") == lit(AppealState)).distinct()\n",
    "# silver_m3 = spark.table(\"ariadm_active_appeals.silver_status_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "# df = caseData(silver_m1, silver_m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23dda552-29e8-47fd-903d-edf96a380ef3",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"legalRepGivenName_inputFields\":270},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1753349799521}",
       "filterBlob": "{\"version\":1,\"filterGroups\":[{\"enabled\":true,\"filterGroupId\":\"fg_2bd82a2a\",\"op\":\"OR\",\"filters\":[{\"filterId\":\"f_3e8d30f6\",\"enabled\":true,\"columnId\":\"dv_representation\",\"dataType\":\"string\",\"filterType\":\"oneof\"}],\"local\":false,\"updatedAt\":1753273373443}],\"syncTimestamp\":1753273373443}",
       "queryPlanFiltersBlob": "[]",
       "tableResultIndex": 0
      }
     },
     "title": "Function: legalRepDetails"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, array, struct, lit, coalesce\n",
    "\n",
    "def legalRepDetails(silver_m1):\n",
    "    conditions_legalRepDetails = (col(\"dv_representation\") == 'LR') & (col(\"lu_appealType\").isNotNull())\n",
    "\n",
    "    df = silver_m1.alias(\"m1\").filter(conditions_legalRepDetails).withColumn(\n",
    "        \"legalRepGivenName\",\n",
    "        coalesce(col(\"Contact\"), col(\"RepName\"), col(\"CaseRepName\"))\n",
    "    ).withColumn(\n",
    "        \"legalRepFamilyNamePaperJ\",\n",
    "        coalesce(col(\"RepName\"), col(\"CaseRepName\"))\n",
    "    ).withColumn(\n",
    "        \"legalRepCompanyPaperJ\",\n",
    "        coalesce(col(\"RepName\"), col(\"CaseRepName\"))\n",
    "    ).withColumn(\n",
    "        \"localAuthorityPolicy\",\n",
    "        lit(\"\"\"{\n",
    "            \"Organisation\": {},\n",
    "            \"OrgPolicyCaseAssignedRole\": \"[LEGALREPRESENTATIVE]\"\n",
    "        }\"\"\")\n",
    "    ).select(\n",
    "        col(\"CaseNo\"),\n",
    "        \"legalRepGivenName\",\n",
    "        \"legalRepFamilyNamePaperJ\",\n",
    "        \"legalRepCompanyPaperJ\",\n",
    "        \"localAuthorityPolicy\"\n",
    "    )\n",
    "\n",
    "    common_inputFields = [lit(\"dv_representation\"), lit(\"lu_appealType\")]\n",
    "    common_inputValues = [col(\"m1_audit.dv_representation\"), col(\"m1_audit.lu_appealType\")]\n",
    "\n",
    "    df_audit = silver_m1.alias(\"m1_audit\").join(df.alias(\"content\"), on = [\"CaseNo\"], how = \"left\").filter(conditions_legalRepDetails).select(\n",
    "        col(\"CaseNo\"),\n",
    "\n",
    "        ## legalRepGivenName\n",
    "        array(struct(*common_inputFields ,lit(\"m1_audit.Contact\"), lit(\"m1_audit.RepName\"), lit(\"m1_audit.CaseRepName\"))).alias(\"legalRepGivenName_inputFields\"),\n",
    "        array(struct(*common_inputValues ,col(\"m1_audit.Contact\"), col(\"m1_audit.RepName\"), col(\"m1_audit.CaseRepName\"))).alias(\"legalRepGivenName_inputValues\"),\n",
    "        col(\"content.legalRepGivenName\"),\n",
    "        lit(\"yes\").alias(\"legalRepGivenName_Transformed\"),\n",
    "\n",
    "        # ## legalRepFamilyNamePaperJ\n",
    "        array(struct(*common_inputFields ,lit(\"m1_audit.RepName\"), lit(\"m1_audit.CaseRepName\"))).alias(\"legalRepFamilyNamePaperJ_inputFields\"),\n",
    "        array(struct(*common_inputValues ,col(\"m1_audit.RepName\"), col(\"m1_audit.CaseRepName\"))).alias(\"legalRepFamilyNamePaperJ_inputValues\"),\n",
    "        col(\"content.legalRepFamilyNamePaperJ\"),\n",
    "        lit(\"yes\").alias(\"legalRepFamilyNamePaperJ_Transformed\"),\n",
    "\n",
    "        # ## legalRepCompanyPaperJ\n",
    "        array(struct(*common_inputFields ,lit(\"m1_audit.RepName\"), lit(\"m1_audit.CaseRepName\"))).alias(\"legalRepCompanyPaperJ_inputFields\"),\n",
    "        array(struct(*common_inputValues ,col(\"m1_audit.RepName\"), col(\"m1_audit.CaseRepName\"))).alias(\"legalRepCompanyPaperJ_inputValues\"),\n",
    "        col(\"content.legalRepCompanyPaperJ\"),\n",
    "        lit(\"yes\").alias(\"legalRepCompanyPaperJ_Transformed\"),\n",
    "\n",
    "        # ## localAuthorityPolicy\n",
    "        array(struct(*common_inputFields)).alias(\"localAuthorityPolicy_inputFields\"),\n",
    "        array(struct(*common_inputValues)).alias(\"localAuthorityPolicy_inputValues\"),\n",
    "        col(\"content.localAuthorityPolicy\"),\n",
    "        lit(\"no\").alias(\"localAuthorityPolicy_Transformed\")\n",
    "    )\n",
    "\n",
    "    return df, df_audit\n",
    "\n",
    "# silver_m1 = spark.table(\"ariadm_active_appeals.silver_appealcase_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "# df, df_audit = legalRepDetails(silver_m1)\n",
    "\n",
    "# display(df)\n",
    "# display(df_audit)\n",
    "# display(silver_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35da9be5-91e4-4743-9b03-d4726742d3e6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: appellantDetails"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, lit, array\n",
    "\n",
    "# AppealType grouping\n",
    "def appellantDetails(silver_m1, silver_m2):\n",
    "    conditions = (col(\"dv_representation\").isin('LR', 'AIP')) & (col(\"lu_appealType\").isNotNull())\n",
    "\n",
    "    df = silver_m1.join(silver_m2, [\"CaseNo\"], \"left\").select(\n",
    "        col(\"CaseNo\"),\n",
    "        when(\n",
    "            conditions,\n",
    "            col(\"AppellantName\")\n",
    "        ).otherwise(None).alias(\"appellantFamilyName\"),\n",
    "        when(\n",
    "            conditions,\n",
    "            col(\"AppellantForenames\")\n",
    "        ).otherwise(None).alias(\"appellantGivenNames\"),\n",
    "        when(conditions, \n",
    "             concat(col(\"AppellantForenames\"), lit(\" \"), col(\"AppellantName\"))\n",
    "        ).otherwise(None).alias(\"appellantNameForDisplay\"),\n",
    "        when(conditions,\n",
    "             date_format(col(\"BirthDate\"),\"yyyy-MM-dd\")\n",
    "        ).otherwise(None).alias(\"appellantDateOfBirth\"),\n",
    "        when(conditions,\n",
    "             concat(col(\"AppellantForenames\"), lit(\" \"), col(\"AppellantName\"))\n",
    "        ).otherwise(None).alias(\"caseNameHmctsInternal\"),\n",
    "        when(conditions,\n",
    "             concat(col(\"AppellantForenames\"), lit(\" \"), col(\"AppellantName\"))\n",
    "        ).otherwise(None).alias(\"hmctsCaseNameInternal\")\n",
    "       \n",
    "    )\n",
    "\n",
    "    common_inputFields = [lit(\"dv_representation\"), lit(\"lu_appealType\")]\n",
    "    common_inputValues = [col(\"audit.dv_representation\"), col(\"audit.lu_appealType\")]\n",
    "\n",
    "    df_audit = silver_m1.join(silver_m2, [\"CaseNo\"], \"left\").alias(\"audit\").join(df.alias(\"content\"), [\"CaseNo\"],\"left\").select(\n",
    "        col(\"CaseNo\"),\n",
    "\n",
    "        #Audit appellantFamilyName\n",
    "        array(struct(*common_inputFields, lit(\"AppellantName\"))).alias(\"appellantFamilyName_inputFields\"),\n",
    "        array(struct(*common_inputValues, col(\"AppellantName\"))).alias(\"appellantFamilyName_inputValues\"),\n",
    "        col(\"content.appellantFamilyName\"),\n",
    "        lit(\"no\").alias(\"appellantFamilyName_Transformation\"),\n",
    "\n",
    "        #Audit appellantGivenNames\n",
    "        array(struct(*common_inputFields, lit(\"AppellantForenames\"))).alias(\"appellantGivenNames_inputfields\"),\n",
    "        array(struct(*common_inputValues, col(\"AppellantForenames\"))).alias(\"appellantGivenNames_inputvalues\"),\n",
    "        col(\"content.appellantGivenNames\"),\n",
    "        lit(\"no\").alias(\"appellantGivenNames_Transformation\"),\n",
    "\n",
    "        #Audit appellantNameForDisplay\n",
    "        array(struct(*common_inputFields,lit(\"AppellantName\"), lit(\"AppellantForenames\"))).alias(\"appellantNameForDisplay_inputfields\"),\n",
    "        array(struct(*common_inputValues,col(\"AppellantName\"), col(\"AppellantForenames\"))).alias(\"appellantNameForDisplay_inputvalues\"),\n",
    "        col(\"content.appellantNameForDisplay\"),\n",
    "        lit(\"no\").alias(\"appellantNameForDisplay_Transformation\"),\n",
    "\n",
    "        #Audit appellantDateOfBirth\n",
    "        array(struct(*common_inputFields,lit(\"BirthDate\"))).alias(\"appellantDateOfBirth_inputfields\"),\n",
    "        array(struct(*common_inputValues,col(\"BirthDate\"))).alias(\"appellantDateOfBirth_inputvalues\"),\n",
    "        col(\"content.appellantDateOfBirth\"),\n",
    "        lit(\"no\").alias(\"appellantDateOfBirth_Transformation\"),\n",
    "\n",
    "        #Audit caseNameHmctsInternal\n",
    "        array(struct(*common_inputFields,lit(\"AppellantName\"), lit(\"AppellantForenames\"))).alias(\"caseNameHmctsInternal_inputfields\"),\n",
    "        array(struct(*common_inputValues,col(\"AppellantName\"), col(\"AppellantForenames\"))).alias(\"caseNameHmctsInternal_inputvalues\"),\n",
    "        col(\"content.caseNameHmctsInternal\"),\n",
    "        lit(\"no\").alias(\"caseNameHmctsInternal_Transformation\"),\n",
    "\n",
    "        #Audit hmctsCaseNameInternal\n",
    "        array(struct(*common_inputFields,lit(\"AppellantName\"), lit(\"AppellantForenames\"))).alias(\"hmctsCaseNameInternal_inputfields\"),\n",
    "        array(struct(*common_inputValues,col(\"AppellantName\"), col(\"AppellantForenames\"))).alias(\"hmctsCaseNameInternal_inputvalues\"),\n",
    "        col(\"content.hmctsCaseNameInternal\"),\n",
    "        lit(\"no\").alias(\"hmctsCaseNameInternal_Transformation\"),\n",
    "\n",
    "    )\n",
    "    \n",
    "    return df, df_audit\n",
    "\n",
    "# silver_m1 = spark.table(\"ariadm_active_appeals.silver_appealcase_detail\").filter(col(\"dv_targetState\") == lit(AppealState)).distinct()\n",
    "# silver_m2 =  spark.table(\"ariadm_active_appeals.silver_caseapplicant_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "# df, df_audit = appellantDetails(silver_m1,silver_m2)\n",
    "# display(df_audit)\n",
    "# # df_audit.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "796671d8-9f79-437f-8c41-ef87273a34df",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1752364743928}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "Function: mainPaymentPendingJsonGenerator"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, StructType, ArrayType, MapType\n",
    "\n",
    "def mainPaymentPending(silver_m1,silver_m2,silver_m3):\n",
    "\n",
    "    AppealState = \"paymentPending\"\n",
    "\n",
    "    # Aggregate details\n",
    "    AppealType_df, AppealType_df_audit = appealType(silver_m1)\n",
    "    # grouped_transaction = TransactionDetails(silver_m4)\n",
    "    caseData_df, caseData_df_audit= caseData(silver_m1, silver_m3)\n",
    "    appellantDetails_df, appellantDetails_df_audit = appellantDetails(silver_m1,silver_m2)\n",
    "    legalRepDetails_df, legalRepDetails_df_audit = legalRepDetails(silver_m1)\n",
    "\n",
    "    # Join all aggregated data with Appeal Case Details\n",
    "    df_combined = AppealType_df.join(caseData_df, on=\"CaseNo\", how=\"left\"\n",
    "                                        ).join(legalRepDetails_df, on=\"CaseNo\", how=\"left\"\n",
    "                                        ).join(appellantDetails_df, on=\"CaseNo\", how=\"left\")\n",
    "\n",
    "\n",
    "    # Join all aggregated data with Appeal Case Details\n",
    "    df_combined_audit = AppealType_df_audit.join(caseData_df_audit, on=\"CaseNo\", how=\"left\"\n",
    "                                            ).join(legalRepDetails_df_audit, on=\"CaseNo\", how=\"left\"\n",
    "                                            ).join(appellantDetails_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "    \n",
    "    Datetime_name = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "    # Create JSON and filename and OMit columns that are with null values\n",
    "    df_final = df_combined.withColumn(\n",
    "        \"JSON_Content\", to_json(struct(*df_combined.drop(col(\"CaseNo\")).columns))\n",
    "    ).withColumn(\n",
    "        \"JSON_File_name\", concat(lit(f\"{gold_outputs}/{Datetime_name}/JSON/APPEALS_\"), regexp_replace(col(\"CaseNo\"), \"/\", \"_\"), lit(\".json\"))\n",
    "    )\n",
    "    \n",
    "    return df_final, df_combined_audit\n",
    "\n",
    "# silver_m1 = spark.table(\"ariadm_active_appeals.silver_appealcase_detail\").filter(col(\"dv_targetState\") == lit(AppealState)).distinct()\n",
    "# silver_m2 =  spark.table(\"ariadm_active_appeals.silver_caseapplicant_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "# silver_m3 = spark.table(\"ariadm_active_appeals.silver_status_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "# silver_m5 = spark.table(\"ariadm_active_appeals.silver_link_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "\n",
    "# df_final, df_audit = mainPaymentPending(silver_m1, silver_m3,silver_m5)\n",
    "# display(df_audit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd194be7-d459-40fb-b7fb-e1754f659817",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Function: Upload  and Blob Client Connection Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02e471dd-c9a6-42a9-8bfa-0225e92f2ad4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Secret Retrieval for Database Connection"
    }
   },
   "outputs": [],
   "source": [
    "secret = dbutils.secrets.get(KeyVault_name, \"CURATED-sbox-SAS-TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87a18b1c-66e9-473e-9527-d9b1d1417984",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Azure Blob Storage Connection Setup in Python"
    }
   },
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "import os\n",
    "\n",
    "# Set up the BlobServiceClient with your connection string\n",
    "connection_string = secret\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "# Specify the container name\n",
    "container_name = \"gold\"\n",
    "container_client = blob_service_client.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0491f238-9f10-4d11-9bc6-3f76111c29d1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: Format Dates for UploadBlob Storage"
    }
   },
   "outputs": [],
   "source": [
    "# Upload HTML to Azure Blob Storage\n",
    "def upload_to_blob(file_name, file_content):\n",
    "    try:\n",
    "        # blob_client = container_client.get_blob_client(f\"{gold_outputs}/HTML/{file_name}\")\n",
    "        blob_client = container_client.get_blob_client(f\"{file_name}\")\n",
    "        blob_client.upload_blob(file_content, overwrite=True)\n",
    "        return \"success\"\n",
    "    except Exception as e:\n",
    "        return f\"error: {str(e)}\"\n",
    "\n",
    "# Register the upload function as a UDF\n",
    "upload_udf = udf(upload_to_blob)\n",
    "\n",
    "# df_with_upload_status = df_final.withColumn(\n",
    "#     \"Status\", upload_udf(col(\"JSON_File_name\"), col(\"JSON_Content\"))\n",
    "# )\n",
    "\n",
    "# display(df_with_upload_status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ee255ab-a380-4564-b454-2c10e65707a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Gold Outputs and Tracking DLT Table Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3966a5d7-de3a-467e-b1ed-04809e2d256b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![DQValidation.png](./Images/DQValidation.png \"DQValidation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fce04fc8-6c49-48ac-bd21-f98b972f711c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Expectations collection"
    }
   },
   "outputs": [],
   "source": [
    "# Define a dictionary to hold data quality checks\n",
    "checks = {}\n",
    "\n",
    "# ##############################\n",
    "# # ARIADM-669 (appealType)\n",
    "# ##############################\n",
    "# checks[\"valid_appealReferenceNumber_not_null\"] = \"(appealReferenceNumber IS NOT NULL)\"\n",
    "\n",
    "# ##############################\n",
    "# # ARIADM-671 (appealType)\n",
    "# ##############################\n",
    "# checks[\"valid_appealtype_in_allowed_values\"] = (\n",
    "#     \"(AppealType IN ('refusalOfHumanRights', 'refusalOfEu', 'deprivation', 'protection', 'revocationOfProtection', 'euSettlementScheme'))\"\n",
    "# )\n",
    "# checks[\"valid_hmctsCaseCategory_not_null\"] = \"(hmctsCaseCategory IS NOT NULL)\"\n",
    "# checks[\"valid_appealTypeDescription_not_null\"] = \"(appealTypeDescription IS NOT NULL)\"\n",
    "# # Null Values as accepted values as where Representation = AIP\n",
    "# checks[\"valid_caseManagementCategory_code_in_list_items\"] = \"\"\"\n",
    "# (\n",
    "#   caseManagementCategory.value.code IS NULL OR\n",
    "#   ARRAY_CONTAINS(\n",
    "#     TRANSFORM(caseManagementCategory.list_items, x -> x.code),\n",
    "#     caseManagementCategory.value.code\n",
    "#   )\n",
    "# )\n",
    "# \"\"\"\n",
    "# checks[\"valid_caseManagementCategory_label_in_list_items\"] = \"\"\"\n",
    "# (\n",
    "#   caseManagementCategory.value.label IS NULL OR\n",
    "#   ARRAY_CONTAINS(\n",
    "#     TRANSFORM(caseManagementCategory.list_items, x -> x.label),\n",
    "#     caseManagementCategory.value.label\n",
    "#   )\n",
    "# )\n",
    "# \"\"\"\n",
    "\n",
    "# ##############################\n",
    "# # ARIADM-673 (caseData)\n",
    "\n",
    "# # \\d is a regular expression (regex) metacharacter that matches any single digit from 0 to 9.\n",
    "# # \"yyyy-mm-ddTHH:mm:ssZ\" r'^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}Z$'\" for ISO 8601 datetime format\n",
    "# # \"yyyy-MM-dd\" r'^\\d{4}-\\d{2}-\\d{2}$' for ISO 8601 date format\n",
    "# ##############################\n",
    "# checks[\"valid_appealSubmissionDate_format\"] = (\n",
    "#     \"(appealSubmissionDate RLIKE r'^\\\\d{4}-\\\\d{2}-\\\\d{2}$')\"\n",
    "# )\n",
    "# checks[\"valid_appealSubmissionInternalDate_format\"] = (\n",
    "#     \"(appealSubmissionInternalDate RLIKE r'^\\\\d{4}-\\\\d{2}-\\\\d{2}$')\"\n",
    "# )\n",
    "# checks[\"valid_tribunalReceivedDate_format\"] = (\n",
    "#     \"(tribunalReceivedDate RLIKE r'^\\\\d{4}-\\\\d{2}-\\\\d{2}$')\"\n",
    "# )\n",
    "\n",
    "# ##############################\n",
    "# # ARIADM-675 (caseData)\n",
    "# ##############################\n",
    "# checks[\"valid_appellantsRepresentation_yes_no\"] = (\n",
    "#     \"(appellantsRepresentation IS NOT NULL AND appellantsRepresentation IN ('Yes', 'No'))\"\n",
    "# )\n",
    "# checks[\"valid_submissionOutOfTime_yes_no\"] = (\n",
    "#     \"(submissionOutOfTime IS NOT NULL AND submissionOutOfTime IN ('Yes', 'No'))\"\n",
    "# )\n",
    "# checks[\"valid_recordedOutOfTimeDecision_yes_no_or_null\"] = (\n",
    "#     \"(recordedOutOfTimeDecision IS NULL OR recordedOutOfTimeDecision IN ('Yes', 'No'))\"\n",
    "# )\n",
    "# checks[\"valid_applicationOutOfTimeExplanation_yes_no_or_null\"] = (\n",
    "#     \"(applicationOutOfTimeExplanation IS NULL OR applicationOutOfTimeExplanation IN ('Yes', 'No'))\"\n",
    "# )\n",
    "\n",
    "# ##############################\n",
    "# # ARIADM-708 (CaseData)\n",
    "# ##############################\n",
    "# checks[\"valid_hearingCentre_in_allowed_values\"] = \"\"\"\n",
    "# (\n",
    "#     hearingCentre IN ('taylorHouse', 'newport', 'newcastle', 'manchester', 'hattonCross', \n",
    "#     'glasgow', 'bradford', 'birmingham', 'arnhemHouse', 'crownHouse', 'harmondsworth', \n",
    "#     'yarlsWood', 'remoteHearing', 'decisionWithoutHearing')\n",
    "# )\n",
    "# \"\"\"\n",
    "# checks[\"valid_staffLocation_not_null\"] = \"(staffLocation IS NOT NULL)\"\n",
    "# checks[\"valid_caseManagementLocation_region_and_baseLocation\"] = \"\"\"\n",
    "# (\n",
    "#   caseManagementLocation.region = '1' AND\n",
    "#   caseManagementLocation.baseLocation IN (\n",
    "#     '231596', '698118', '366559', '386417', '512401',\n",
    "#     '227101', '765324', '366796', '324339', '649000',\n",
    "#     '999971', '420587', '28837'\n",
    "#   )\n",
    "# )\n",
    "# \"\"\"\n",
    "# checks[\"valid_hearingCentreDynamicList_code_in_list_items\"] = \"\"\"\n",
    "# (\n",
    "#   hearingCentreDynamicList.value.code IS NOT NULL AND\n",
    "#   ARRAY_CONTAINS(\n",
    "#     TRANSFORM(hearingCentreDynamicList.list_items, x -> x.code),\n",
    "#     hearingCentreDynamicList.value.code\n",
    "#   )\n",
    "# )\n",
    "# \"\"\"\n",
    "# checks[\"valid_hearingCentreDynamicList_label_in_list_items\"] = \"\"\"\n",
    "# (\n",
    "#   hearingCentreDynamicList.value.label IS NOT NULL AND\n",
    "#   ARRAY_CONTAINS(\n",
    "#     TRANSFORM(hearingCentreDynamicList.list_items, x -> x.label),\n",
    "#     hearingCentreDynamicList.value.label\n",
    "#   )\n",
    "# )\n",
    "# \"\"\"\n",
    "# checks[\"valid_caseManagementLocationRefData_code_in_list_items\"] = \"\"\"\n",
    "# (\n",
    "#   caseManagementLocationRefData.baseLocation.value.code IS NOT NULL AND\n",
    "#   ARRAY_CONTAINS(\n",
    "#     TRANSFORM(caseManagementLocationRefData.baseLocation.list_items, x -> x.code),\n",
    "#     caseManagementLocationRefData.baseLocation.value.code\n",
    "#   )\n",
    "# )\n",
    "# \"\"\"\n",
    "# checks[\"valid_caseManagementLocationRefData_label_in_list_items\"] = \"\"\"\n",
    "# (\n",
    "#   caseManagementLocationRefData.baseLocation.value.label IS NOT NULL AND\n",
    "#   ARRAY_CONTAINS(\n",
    "#     TRANSFORM(caseManagementLocationRefData.baseLocation.list_items, x -> x.label),\n",
    "#     caseManagementLocationRefData.baseLocation.value.label\n",
    "#   )\n",
    "# )\n",
    "# \"\"\"\n",
    "# checks[\"valid_selectedHearingCentreRefData_not_null\"] = \"(selectedHearingCentreRefData IS NOT NULL)\"\n",
    "\n",
    "\n",
    "# ##############################\n",
    "# # ARIADM-768 (legalRepDetails)\n",
    "# ##############################\n",
    "\n",
    "checks[\"valid_legalRepGivenName_not_null\"] = \"((legalRepGivenName iS NULL) |((legalRepGivenName IS NOT NULL) AND (dv_representation = 'LR')))\"\n",
    "\n",
    "checks[\"valid_legalRepFamilyNamePaperJ_not_null\"] = \"((legalRepGivenName iS NULL) | ((legalRepFamilyNamePaperJ IS NOT NULL) AND (dv_representation = 'LR')))\"\n",
    "\n",
    "checks[\"valid_legalRepCompanyPaperJ_not_null\"] = \"((legalRepGivenName iS NULL) | ((legalRepCompanyPaperJ IS NOT NULL) AND (dv_representation = 'LR')))\"\n",
    "\n",
    "##############################\n",
    "# ARIADM-756 (appellantDetails)\n",
    "##############################\n",
    "checks[\"valid_appellantFamilyName_not_null\"] = \"(appellantFamilyName IS NOT NULL)\"\n",
    "checks[\"valid_appellantGivenNames_not_null\"] = \"(appellantGivenNames IS NOT NULL)\"\n",
    "checks[\"valid_appellantNameForDisplay_not_null\"] = \"(appellantNameForDisplay IS NOT NULL)\"\n",
    "\n",
    "checks[\"valid_appellantDateOfBirth_format\"] = (\n",
    "    \"(appellantDateOfBirth RLIKE r'^\\\\d{4}-\\\\d{2}-\\\\d{2}$')\"\n",
    ")\n",
    "checks[\"valid_caseNameHmctsInternal_not_null\"] = \"(caseNameHmctsInternal IS NOT NULL)\"\n",
    "checks[\"valid_hmctsCaseNameInternal_not_null\"] = \"(hmctsCaseNameInternal IS NOT NULL)\"\n",
    "\n",
    "# Combine all checks into a single string with AND conditions\n",
    "# Create a validation expression to quarantine records\n",
    "dq_rules = \"({0})\".format(\" AND \".join(checks.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e673184-66e1-4269-8c3b-c83daffe4e0a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "display DQRules"
    }
   },
   "outputs": [],
   "source": [
    "# print(dq_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a543a04d-1a94-45e8-9ba0-c5dfcb6f60f4",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1753356493477}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "validatePendingPayments"
    }
   },
   "outputs": [],
   "source": [
    "# # This is a placeholder, like a test\n",
    "# spark.sql(f\"\"\"\n",
    "# SELECT \n",
    "#   CaseNo,\n",
    "#   legalRepGivenName,legalRepFamilyNamePaperJ,legalRepFamilyNamePaperJ\n",
    "# FROM ariadm_active_appeals.stg_main_payment_pending_validation\n",
    "# -- WHERE {dq_rules}\n",
    "# \"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6742b7aa-6240-402b-9800-8ab881e416bb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Transformation: stg_payment_pending_ccd_json_generator"
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, lit, expr\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"stg_main_payment_pending_validation\",\n",
    "    comment=\"DLT table running mainPaymentPending to generate a JSON_Content column for CCD validation. Applies DLT expectations on CCD, adding is_valid to flag validation results.\",\n",
    "    path=f\"{audit_path}/stg_main_payment_pending_validation\"\n",
    ")\n",
    "@dlt.expect_all(checks)\n",
    "def stg_main_payment_pending_validation():\n",
    "    try:\n",
    "        silver_m1 = dlt.read(\"silver_appealcase_detail\").filter(col(\"dv_targetState\") == lit(AppealState)).distinct()\n",
    "        bronze_appealtype_lookup_df = dlt.read(\"bronze_appealtype\").distinct()\n",
    "        bronze_hearing_centres_lookup_df = dlt.read(\"bronze_hearing_centres\").distinct()\n",
    "        # stg_representation = dlt.read(\"stg_representation\").select(col(\"Representation\").alias(\"valid_representation\"))\n",
    "        silver_m2 = dlt.read(\"silver_caseapplicant_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_m3 = dlt.read(\"silver_status_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        # silver_m4 = dlt.read(\"silver_transaction_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_m5 = dlt.read(\"silver_link_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        # silver_m6 = dlt.read(\"silver_adjudicator_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        # silver_m7 = dlt.read(\"silver_appealcategory_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        # silver_m8 = dlt.read(\"silver_documentsreceived_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        # silver_m9 = dlt.read(\"silver_history_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "    except:\n",
    "        silver_m1 = spark.table(\"ariadm_active_appeals.silver_appealcase_detail\").filter(col(\"dv_targetState\") == lit(AppealState)).distinct()\n",
    "        bronze_appealtype_lookup_df = spark.table(\"ariadm_active_appeals.bronze_appealtype\").distinct()\n",
    "        bronze_hearing_centres_lookup_df = spark.table(\"ariadm_active_appeals.bronze_hearing_centres\").distinct()\n",
    "        # stg_representation = spark.table(\"ariadm_active_appeals.stg_representation\").select(col(\"Representation\").alias(\"valid_representation\"))\n",
    "        silver_m2 = spark.table(\"ariadm_active_appeals.silver_caseapplicant_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_m3 = spark.table(\"ariadm_active_appeals.silver_status_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        # silver_m4 = spark.table(\"ariadm_active_appeals.silver_transaction_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_m5 = spark.table(\"ariadm_active_appeals.silver_link_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        # silver_m6 = spark.table(\"ariadm_active_appeals.silver_adjudicator_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        # silver_m7 = spark.table(\"ariadm_active_appeals.silver_appealcategory_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        # silver_m8 = spark.table(\"ariadm_active_appeals.silver_documentsreceived_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        # silver_m9 = spark.table(\"ariadm_active_appeals.silver_history_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "\n",
    "    df_final,df_audit = mainPaymentPending(silver_m1,silver_m2, silver_m3)\n",
    "\n",
    "    valid_representation = silver_m1.select(col(\"CaseNo\"),col(\"dv_representation\"))\n",
    "\n",
    "    df_final = df_final.join(valid_representation, on=\"CaseNo\", how=\"left\")\n",
    "\n",
    "    df_final = df_final.withColumn(\"is_valid\", expr(dq_rules))\n",
    "\n",
    "    return df_final.drop(\"dv_representation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ee35c3c-bef2-4365-b3ab-f806bcf5f5fb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Transformation: stg_valid_payment_pending_records"
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"stg_valid_payment_pending_records\",\n",
    "    comment=\"Delta Live Gold Table with JSON content.\",\n",
    "    path=f\"{audit_path}/stg_valid_payment_pending_records\"\n",
    ")\n",
    "def stg_valid_payment_pending_records():\n",
    "    \"\"\"\n",
    "    Delta Live Table for creating and uploading JSON content for Appeals.\n",
    "    \"\"\"\n",
    "    # Load source data\n",
    "    df = dlt.read(\"stg_main_payment_pending_validation\")\n",
    "\n",
    "    df_filtered = df.filter(\n",
    "        (col(\"is_valid\") == True)\n",
    "    )\n",
    "\n",
    "    # Repartition to optimize parallelism\n",
    "    repartitioned_df = df_filtered.repartition(64)\n",
    "\n",
    "    df_with_upload_status = repartitioned_df.filter(~col(\"JSON_content\").like(\"Error%\")).withColumn(\n",
    "            \"Status\", upload_udf(col(\"JSON_File_Name\"), col(\"JSON_content\"))\n",
    "        )\n",
    "\n",
    "    # Return the DataFrame for DLT table creation\n",
    "    return df_with_upload_status.select(\"CaseNo\", \"JSON_content\",col(\"JSON_File_Name\").alias(\"File_Name\"),\"Status\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a73c1bae-add0-4280-a33f-24a2c5607f29",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Transformation: stg_invalid_payment_pending_quarantine_records"
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"stg_invalid_payment_pending_quarantine_records\",\n",
    "    comment=\"Quarantined records that failed data quality checks or JSON generation.\",\n",
    "    path=f\"{audit_path}/stg_invalid_payment_pending_quarantine_records\"\n",
    ")\n",
    "def stg_invalid_payment_pending_quarantine_records():\n",
    "\n",
    "    df = dlt.read(\"stg_main_payment_pending_validation\")\n",
    "\n",
    "    df_filtered = df.filter(\n",
    "        (col(\"is_valid\") != True)\n",
    "    ).withColumn(\"JSON_File_Name\", regexp_replace(col(\"JSON_File_Name\"), \"/JSON/\", \"/INVALID_JSON/\"))\n",
    "\n",
    "    # Repartition to optimize parallelism\n",
    "    repartitioned_df = df_filtered.repartition(64)\n",
    "\n",
    "    df_with_upload_status = repartitioned_df.filter(~col(\"JSON_content\").like(\"Error%\")).withColumn(\n",
    "            \"Status\", upload_udf(col(\"JSON_File_Name\"), col(\"JSON_content\"))\n",
    "        )\n",
    "\n",
    "    return df_with_upload_status.select(\"CaseNo\", \"JSON_content\",col(\"JSON_File_Name\").alias(\"File_Name\"),\"Status\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "729db0f8-4867-420d-8995-a25333e2a8ca",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Transformation: apl_active_payment_pending_cr_audit_table"
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, lit, expr\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"apl_active_payment_pending_cr_audit_table\",\n",
    "    comment=\"DLT table Covers 4.2 Silver layer LLD requirements: Audits CCD attributes, input field values, derived values, and all columns for validation and traceability.\",\n",
    "    path=f\"{audit_path}/apl_active_payment_pending_cr_audit_table\"\n",
    ")\n",
    "def apl_active_payment_pending_cr_audit_table():\n",
    "    try:\n",
    "        silver_m1 = dlt.read(\"silver_appealcase_detail\").filter(col(\"dv_targetState\") == lit(AppealState)).distinct()\n",
    "        silver_m2 = dlt.read(\"silver_caseapplicant_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        bronze_appealtype_lookup_df = dlt.read(\"bronze_appealtype\").distinct()\n",
    "        bronze_hearing_centres_lookup_df = dlt.read(\"bronze_hearing_centres\").distinct()\n",
    "        silver_m3 = dlt.read(\"silver_status_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "      \n",
    "    except:\n",
    "        silver_m1 = spark.table(\"ariadm_active_appeals.silver_appealcase_detail\").filter(col(\"dv_targetState\") == lit(AppealState)).distinct()\n",
    "        silver_m2 = spark.table(\"ariadm_active_appeals.silver_caseapplicant_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        bronze_appealtype_lookup_df = spark.table(\"ariadm_active_appeals.bronze_appealtype\").distinct()\n",
    "        bronze_hearing_centres_lookup_df = spark.table(\"ariadm_active_appeals.bronze_hearing_centres\").distinct()\n",
    "        silver_m3 = spark.table(\"ariadm_active_appeals.silver_status_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "       \n",
    "\n",
    "    df_final,df_audit = mainPaymentPending(silver_m1,silver_m2, silver_m3)\n",
    "\n",
    "    return df_audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed72e9c7-2621-4707-84f7-b4985beb9df4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.exit(\"Notebook completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89fdf409-78a7-47f2-bbcf-d4b001ea7051",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9edb7ba9-63ab-47ee-ac6a-245d6f2c0dc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e6ef5b8-5f04-459d-999f-4192ad88e9aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# drop schema ariadm_active_appeals cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbeaf641-013a-4d3e-9c9a-b60db8212434",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# first_row = df_final.filter(df_final[\"CaseNo\"] == \"HU/00035/2017\").select(\"JSON_Content\").first()\n",
    "# json_content = first_row[\"JSON_Content\"]\n",
    "# parsed_json = json.loads(json_content)\n",
    "# display(parsed_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca8fd74e-8a0b-4196-b1ff-7cfcc6eda700",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Check for Duplicates in Silver Appeal Tables"
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import col, count\n",
    "\n",
    "# # Reading tables into DataFrames and labeling as M1 to M9\n",
    "# M1 = spark.table(\"ariadm_active_appeals.silver_appealcase_detail\").distinct()\n",
    "# M2 = spark.table(\"ariadm_active_appeals.silver_caseapplicant_detail\")\n",
    "# M3 = spark.table(\"ariadm_active_appeals.silver_status_detail\")\n",
    "# M4 = spark.table(\"ariadm_active_appeals.silver_transaction_detail\")\n",
    "# M5 = spark.table(\"ariadm_active_appeals.silver_link_detail\")\n",
    "# M6 = spark.table(\"ariadm_active_appeals.silver_adjudicator_detail\")\n",
    "# M7 = spark.table(\"ariadm_active_appeals.silver_appealcategory_detail\")\n",
    "# M8 = spark.table(\"ariadm_active_appeals.silver_documentsreceived_detail\")\n",
    "# M9 = spark.table(\"ariadm_active_appeals.silver_history_detail\")\n",
    "\n",
    "# # Function to check for duplicates\n",
    "# def check_duplicates(df, table_name):\n",
    "#     duplicates = df.groupBy(\"caseno\").agg(count(\"*\").alias(\"count\")).filter(col(\"count\") > 1)\n",
    "#     if duplicates.count() > 0:\n",
    "#         displayHTML(f\"<span style='color:red;'>&#x274C; Table {table_name} has duplicates.</span>\")\n",
    "#     else:\n",
    "#         displayHTML(f\"<span style='color:green;'>&#x2705; Table {table_name} has no duplicates.</span>\")\n",
    "\n",
    "# # Check for duplicates in each table\n",
    "# check_duplicates(M1, \"silver_appealcase_detail\")\n",
    "# check_duplicates(M2, \"silver_caseapplicant_detail\")\n",
    "# check_duplicates(M3, \"silver_status_detail\")\n",
    "# check_duplicates(M4, \"silver_transaction_detail\")\n",
    "# check_duplicates(M5, \"silver_link_detail\")\n",
    "# check_duplicates(M6, \"silver_adjudicator_detail\")\n",
    "# check_duplicates(M7, \"silver_appealcategory_detail\")\n",
    "# check_duplicates(M8, \"silver_documentsreceived_detail\")\n",
    "# check_duplicates(M9, \"silver_history_detail\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8887805921781523,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "GOLD_PAYMENT_PENDING_JSON",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
