{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "971d01f4-9654-4671-91ff-b2b6e49d88bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "import json\n",
    "from  itertools import islice\n",
    "import numpy as np\n",
    "# from pyspark.sql.functions import col, decode, split, element_at,udf\n",
    "import logging\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "516c9e72-cbd7-433b-9fc2-924a96f0bc08",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Extract Environment Details and Generate KeyVault Name"
    }
   },
   "outputs": [],
   "source": [
    "config = spark.read.option(\"multiline\", \"true\").json(\"dbfs:/configs/config.json\")\n",
    "env_name = config.first()[\"env\"].strip().lower()\n",
    "lz_key = config.first()[\"lz_key\"].strip().lower()\n",
    "\n",
    "print(f\"env_code: {lz_key}\")  # This won't be redacted\n",
    "print(f\"env_name: {env_name}\")  # This won't be redacted\n",
    "\n",
    "KeyVault_name = f\"ingest{lz_key}-meta002-{env_name}\"\n",
    "print(f\"KeyVault_name: {KeyVault_name}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "706c1521-597b-41ae-8add-61dc22cb526f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Configure SP OAuth"
    }
   },
   "outputs": [],
   "source": [
    "KeyVault_name = f\"ingest{lz_key}-meta002-{env_name}\"\n",
    "\n",
    "# Service principal credentials\n",
    "client_id = dbutils.secrets.get(KeyVault_name, \"SERVICE-PRINCIPLE-CLIENT-ID\")\n",
    "client_secret = dbutils.secrets.get(KeyVault_name, \"SERVICE-PRINCIPLE-CLIENT-SECRET\")\n",
    "tenant_id = dbutils.secrets.get(KeyVault_name, \"SERVICE-PRINCIPLE-TENANT-ID\")\n",
    "\n",
    "# Storage account names\n",
    "curated_storage = f\"ingest{lz_key}curated{env_name}\"\n",
    "\n",
    "# Spark config for curated storage (Delta table)\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{curated_storage}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{curated_storage}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{curated_storage}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{curated_storage}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{curated_storage}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca5d0732-52ee-47db-8fc2-e2cd9efaac84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Read in HTML and JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a41ea18-a1ef-4126-9f92-363cc05a0761",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# eh_kv_secret = dbutils.secrets.get(scope=KeyVault_name, key=\"evh-namespace-connection-string\")\n",
    "eh_kv_secret = dbutils.secrets.get(scope=KeyVault_name, key=\"RootManageSharedAccessKey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab9b9b97-9c5d-477d-a68a-b3f8044b3ae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "gold_mount = f\"abfss://gold@ingest{lz_key}curated{env_name}.dfs.core.windows.net/ARIADM/ARM/JOH\"\n",
    "# topic = f\"evh-td-pub-dev-uks-dlrm-01\"\n",
    "# topic = f\"evh-td-pub-00-uks-dlrm-01\"\n",
    "topic = f\"evh-joh-pub-{lz_key}-uks-dlrm-01\"\n",
    "# dropzone_mount = f\"/mnt/dropzoneariatd/TD/\"\n",
    "audit_path = f\"abfss://silver@ingest{lz_key}curated{env_name}.dfs.core.windows.net/ARIADM/ARM/AUDIT/JOH/joh_pub_audit_table\"\n",
    "\n",
    "dbutils.widgets.dropdown(\n",
    "    name='file_types', \n",
    "    defaultValue='html,json', \n",
    "    choices=[\n",
    "        'html,json', \n",
    "        'a360'\n",
    "    ]\n",
    ")\n",
    "file_types = dbutils.widgets.get('file_types')\n",
    "\n",
    "\n",
    "display(f\"Gold Mount: {gold_mount}\", f\"Topic: {topic}\", \n",
    "        # f\"Dropzone Mount: {dropzone_mount}\",\n",
    "         f\"File Types: {file_types}\", f\"Audit Path: {audit_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "625208fc-4823-45f7-8e56-5338370ef88a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, element_at\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark import SparkContext\n",
    "\n",
    "\n",
    "\n",
    "# Event Hub configurations\n",
    "# eventhubs_hostname = \"sbox-dlrm-eventhub-ns.servicebus.windows.net:9093\"\n",
    "eventhubs_hostname = f\"ingest{lz_key}-integration-eventHubNamespace001-{env_name}.servicebus.windows.net:9093\"\n",
    "conf = {\n",
    "    'bootstrap.servers': eventhubs_hostname,\n",
    "    'security.protocol': 'SASL_SSL',\n",
    "    'sasl.mechanism': 'PLAIN',\n",
    "    'sasl.username': '$ConnectionString',\n",
    "    # 'sasl.password': \"Endpoint=sb://sbox-dlrm-eventhub-ns.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=\" ,\n",
    "    'sasl.password': eh_kv_secret,\n",
    "    'retries': 5,                     # Increased retries\n",
    "    'enable.idempotence': True        # Enable idempotent producer\n",
    "}\n",
    "broadcast_conf = sc.broadcast(conf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24c2aef4-dec0-43e7-8d12-c118e0c7a812",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read and prepare data HTML files\n",
    "# json_mount = '/mnt/ingest00curatedsboxgold/ARIADM/ARM/ARIATD/'\n",
    "\n",
    "from pyspark.sql.functions import concat, lit, when, col, upper\n",
    "\n",
    "binary_df = spark.read.format('binaryFile') \\\n",
    "                     .option('pathGlobFilter', f'*.{{{file_types}}}') \\\n",
    "                     .option('recursiveFileLookup', 'true') \\\n",
    "                     .load(gold_mount)\n",
    "\n",
    "\n",
    "\n",
    "html_df = binary_df.withColumn(\"content_str\", decode(col('content'), 'utf-8')) \\\n",
    "                   .withColumn('file_path', element_at(split(col('path'), '/'), -1))\n",
    "html_df = html_df.select('content_str','file_path')\n",
    "\n",
    "html_df = html_df.withColumn(\n",
    "    \"suffix\",\n",
    "    when(col(\"file_path\").endswith(\"html\"), lit(\"HTML\"))\n",
    "    .when(col(\"file_path\").endswith(\"json\"), lit(\"JSON\"))\n",
    "    .when(col(\"file_path\").endswith(\"a360\"), lit(\"A360\"))\n",
    ").withColumn(\n",
    "    \"blob_url\",\n",
    "    concat(\n",
    "        lit(\"https://ingest\"),\n",
    "        lit(lz_key),\n",
    "        lit(\"curated\"),\n",
    "        lit(env_name),\n",
    "        lit(f\".blob.core.windows.net/gold/ARIADM/ARM/JOH/\"),\n",
    "        upper(col(\"suffix\")), lit(\"/\"),\n",
    "        col(\"file_path\")\n",
    "    )\n",
    ").drop(\"content_str\")\n",
    "\n",
    "\n",
    "html_df.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d99f4b22-2d4c-4550-9959-219d94d18973",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Send to EventHubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e6df5e0-b6ae-481f-a221-a7bcd2a64141",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Repartition based on cluster resources\n",
    "num_spark_partitions =  8\n",
    "optimized_html_df = html_df.repartition(num_spark_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2033675-a04b-4f90-95f1-c3103ba4f656",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optimized_html_df.filter(\"file_path is null OR blob_url is null\").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cacfef9-1522-43f8-ad26-82864f1c6bce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_partition(partition):\n",
    "    import logging\n",
    "    from confluent_kafka import Producer\n",
    "    from datetime import datetime\n",
    "\n",
    "    # Initialize logger\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger('KafkaProducer')\n",
    "    \n",
    "    failure_list = []\n",
    "    success_list = []\n",
    "    results = []\n",
    "\n",
    "    # Initialize producer\n",
    "    producer = Producer(**broadcast_conf.value)\n",
    "\n",
    "    def delivery_report(err, msg):\n",
    "        key_str = msg.key().decode('utf-8') if msg.key() is not None else \"Unknown\"\n",
    "        if err is not None:\n",
    "            err_msg = str(err)\n",
    "            logger.error(f\"Message delivery failed for key {key_str}: {err}\")\n",
    "            failure_list.append((key_str, \"failure\", err_msg, datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "        else:\n",
    "            success_list.append((key_str, \"success\", \"\", datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "\n",
    "    for row in partition:\n",
    "\n",
    "        producer.poll(0)  # <-- minimal fix added to avoid producer buffer full error\n",
    "\n",
    "        # Check if blob_url and file_path exist\n",
    "        if row.file_path is None or row.blob_url is None:\n",
    "            logger.warning(f\"Skipping row with missing file_path/blob_url: {row}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Send blob_url as the message value\n",
    "            value = row.blob_url.encode('utf-8')\n",
    "            producer.produce(\n",
    "                topic=topic,\n",
    "                key=row.file_path.encode('utf-8'),\n",
    "                value=value,\n",
    "                callback=delivery_report\n",
    "            )\n",
    "\n",
    "        except BufferError:\n",
    "            logger.error(\"Producer buffer full. Polling for events.\")\n",
    "            producer.poll(1)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error during production: {e}\")\n",
    "            failure_list.append((row.file_path, \"failure\", str(e), datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "\n",
    "    try:\n",
    "        producer.flush()\n",
    "        logger.info(\"Producer flushed successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error during flush: {e}\")\n",
    "\n",
    "    results.extend(success_list)\n",
    "    results.extend(failure_list)\n",
    "\n",
    "    return results  # Return list instead of using yield\n",
    "\n",
    "\n",
    "# Schema for result DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"file_name\", StringType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"error_message\", StringType(), True),\n",
    "    StructField(\"timestamp\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Apply optimized processing\n",
    "result_rdd = optimized_html_df.rdd.mapPartitions(process_partition)  # <-- no .collect()\n",
    "\n",
    "# Create DataFrame and show results\n",
    "result_df = spark.createDataFrame(result_rdd, schema)\n",
    "display(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ea0014f-d416-470f-9d74-15337a6d4b32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Display failed files\n",
    "\n",
    "failed_files = result_df.filter(col(\"status\") == \"failure\")\n",
    "\n",
    "display(failed_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aa3c06f-9a2c-4469-93e6-626054d5a56a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_df.write.format(\"delta\").mode(\"append\").save(audit_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "330238fb-64de-4c67-ac49-4aa4e3e780db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "html_count = result_df.filter(lower(col(\"file_name\")).endswith(\".html\")).distinct().count()\n",
    "json_count = result_df.filter(lower(col(\"file_name\")).endswith(\".json\")).distinct().count()\n",
    "a360_count = result_df.filter(lower(col(\"file_name\")).endswith(\".a360\")).distinct().count()\n",
    "display({\"html_count\": html_count, \"json_count\": json_count, \"a360_count\": a360_count})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87b72610-b1b4-488d-bc99-bcea706c35d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "successful_files =  result_df.filter(col(\"status\") == \"success\").count()\n",
    "failed_files =  result_df.filter(col(\"status\") == \"failure\").count()\n",
    "\n",
    "dbutils.notebook.exit({\"successful_files\": successful_files, \"failed_files\": failed_files})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "388dbe66-2e57-4a7b-acb8-4022c0543656",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "005c72d9-50f9-4f26-a2e3-fb53ae181c7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "212d034a-113f-4f90-8abb-bca8d919404f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "html_df.alias(\"html\").join(result_df.alias(\"result\"),col(\"file_name\") == col(\"file_path\"),\"outer\").filter(col(\"result.file_name\").isNull()).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89935fc2-c4b1-4736-b51b-601e0ffbc989",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower\n",
    "\n",
    "html_count = result_df.filter(lower(col(\"file_path\")).endswith(\".html\")).count()\n",
    "json_count = result_df.filter(lower(col(\"file_path\")).endswith(\".json\")).count()\n",
    "\n",
    "display({\"html_count\": html_count, \"json_count\": json_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f84c224-484b-4f87-a992-86d7c64b91c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower\n",
    "\n",
    "html_count = html_df.filter(lower(col(\"file_path\")).endswith(\".html\")).count()\n",
    "json_count = html_df.filter(lower(col(\"file_path\")).endswith(\".json\")).count()\n",
    "\n",
    "display({\"html_count\": html_count, \"json_count\": json_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37410b8b-ee80-4bda-8136-c3bd86674ecf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower\n",
    "\n",
    "html_count = html_df.select(\"file_path\").filter(lower(col(\"file_path\")).endswith(\".html\")).distinct().count()\n",
    "json_count = html_df.select(\"file_path\").filter(lower(col(\"file_path\")).endswith(\".json\")).distinct().count()\n",
    "\n",
    "display({\"html_count\": html_count, \"json_count\": json_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b635f5f-e21d-4607-9ef4-53c187aecb9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dropzone_mount = f\"/mnt/dropzoneariatd/TD/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "842332e1-349f-429b-89c2-45d0c34f7b31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.fs.ls(\"/mnt/dropzoneariatd/ARIATD/submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "757f2c8e-c06e-4421-813c-ab8c7af337d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import col, from_unixtime\n",
    "\n",
    "# files_df = spark.createDataFrame(dbutils.fs.ls(f\"{dropzone_mount}submission/\"))\n",
    "# files_df = files_df.withColumn(\"modificationTime\", from_unixtime(col(\"modificationTime\") / 1000).cast(\"timestamp\"))\n",
    "\n",
    "# display(files_df.orderBy(col(\"modificationTime\").desc()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62f21d0b-7f5a-4be5-b590-4fa6993c18f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# json_count = files_df.filter(col(\"path\").endswith(\".json\")).count()\n",
    "# html_count = files_df.filter(col(\"path\").endswith(\".html\")).count()\n",
    "# a360_count = files_df.filter(col(\"path\").endswith(\".a360\")).count()\n",
    "\n",
    "# display(json_count)\n",
    "# display(html_count)\n",
    "# display(a360_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3ed727c-17ed-40ef-bef0-875341ce2246",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Read and prepare data HTML files\n",
    "# t_json_mount = f'{dropzone_mount}response/'\n",
    "# t_binary_df = spark.read.format('binaryFile') \\\n",
    "#                      .option('pathGlobFilter', '*.rsp') \\\n",
    "#                      .option('recursiveFileLookup', 'true') \\\n",
    "#                      .load(t_json_mount)\n",
    " \n",
    " \n",
    " \n",
    "# t_html_df = t_binary_df.withColumn(\"content_str\", decode(col('content'), 'utf-8')) \\\n",
    "#                    .withColumn('file_path', element_at(split(col('path'), '/'), -1))\n",
    "# t_html_df = t_html_df.select('content_str','file_path')\n",
    " \n",
    "# display(t_html_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc49391e-606c-4ae9-8346-8145337b8ef7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "html_df.select(\"suffix\").filter(col(\"suffix\") == \"HTML\").count()\n",
    "\n",
    "\n",
    "\n",
    " \n",
    " \n",
    "# 537797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fc8b6a3-3708-4d8d-b37c-28a6cbba156d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "html_df.select(\"suffix\").filter(col(\"suffix\") == \"JSON\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa0e92a3-4361-41c0-ad12-58c1ba690fe4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select *\n",
    "from ariadm_arm_td.stg_create_td_iris_a360_content\n",
    "where client_identifier in ('EA/00007/2023',\n",
    "'EA/00002/2023',\n",
    "'EA/00006/2023')\n",
    "-- -- where status != 'Successful creating JSON Content'\n",
    "-- where Caseno not in (select CaseNo from  ariadm_arm_td.gold_td_iris_with_json )\n",
    "-- -- group by status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71f0ed1c-65cb-4d93-91c2-3e51b92c0aa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select *\n",
    "from ariadm_arm_td.stg_create_td_iris_json_content\n",
    "-- where status != 'Successful creating JSON Content'\n",
    "where Caseno not in (select CaseNo from  ariadm_arm_td.gold_td_iris_with_json )\n",
    "-- group by status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fcd1c15-9dd7-4ee8-8676-02d079bc113f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select *\n",
    "from ariadm_arm_td.stg_create_td_iris_html_content\n",
    "-- where status != 'Successful creating JSON Content'\n",
    "where Caseno not in (select CaseNo from  ariadm_arm_td.gold_td_iris_with_html )\n",
    "-- group by status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e717438-6028-4ef0-8db4-e9ad54ac9d7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select status, count(*) as count\n",
    "from ariadm_arm_td.gold_td_iris_with_html\n",
    "-- where status != 'Successful creating JSON Content'\n",
    "group by status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4085d8f0-107d-4fa8-865a-d6e92ad41bc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select status, count(*) as count\n",
    "from ariadm_arm_td.stg_create_td_iris_html_content\n",
    "-- where status != 'Successful creating JSON Content'\n",
    "group by status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed08e198-9b60-4325-89bc-487b340de854",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select status,Caseno, count(*) as count\n",
    "from ariadm_arm_td.stg_create_td_iris_json_content\n",
    "-- where status != 'Successful creating JSON Content'\n",
    "group by all\n",
    "having count(*) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8aa614e-84e6-45cc-a830-b4a2ab5add0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Container and path for storing Delta table (in curated storage account)\n",
    "data_path = f\"abfss://silver@ingest{lz_key}curated{env_name}.dfs.core.windows.net/ARIADM/ARM/AUDIT/TD/td_ack_audit_table\"\n",
    "df = spark.read.format(\"delta\").load(data_path)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "028a83a0-1233-4be0-8013-8d1b25b3070b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.select(\"filename\").distinct().count()\n",
    "# 1075576\n",
    "# 1075278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "282cab0e-ac61-443b-9503-a55b5c17ff35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "KeyVault_name = f\"ingest{lz_key}-meta002-{env_name}\"\n",
    "\n",
    "# Service principal credentials\n",
    "client_id = dbutils.secrets.get(KeyVault_name, \"SERVICE-PRINCIPLE-CLIENT-ID\")\n",
    "client_secret = dbutils.secrets.get(KeyVault_name, \"SERVICE-PRINCIPLE-CLIENT-SECRET\")\n",
    "tenant_id = dbutils.secrets.get(KeyVault_name, \"SERVICE-PRINCIPLE-TENANT-ID\")\n",
    "\n",
    "# Storage account names\n",
    "curated_storage = f\"ingest{lz_key}curated{env_name}\"\n",
    "\n",
    "xcutting_storage = f\"ingest{lz_key}xcutting{env_name}\"\n",
    "\n",
    "# Spark config for curated storage (Delta table)\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{xcutting_storage}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{xcutting_storage}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{xcutting_storage}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{xcutting_storage}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{xcutting_storage}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48f35927-97f5-4146-9abf-5b19352f04fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"abfss://af-idempotency@ingest00xcuttingsbox.dfs.core.windows.net/ARCHIVE/ARIATDDEV/processed/\"\n",
    "binary_df = spark.read.format(\"binaryFile\").option(\"recursiveFileLookup\", \"true\").load(data_path)\n",
    "display(binary_df)\n",
    "\n",
    "# 1075576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae7c3dfa-a809-441d-a29a-0f7af2a2d445",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "binary_df.count()\n",
    "\n",
    "# 1075576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29bbcef3-c882-4539-b6b4-48e9c4a86a58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "htm_count = binary_df.filter(col(\"path\").endswith(\".html.flag\")).count()\n",
    "display(htm_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e814c47d-7e34-405a-8926-ab1679631b5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "htm_count = binary_df.filter(col(\"path\").endswith(\".json.flag\")).count()\n",
    "display(htm_count)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3626812047035775,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ARIA_ADLS_TO_EVENTHUBS_GENRIC_JOH",
   "widgets": {
    "file_types": {
     "currentValue": "a360",
     "nuid": "6e946561-66e6-443c-8fb0-3061a3d7cee3",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "html,json",
      "label": null,
      "name": "file_types",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "html,json",
        "a360"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "html,json",
      "label": null,
      "name": "file_types",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "html,json",
        "a360"
       ]
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
