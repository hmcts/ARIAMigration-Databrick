{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a69617e1-9b6d-452d-98c8-fc369f34cad5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import packages"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import logging\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType, LongType\n",
    "from pyspark.sql.functions import col,from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "365b3a3a-7a55-4f2f-8cf9-ed9dbb1e6203",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Initialise Logging"
    }
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"DatabricksWorkflow\")\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "if not logger.hasHandlers():\n",
    "    logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19244474-d430-44cb-b183-4e8d800fe38b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define the acknowledge schema"
    }
   },
   "outputs": [],
   "source": [
    "ack_schema = StructType([\n",
    "    StructField(\"filename\", StringType(), True),\n",
    "    StructField(\"http_response\", IntegerType(),True),\n",
    "    StructField(\"timestamp\", TimestampType(), True),\n",
    "    StructField(\"http_message\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68d88f8f-aabf-49b4-80e1-56f87fe31e4e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Access environment variables"
    }
   },
   "outputs": [],
   "source": [
    "#Load configuration JSON\n",
    "config_path = \"dbfs:/configs/config.json\"\n",
    "try:\n",
    "    config = spark.read.option(\"multiline\", \"true\").json(config_path)\n",
    "    logger.info(f\"Successfully read config file from {config_path}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Could not read config file at {config_path}: {e}\", exc_info=True)\n",
    "    raise FileNotFoundError(f\"Could not read config file at {config_path}: {e}\")\n",
    "\n",
    "#Extract environment and lz_key\n",
    "try:\n",
    "    first_row = config.first()\n",
    "    env = first_row[\"env\"].strip().lower()\n",
    "    lz_key = first_row[\"lz_key\"].strip().lower()\n",
    "    logger.info(f\"Extracted configs: env={env}, lz_key={lz_key}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Missing expected keys 'env' or 'lz_key' in config file: {e}\", exc_info=True)\n",
    "    raise KeyError(f\"Missing expected keys 'env' or 'lz_key' in config file: {e}\")\n",
    "\n",
    "#Construct keyvault name\n",
    "try:\n",
    "    keyvault_name = f\"ingest{lz_key}-meta002-{env}\"\n",
    "    logger.info(f\"Constructed keyvault name: {keyvault_name}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error constructing keyvault name: {e}\", exc_info=True)\n",
    "    raise ValueError(f\"Error constructing keyvault name: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41e0c186-0ca3-4362-8780-5af434bf9a67",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read in Service Principle"
    }
   },
   "outputs": [],
   "source": [
    "# Access the Service Principal secrets from Key Vault\n",
    "try:\n",
    "    client_secret = dbutils.secrets.get(scope=keyvault_name, key='SERVICE-PRINCIPLE-CLIENT-SECRET')\n",
    "    logger.info(\"Successfully retrieved SERVICE-PRINCIPLE-CLIENT-SECRET from Key Vault\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Could not retrieve 'SERVICE-PRINCIPLE-CLIENT-SECRET' from Key Vault '{keyvault_name}': {e}\", exc_info=True)\n",
    "    raise KeyError(f\"Could not retrieve 'SERVICE-PRINCIPLE-CLIENT-SECRET' from Key Vault '{keyvault_name}': {e}\")\n",
    "\n",
    "try:\n",
    "    tenant_id = dbutils.secrets.get(scope=keyvault_name, key='SERVICE-PRINCIPLE-TENANT-ID')\n",
    "    logger.info(\"Successfully retrieved SERVICE-PRINCIPLE-TENANT-ID from Key Vault\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Could not retrieve 'SERVICE-PRINCIPLE-TENANT-ID' from Key Vault '{keyvault_name}': {e}\", exc_info=True)\n",
    "    raise KeyError(f\"Could not retrieve 'SERVICE-PRINCIPLE-TENANT-ID' from Key Vault '{keyvault_name}': {e}\")\n",
    "\n",
    "try:\n",
    "    client_id = dbutils.secrets.get(scope=keyvault_name, key='SERVICE-PRINCIPLE-CLIENT-ID')\n",
    "    logger.info(\"Successfully retrieved SERVICE-PRINCIPLE-CLIENT-ID from Key Vault\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Could not retrieve 'SERVICE-PRINCIPLE-CLIENT-ID' from Key Vault '{keyvault_name}': {e}\", exc_info=True)\n",
    "    raise KeyError(f\"Could not retrieve 'SERVICE-PRINCIPLE-CLIENT-ID' from Key Vault '{keyvault_name}': {e}\")\n",
    "\n",
    "logger.info(\"✅ Successfully retrieved all Service Principal secrets from Key Vault\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae4b78aa-c1e1-4c29-9fbc-c08bcf7c8446",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define EventHub values"
    }
   },
   "outputs": [],
   "source": [
    "segment_short = \"fta\"\n",
    "segment = \"APPEALS\"\n",
    "recordclass = \"ARIAFTA\"\n",
    "EH_NAMESPACE = f\"ingest{lz_key}-integration-eventHubNamespace001-{env}\"\n",
    "EH_NAME = f\"evh-apl{segment_short}-ack-{lz_key}-uks-dlrm-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35b51a6c-946f-43f7-85bc-e5a71f00defb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set Kafka configuration"
    }
   },
   "outputs": [],
   "source": [
    "connection_string = dbutils.secrets.get(keyvault_name, \"RootManageSharedAccessKey\")\n",
    "\n",
    "KAFKA_OPTIONS = {\n",
    "    \"kafka.bootstrap.servers\": f\"{EH_NAMESPACE}.servicebus.windows.net:9093\",\n",
    "    \"subscribe\": EH_NAME,\n",
    "    \"startingOffsets\": \"earliest\",\n",
    "    \"kafka.security.protocol\": \"SASL_SSL\",\n",
    "    \"failOnDataLoss\": \"false\",\n",
    "    \"kafka.sasl.mechanism\": \"PLAIN\",\n",
    "    \"kafka.sasl.jaas.config\": f'kafkashaded.org.apache.kafka.common.security.plain.PlainLoginModule required username=\"$ConnectionString\" password=\"{connection_string}\";'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0d386ab-d63e-41a6-9655-2691351a4f38",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Assign OAuth"
    }
   },
   "outputs": [],
   "source": [
    "# --- Parameterise containers ---\n",
    "curated_storage_account = f\"ingest{lz_key}curated{env}\"\n",
    "curated_container = \"gold\"\n",
    "silver_curated_container = \"silver\"\n",
    "checkpoint_storage_account = f\"ingest{lz_key}xcutting{env}\"\n",
    "\n",
    "# --- Assign OAuth to storage accounts ---\n",
    "storage_accounts = [curated_storage_account, checkpoint_storage_account]\n",
    "\n",
    "for storage_account in storage_accounts:\n",
    "    try:\n",
    "        configs = {\n",
    "            f\"fs.azure.account.auth.type.{storage_account}.dfs.core.windows.net\": \"OAuth\",\n",
    "            f\"fs.azure.account.oauth.provider.type.{storage_account}.dfs.core.windows.net\":\n",
    "                \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "            f\"fs.azure.account.oauth2.client.id.{storage_account}.dfs.core.windows.net\": client_id,\n",
    "            f\"fs.azure.account.oauth2.client.secret.{storage_account}.dfs.core.windows.net\": client_secret,\n",
    "            f\"fs.azure.account.oauth2.client.endpoint.{storage_account}.dfs.core.windows.net\":\n",
    "                f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\"\n",
    "        }\n",
    "\n",
    "        for key, val in configs.items():\n",
    "            try:\n",
    "                spark.conf.set(key, val)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to set Spark config '{key}' for storage account '{storage_account}': {e}\", exc_info=True)\n",
    "                raise RuntimeError(f\"Failed to set Spark config '{key}' for storage account '{storage_account}': {e}\")\n",
    "\n",
    "        logger.info(f\"✅ Successfully configured OAuth for storage account: {storage_account}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error configuring OAuth for storage account '{storage_account}': {e}\", exc_info=True)\n",
    "        raise RuntimeError(f\"Error configuring OAuth for storage account '{storage_account}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f84b319-1db1-446d-8e7a-2995d8746a7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gold_data_path = f\"abfss://gold@ingest{lz_key}curated{env}.dfs.core.windows.net/ARIADM/ARM/{segment}/{recordclass}/\"\n",
    "# HTML Count\n",
    "html_path = f\"{gold_data_path}HTML/*.html\"\n",
    "html_df = spark.read.format(\"binaryFile\").load(html_path)\n",
    "\n",
    "json_path = f\"{gold_data_path}JSON/*.json\"\n",
    "json_df = spark.read.format(\"binaryFile\").load(json_path)\n",
    "\n",
    "a360_path = f\"{gold_data_path}A360/*.a360\"\n",
    "a360_df = spark.read.format(\"binaryFile\").load(a360_path)\n",
    "\n",
    "expected_html = html_df.count()\n",
    "expected_json = json_df.count()\n",
    "expected_a360 = a360_df.count()\n",
    "\n",
    "logger.info(f\"Expected HTML: {expected_html}\")\n",
    "logger.info(f\"Expected JSON: {expected_json}\")\n",
    "logger.info(f\"Expected A360: {expected_a360}\")\n",
    "\n",
    "#1a. how many records in source data? (prod aria db) or we can use outputs of segmentation tables eg gold tables\n",
    "#1b json content, html content should be the same as what we have established in the source\n",
    "#1c a360 is %% (mod) 250\n",
    "## expected pre-publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e62d101f-9a17-4220-a219-2ef51326c50d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Assign output path and checkpoint path"
    }
   },
   "outputs": [],
   "source": [
    "# Container and path for storing Delta table (in curated storage account)\n",
    "data_path = f\"abfss://silver@ingest{lz_key}curated{env}.dfs.core.windows.net/ARIADM/ARM/AUDIT/{segment}/{recordclass}/{segment_short}_ack_audit_table\"\n",
    "\n",
    "# Container and path for checkpoint (in xcuttings storage account)\n",
    "checkpoint_path = f\"abfss://db-ack-checkpoint@ingest{lz_key}xcutting{env}.dfs.core.windows.net/{segment}/{recordclass}/ACK/ack\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e919d51-7805-459d-996f-9978be8d27e4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Initiate spark structured streaming"
    }
   },
   "outputs": [],
   "source": [
    "eventhubdf = spark.readStream.format(\"kafka\")\\\n",
    "    .options(**KAFKA_OPTIONS)\\\n",
    "        .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28e68aec-1444-42c5-8ab9-5c57fe154d85",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Parse Kafka message to JSON object"
    }
   },
   "outputs": [],
   "source": [
    "parsed_df = (\n",
    "    eventhubdf\n",
    "    # 'body' is binary, so we cast to string (assuming UTF-8)\n",
    "    .select(col(\"value\").cast(\"string\").alias(\"json_str\"))\n",
    "    .select(from_json(col(\"json_str\"), ack_schema).alias(\"json_obj\"))\n",
    "    .select(\"json_obj.*\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58be3df5-d386-420b-b26f-7cc3d7524b0f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create function to determine processed number of A360 records"
    }
   },
   "outputs": [],
   "source": [
    "def get_processed_counts():\n",
    "    df = spark.read.format(\"delta\").load(data_path)\n",
    "    \n",
    "    a360_count = df.filter((col(\"filename\")).endswith(\".a360\")).select(\"filename\").distinct().count()\n",
    "\n",
    "    return a360_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00bb7847-1deb-4df9-a3ad-8b88772b3ce5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Write stream to curated storage account"
    }
   },
   "outputs": [],
   "source": [
    "query = parsed_df.writeStream \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"checkpointLocation\", checkpoint_path) \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d604b36-a49b-46d5-b66f-95ce1d316e39",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define a wait period for the stream to initialise and create storage account"
    }
   },
   "outputs": [],
   "source": [
    "# wait 60 seconds before the reconcilliaiton checks\n",
    "max_attempt = 5\n",
    "delay = 30 # seconds\n",
    "\n",
    "for attempt in range(1,max_attempt):\n",
    "    try:\n",
    "        a360_count = get_processed_counts()\n",
    "    except Exception as e:\n",
    "        if attempt < max_attempt:\n",
    "            print(f\"Attempt {attempt} failed: {e}. Retrying in {delay} seconds... \")\n",
    "            time.sleep(60)\n",
    "        else:\n",
    "            print(\"Failed to get processed counts after {max_attempt} attempts: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d51a5adb-5786-42a3-9482-c6c3e2f7bbfd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "While the stream is live, count the number of processed records"
    }
   },
   "outputs": [],
   "source": [
    "while query.isActive:\n",
    "    a360_count = get_processed_counts()\n",
    "    logger.info(f\"Status A360: {a360_count}/{expected_a360}\")\n",
    "\n",
    "    if (\n",
    "        a360_count >= expected_a360\n",
    "    ):\n",
    "        logger.info(\"All files processed\")\n",
    "        query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c4b5ff9-3945-41ec-b1f0-49222766c1dc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read in tables"
    }
   },
   "outputs": [],
   "source": [
    "silver_container = \"silver\"\n",
    "df_fta_ack_audit_data = spark.read.format(\"delta\").load(f\"abfss://{silver_container}@{curated_storage_account}.dfs.core.windows.net/ARIADM/ARM/AUDIT/{segment}/{recordclass}/{segment_short}_ack_audit_table/\")\n",
    "df_fta_ack_audit_data.createOrReplaceTempView(f\"{segment_short}_acknowledge_audit_data\")\n",
    "\n",
    "fta_cr_audit_table = spark.read.format(\"delta\").load(f\"abfss://{silver_container}@{curated_storage_account}.dfs.core.windows.net/ARIADM/ARM/AUDIT/{segment}/{recordclass}/apl_{segment_short}_cr_audit_table/\")\n",
    "fta_cr_audit_table.createOrReplaceTempView(f\"{segment_short}_cr_audit_table\")\n",
    "\n",
    "df_fta_pub_audit_db_eh_audit_data = spark.read.format(\"delta\").load(f\"abfss://{silver_container}@{curated_storage_account}.dfs.core.windows.net/ARIADM/ARM/AUDIT/{segment}/{recordclass}/apl_{segment_short}_pub_audit_table/\")\n",
    "df_fta_pub_audit_db_eh_audit_data.createOrReplaceTempView(f\"{segment_short}_publish_audit_db_eh_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3431d89b-5a21-490b-b983-5dfa42191938",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"http_response_status\":521,\"filename\":397},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763374154124}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "A360 Table"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"    \n",
    "with window_func as (\n",
    "SELECT filename,\n",
    "            CASE WHEN http_response = 201 THEN 'Success' ELSE 'Failure' END AS http_response_status,\n",
    "            timestamp,\n",
    "            ROW_NUMBER() OVER (PARTITION BY filename ORDER BY timestamp DESC) as rn\n",
    "\n",
    "FROM {segment_short}_acknowledge_audit_data)\n",
    "SELECT filename, \n",
    "        http_response_status,\n",
    "        timestamp\n",
    "FROM window_func where rn=1 and filename LIKE '%.a360'\n",
    "     \"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ddd6d7a-03e6-455e-a1c4-81ee4ce44851",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "JSON Table"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"   \n",
    "with window_func as (\n",
    "SELECT filename,\n",
    "            CASE WHEN http_response = 201 THEN 'Success' ELSE 'Failure' END AS http_response_status,\n",
    "            timestamp,\n",
    "            ROW_NUMBER() OVER (PARTITION BY filename ORDER BY timestamp DESC) as rn\n",
    "\n",
    "FROM {segment_short}_acknowledge_audit_data)\n",
    "SELECT filename, \n",
    "        http_response_status,\n",
    "        timestamp\n",
    "FROM window_func where rn=1 and filename LIKE '%.json'\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cbe0ebd-6f02-4e4f-a797-882cd5e51226",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "HTML Table"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"  \n",
    "with window_func as (\n",
    "SELECT filename,\n",
    "            CASE WHEN http_response = 201 THEN 'Success' ELSE 'Failure' END AS http_response_status,\n",
    "            timestamp,\n",
    "            ROW_NUMBER() OVER (PARTITION BY filename ORDER BY timestamp DESC) as rn\n",
    "\n",
    "FROM {segment_short}_acknowledge_audit_data)\n",
    "SELECT filename, \n",
    "        http_response_status,\n",
    "        timestamp\n",
    "FROM window_func where rn=1 and filename LIKE '%.html'\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab4ee9a6-2185-459c-951f-f52f136c47c1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "JSON Query"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "spark.sql(f\"\"\"\n    WITH window_func AS (\n        SELECT \n            filename,\n            http_response,\n            http_message,\n            timestamp,\n            ROW_NUMBER() OVER (PARTITION BY filename ORDER BY timestamp DESC) as rn\n        FROM {segment_short}_acknowledge_audit_data\n    ),\n    deduped AS (\n        SELECT *\n        FROM window_func\n        WHERE rn = 1\n    ),\n    results AS (\n        SELECT \n            split_part(filename, '.', -1) AS file_extension,\n            COUNT(CASE WHEN (http_response = 201 AND http_message = 'Created') OR http_message = 'Duplicate skipped by idempotency' THEN 1 END) AS count_of_successful_eventhub_responses,\n            COUNT(CASE WHEN (http_response <> 201 AND http_message <> 'Created') OR http_message = 'Duplicate skipped by idempotency' THEN 1 END) AS count_of_unsuccessful_eventhub_responses\n        FROM deduped\n        WHERE split_part(filename, '.', -1) = 'json'\n        GROUP BY split_part(filename, '.', -1)\n    )\n    SELECT\n        file_extension AS file_type,\n        {expected_html} AS total_expected_html_eventhub_responses,\n        CASE WHEN file_extension = 'json' THEN count_of_successful_eventhub_responses ELSE NULL END AS `total_sent_json_eventhub_responses`,\n        CASE WHEN file_extension = 'json' THEN concat(ROUND((count_of_successful_eventhub_responses / {expected_html}) * 100, 2), \"%\") ELSE NULL END AS `%total_expected_json_eventhub_responses`\n    FROM results\n\"\"\").display()",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "DETAILS"
         },
         {
          "key": "options",
          "value": {
           "columns": [
            {
             "name": "file_type",
             "title": "file_type",
             "type": "string"
            },
            {
             "name": "total_expected_html_eventhub_responses",
             "title": "total_expected_html_eventhub_responses",
             "type": "integer"
            },
            {
             "name": "total_sent_json_eventhub_responses",
             "title": "total_sent_json_eventhub_responses",
             "type": "integer"
            },
            {
             "name": "%total_expected_json_eventhub_responses",
             "title": "%total_expected_json_eventhub_responses",
             "type": "string"
            }
           ],
           "version": 1
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "d17fae88-46d3-487b-bb6f-bdeb7dbd76be",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 22.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {},
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    WITH window_func AS (\n",
    "        SELECT \n",
    "            filename,\n",
    "            http_response,\n",
    "            http_message,\n",
    "            timestamp,\n",
    "            ROW_NUMBER() OVER (PARTITION BY filename ORDER BY timestamp DESC) as rn\n",
    "        FROM {segment_short}_acknowledge_audit_data\n",
    "    ),\n",
    "    deduped AS (\n",
    "        SELECT *\n",
    "        FROM window_func\n",
    "        WHERE rn = 1\n",
    "    ),\n",
    "    results AS (\n",
    "        SELECT \n",
    "            split_part(filename, '.', -1) AS file_extension,\n",
    "            COUNT(CASE WHEN (http_response = 201 AND http_message = 'Created') OR (http_response = 201 AND  http_message like 'Duplicate%') THEN 1 END) AS count_of_successful_eventhub_responses,\n",
    "            COUNT(CASE WHEN (http_response <> 201 AND http_message <> 'Created') OR (http_message like 'Duplicate%' and http_response = 201 ) THEN 1 END) AS count_of_unsuccessful_eventhub_responses\n",
    "        FROM deduped\n",
    "        WHERE split_part(filename, '.', -1) = 'json'\n",
    "        GROUP BY split_part(filename, '.', -1)\n",
    "    )\n",
    "    SELECT\n",
    "        file_extension AS file_type,\n",
    "        {expected_html} AS total_expected_html_eventhub_responses,\n",
    "        CASE WHEN file_extension = 'json' THEN count_of_successful_eventhub_responses ELSE NULL END AS `total_sent_json_eventhub_responses`,\n",
    "        CASE WHEN file_extension = 'json' THEN concat(ROUND((count_of_successful_eventhub_responses / {expected_html}) * 100, 2), \"%\") ELSE NULL END AS `%total_expected_json_eventhub_responses`\n",
    "    FROM results\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fb0db7c-e87b-4d4f-9db2-906d1b13685b",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763653607159}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "HTML Query"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "spark.sql(f\"\"\"\n    WITH window_func AS (\n        SELECT \n            filename,\n            http_response,\n            http_message,\n            timestamp,\n            ROW_NUMBER() OVER (PARTITION BY filename ORDER BY timestamp DESC) as rn\n        FROM {segment_short}_acknowledge_audit_data\n    ),\n    deduped AS (\n        SELECT *\n        FROM window_func\n        WHERE rn = 1\n    ),\n    results AS (\n        SELECT \n            split_part(filename, '.', -1) AS file_extension,\n            COUNT(CASE WHEN (http_response = 201 AND http_message = 'Created') OR http_message = 'Duplicate skipped by idempotency' THEN 1 END) AS count_of_successful_eventhub_responses,\n            COUNT(CASE WHEN (http_response <> 201 AND http_message <> 'Created') OR http_message = 'Duplicate skipped by idempotency' THEN 1 END) AS count_of_unsuccessful_eventhub_responses\n        FROM deduped\n        WHERE split_part(filename, '.', -1) = 'html'\n        GROUP BY split_part(filename, '.', -1)\n    )\n    SELECT\n        file_extension AS file_type,\n        {expected_html} AS total_expected_html_eventhub_responses,\n        CASE WHEN file_extension = 'html' THEN count_of_successful_eventhub_responses ELSE NULL END AS `total_sent_json_eventhub_responses`,\n        CASE WHEN file_extension = 'html' THEN concat(ROUND((count_of_successful_eventhub_responses / {expected_html}) * 100, 2), \"%\") ELSE NULL END AS `%total_expected_json_eventhub_responses`\n    FROM results\n\"\"\").display()",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "DETAILS"
         },
         {
          "key": "options",
          "value": {
           "columns": [
            {
             "name": "file_type",
             "title": "file_type",
             "type": "string"
            },
            {
             "name": "total_expected_html_eventhub_responses",
             "title": "total_expected_html_eventhub_responses",
             "type": "integer"
            },
            {
             "name": "total_sent_html_eventhub_responses",
             "title": "total_sent_html_eventhub_responses",
             "type": "integer"
            },
            {
             "name": "%total_expected_html_eventhub_responses",
             "title": "%total_expected_html_eventhub_responses",
             "type": "string"
            }
           ],
           "version": 1
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "6518f3f2-3a3e-4cc1-a248-274deb995b3d",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 23.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {},
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    WITH window_func AS (\n",
    "        SELECT \n",
    "            filename,\n",
    "            http_response,\n",
    "            http_message,\n",
    "            timestamp,\n",
    "            ROW_NUMBER() OVER (PARTITION BY filename ORDER BY timestamp DESC) as rn\n",
    "        FROM {segment_short}_acknowledge_audit_data\n",
    "    ),\n",
    "    deduped AS (\n",
    "        SELECT *\n",
    "        FROM window_func\n",
    "        WHERE rn = 1\n",
    "    ),\n",
    "    results AS (\n",
    "        SELECT \n",
    "            split_part(filename, '.', -1) AS file_extension,\n",
    "            COUNT(CASE WHEN (http_response = 201 AND http_message = 'Created') OR http_message like 'Duplicate%' THEN 1 END) AS count_of_successful_eventhub_responses,\n",
    "            COUNT(CASE WHEN (http_response <> 201 AND http_message <> 'Created') OR http_message like 'Duplicate%' THEN 1 END) AS count_of_unsuccessful_eventhub_responses\n",
    "        FROM deduped\n",
    "        WHERE split_part(filename, '.', -1) = 'html'\n",
    "        GROUP BY split_part(filename, '.', -1)\n",
    "    )\n",
    "    SELECT\n",
    "        file_extension AS file_type,\n",
    "        {expected_html} AS total_expected_html_eventhub_responses,\n",
    "        CASE WHEN file_extension = 'html' THEN count_of_successful_eventhub_responses ELSE NULL END AS `total_sent_json_eventhub_responses`,\n",
    "        CASE WHEN file_extension = 'html' THEN concat(ROUND((count_of_successful_eventhub_responses / {expected_html}) * 100, 2), \"%\") ELSE NULL END AS `%total_expected_json_eventhub_responses`\n",
    "    FROM results\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87288a60-c06d-46e8-a1ef-191849772b21",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "A360 Query"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    WITH window_func AS (\n",
    "        SELECT \n",
    "            filename,\n",
    "            http_response,\n",
    "            http_message,\n",
    "            timestamp,\n",
    "            ROW_NUMBER() OVER (PARTITION BY filename ORDER BY timestamp DESC) as rn\n",
    "        FROM {segment_short}_acknowledge_audit_data\n",
    "    ),\n",
    "    deduped AS (\n",
    "        SELECT *\n",
    "        FROM window_func\n",
    "        WHERE rn = 1\n",
    "    ),\n",
    "    results AS (\n",
    "        SELECT \n",
    "            split_part(filename, '.', -1) AS file_extension,\n",
    "            COUNT(CASE WHEN (http_response = 201 AND http_message = 'Created') OR http_message like 'Duplicate%' THEN 1 END) AS count_of_successful_eventhub_responses,\n",
    "            COUNT(CASE WHEN (http_response <> 201 AND http_message <> 'Created') OR http_message like 'Duplicate%' THEN 1 END) AS count_of_unsuccessful_eventhub_responses\n",
    "        FROM deduped\n",
    "        WHERE split_part(filename, '.', -1) = 'a360'\n",
    "        GROUP BY split_part(filename, '.', -1)\n",
    "    )\n",
    "    SELECT\n",
    "        file_extension AS file_type,\n",
    "        {expected_html} AS total_expected_html_eventhub_responses,\n",
    "        CASE WHEN file_extension = 'a360' THEN count_of_successful_eventhub_responses ELSE NULL END AS `total_sent_json_eventhub_responses`,\n",
    "        CASE WHEN file_extension = 'a360' THEN concat(ROUND((count_of_successful_eventhub_responses / {expected_html}) * 100, 2), \"%\") ELSE NULL END AS `%total_expected_json_eventhub_responses`\n",
    "    FROM results\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63e6e393-0620-4af6-8037-e6b91a2ed5e0",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"count_of_gold_records\":417,\"Table_Name\":469,\"Stage_Name\":463},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763373898425}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "Gold DLT Outputs"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "WITH ARIAFTA AS (\n",
    "    SELECT \n",
    "        COUNT(Unique_Identifier) AS count_of_gold_records, \n",
    "        Table_Name, \n",
    "        Stage_Name \n",
    "    FROM fta_cr_audit_table \n",
    "    WHERE table_name LIKE 'stg_appeals_filtered'\n",
    "      AND Description LIKE '%FTA%'\n",
    "    GROUP BY Table_Name, Stage_Name\n",
    "    ORDER BY Stage_Name DESC\n",
    "),\n",
    "CTE AS (\n",
    "    SELECT \n",
    "        COUNT(Unique_Identifier) AS count_of_gold_records, \n",
    "        Table_Name, \n",
    "        Stage_Name \n",
    "    FROM {segment_short}_cr_audit_table \n",
    "    WHERE Stage_Name IN ('segmentation_stage', 'gold_stage') \n",
    "      AND Table_Name IN (\n",
    "          -- 'silver_normal_bail', \n",
    "          -- 'create_bails_json_content', \n",
    "          -- 'create_bails_html_content', \n",
    "          -- 'gold_bails_a360',\n",
    "          -- 'save_html_to_blob',\n",
    "          -- 'save_json_to_blob'\n",
    "          'stg_apl_create_json_content',\n",
    "          'stg_apl_create_html_content',\n",
    "          'stg_apl_create_a360_content',\n",
    "          'gold_appeals_with_json',\n",
    "          'gold_appeals_with_html',\n",
    "          'gold_appeals_with_a360'\n",
    "      )\n",
    "    GROUP BY Table_Name, Stage_Name\n",
    "    ORDER BY Stage_Name DESC\n",
    ")\n",
    "SELECT\n",
    "    count_of_gold_records,\n",
    "    Table_Name,\n",
    "    Stage_Name\n",
    "FROM CTE\n",
    "UNION ALL \n",
    "SELECT \n",
    "    count_of_gold_records,\n",
    "    Table_Name,\n",
    "    Stage_Name\n",
    "FROM ARIAFTA\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d457f429-90e3-488b-aabc-80dd98beb889",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Publish HTML/JSON/A360 to EventHub"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "      SELECT \n",
    "      split_part(file_name, '.', -1) as file_extension,\n",
    "      {expected_html} as total_expected_html_eventhub_responses,\n",
    "      {expected_json} as total_expected_json_eventhub_responses,\n",
    "      {expected_a360} as total_expected_a360_eventhub_responses,\n",
    "      COUNT(CASE WHEN status = 'success' THEN 1 END) AS count_of_successful_eventhub_responses,\n",
    "      COUNT(CASE WHEN status <> 'success' THEN 1 END) AS count_of_unsuccessful_eventhub_responses,\n",
    "      concat(((count_of_successful_eventhub_responses/total_expected_html_eventhub_responses) * 100), \"%\") as `%_of_successful_eventhub_responses`\n",
    "\n",
    "FROM {segment_short}_publish_audit_db_eh_data\n",
    "GROUP BY file_extension\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd272c54-d5ba-4bca-8911-e43930c45803",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "HTML Acknowledge"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "spark.sql(f\"\"\"\n    WITH results AS (\n        SELECT \n            split_part(file_name, '.', -1) AS file_extension,\n            COUNT(CASE WHEN status = 'success' THEN 1 END) AS count_of_successful_eventhub_responses,\n            COUNT(CASE WHEN status != 'success' THEN 1 END) AS count_of_unsuccessful_eventhub_responses\n        FROM {segment_short}_publish_audit_db_eh_data\n        WHERE split_part(file_name, '.', -1) = 'html'\n        GROUP BY split_part(file_name, '.', -1)\n    )\n    SELECT\n        file_extension AS file_type,\n        {expected_html} AS total_expected_html_eventhub_responses,\n        count_of_successful_eventhub_responses AS count_of_successful_html_responses,\n        concat(\n            ROUND(\n                (count_of_successful_eventhub_responses / {expected_html}) * 100, 2\n            ), \"%\"\n        ) AS `%total_expected_html_eventhub_responses`\n    FROM results\n\"\"\").display()",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "DETAILS"
         },
         {
          "key": "options",
          "value": {
           "columns": [
            {
             "name": "file_type",
             "title": "file_type",
             "type": "string"
            },
            {
             "name": "total_expected_html_eventhub_responses",
             "title": "total_expected_html_eventhub_responses",
             "type": "integer"
            },
            {
             "name": "count_of_successful_html_responses",
             "title": "count_of_successful_html_responses",
             "type": "integer"
            },
            {
             "name": "%total_expected_html_eventhub_responses",
             "title": "%total_expected_html_eventhub_responses",
             "type": "string"
            }
           ],
           "version": 1
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "974ef8e7-bce5-4a4a-bcab-a897e5a542d2",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 27.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {},
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    WITH results AS (\n",
    "        SELECT \n",
    "            split_part(file_name, '.', -1) AS file_extension,\n",
    "            COUNT(CASE WHEN status = 'success' THEN 1 END) AS count_of_successful_eventhub_responses,\n",
    "            COUNT(CASE WHEN status != 'success' THEN 1 END) AS count_of_unsuccessful_eventhub_responses\n",
    "        FROM {segment_short}_publish_audit_db_eh_data\n",
    "        WHERE split_part(file_name, '.', -1) = 'html'\n",
    "        GROUP BY split_part(file_name, '.', -1)\n",
    "    )\n",
    "    SELECT\n",
    "        file_extension AS file_type,\n",
    "        {expected_html} AS total_expected_html_eventhub_responses,\n",
    "        count_of_successful_eventhub_responses AS count_of_successful_html_responses,\n",
    "        concat(\n",
    "            ROUND(\n",
    "                (count_of_successful_eventhub_responses / {expected_html}) * 100, 2\n",
    "            ), \"%\"\n",
    "        ) AS `%total_expected_html_eventhub_responses`\n",
    "    FROM results\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54b4d29b-e896-494d-884a-5001e470feb1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "JSON Acknowledge"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "spark.sql(f\"\"\"\n    WITH results AS (\n        SELECT \n            split_part(file_name, '.', -1) AS file_extension,\n            COUNT(CASE WHEN status = 'success' THEN 1 END) AS count_of_successful_eventhub_responses,\n            COUNT(CASE WHEN status != 'success' THEN 1 END) AS count_of_unsuccessful_eventhub_responses\n        FROM {segment_short}_publish_audit_db_eh_data\n        WHERE split_part(file_name, '.', -1) = 'json'\n        GROUP BY split_part(file_name, '.', -1)\n    )\n    SELECT\n        file_extension AS file_type,\n        {expected_json} AS total_expected_json_eventhub_responses,\n        count_of_successful_eventhub_responses AS count_of_successful_json_responses,\n        concat(\n            ROUND(\n                (count_of_successful_eventhub_responses / {expected_json}) * 100, 2\n            ), \"%\"\n        ) AS `%total_expected_json_eventhub_responses`\n    FROM results\n\"\"\").display()",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "DETAILS"
         },
         {
          "key": "options",
          "value": {
           "columns": [
            {
             "name": "file_type",
             "title": "file_type",
             "type": "string"
            },
            {
             "name": "total_expected_json_eventhub_responses",
             "title": "total_expected_json_eventhub_responses",
             "type": "integer"
            },
            {
             "name": "count_of_successful_json_responses",
             "title": "count_of_successful_json_responses",
             "type": "integer"
            },
            {
             "name": "%total_expected_json_eventhub_responses",
             "title": "%total_expected_json_eventhub_responses",
             "type": "string"
            }
           ],
           "version": 1
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "fd8639a8-5ed7-4585-9b01-3ce52414c647",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 28.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {},
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    WITH results AS (\n",
    "        SELECT \n",
    "            split_part(file_name, '.', -1) AS file_extension,\n",
    "            COUNT(CASE WHEN status = 'success' THEN 1 END) AS count_of_successful_eventhub_responses,\n",
    "            COUNT(CASE WHEN status != 'success' THEN 1 END) AS count_of_unsuccessful_eventhub_responses\n",
    "        FROM {segment_short}_publish_audit_db_eh_data\n",
    "        WHERE split_part(file_name, '.', -1) = 'json'\n",
    "        GROUP BY split_part(file_name, '.', -1)\n",
    "    )\n",
    "    SELECT\n",
    "        file_extension AS file_type,\n",
    "        {expected_json} AS total_expected_json_eventhub_responses,\n",
    "        count_of_successful_eventhub_responses AS count_of_successful_json_responses,\n",
    "        concat(\n",
    "            ROUND(\n",
    "                (count_of_successful_eventhub_responses / {expected_json}) * 100, 2\n",
    "            ), \"%\"\n",
    "        ) AS `%total_expected_json_eventhub_responses`\n",
    "    FROM results\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ff69aa9-1952-478d-817a-66da3adab8aa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "A360 Acknowledge"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "spark.sql(f\"\"\"\n    WITH results AS (\n        SELECT \n            split_part(file_name, '.', -1) AS file_extension,\n            COUNT(CASE WHEN status = 'success' THEN 1 END) AS count_of_successful_eventhub_responses,\n            COUNT(CASE WHEN status != 'success' THEN 1 END) AS count_of_unsuccessful_eventhub_responses\n        FROM {segment_short}_publish_audit_db_eh_data\n        WHERE split_part(file_name, '.', -1) = 'a360'\n        GROUP BY split_part(file_name, '.', -1)\n    )\n    SELECT\n        file_extension AS file_type,\n        {expected_a360} AS total_expected_a360_eventhub_responses,\n        count_of_successful_eventhub_responses AS count_of_successful_a360_responses,\n        concat(\n            ROUND(\n                (count_of_successful_eventhub_responses / {expected_a360}) * 100, 2\n            ), \"%\"\n        ) AS `%total_expected_a360_eventhub_responses`\n    FROM results\n\"\"\").display()",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "DETAILS"
         },
         {
          "key": "options",
          "value": {
           "columns": [
            {
             "name": "file_type",
             "title": "file_type",
             "type": "string"
            },
            {
             "name": "total_expected_a360_eventhub_responses",
             "title": "total_expected_a360_eventhub_responses",
             "type": "integer"
            },
            {
             "name": "count_of_successful_a360_responses",
             "title": "count_of_successful_a360_responses",
             "type": "integer"
            },
            {
             "name": "%total_expected_a360_eventhub_responses",
             "title": "%total_expected_a360_eventhub_responses",
             "type": "string"
            }
           ],
           "version": 1
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "db100c55-8290-48c3-8ae5-94e62f5bec66",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 29.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {},
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "    WITH results AS (\n",
    "        SELECT \n",
    "            split_part(file_name, '.', -1) AS file_extension,\n",
    "            COUNT(CASE WHEN status = 'success' THEN 1 END) AS count_of_successful_eventhub_responses,\n",
    "            COUNT(CASE WHEN status != 'success' THEN 1 END) AS count_of_unsuccessful_eventhub_responses\n",
    "        FROM {segment_short}_publish_audit_db_eh_data\n",
    "        WHERE split_part(file_name, '.', -1) = 'a360'\n",
    "        GROUP BY split_part(file_name, '.', -1)\n",
    "    )\n",
    "    SELECT\n",
    "        file_extension AS file_type,\n",
    "        {expected_a360} AS total_expected_a360_eventhub_responses,\n",
    "        count_of_successful_eventhub_responses AS count_of_successful_a360_responses,\n",
    "        concat(\n",
    "            ROUND(\n",
    "                (count_of_successful_eventhub_responses / {expected_a360}) * 100, 2\n",
    "            ), \"%\"\n",
    "        ) AS `%total_expected_a360_eventhub_responses`\n",
    "    FROM results\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5a10d46-2f25-414b-84de-5d6086680e07",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Close the notebook"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.exit(\"Notebook completed successfully\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [
    {
     "elements": [
      {
       "dashboardResultIndex": 0,
       "elementNUID": "63e6e393-0620-4af6-8037-e6b91a2ed5e0",
       "elementType": "command",
       "guid": "05ff75d4-4ac5-42be-9bb7-8c3cd6b3cf7b",
       "options": null,
       "position": {
        "height": 4,
        "width": 24,
        "x": 0,
        "y": 0,
        "z": null
       },
       "resultIndex": null
      },
      {
       "dashboardResultIndex": null,
       "elementNUID": "974ef8e7-bce5-4a4a-bcab-a897e5a542d2",
       "elementType": "command",
       "guid": "5d825f58-514f-4dda-8462-e940aa8e4b7a",
       "options": {
        "autoScaleImg": false,
        "scale": 0,
        "showTitle": true,
        "title": "Count of HTML acknowledged by EventHub",
        "titleAlign": "center"
       },
       "position": {
        "height": 4,
        "width": 12,
        "x": 12,
        "y": 4,
        "z": null
       },
       "resultIndex": null
      },
      {
       "dashboardResultIndex": 0,
       "elementNUID": "3431d89b-5a21-490b-b983-5dfa42191938",
       "elementType": "command",
       "guid": "60ca0f2e-c00c-4455-ae31-b2c6f43524bd",
       "options": {
        "autoScaleImg": false,
        "scale": 0,
        "showTitle": true,
        "title": "Gold A360 table (DLT output)",
        "titleAlign": "center"
       },
       "position": {
        "height": 4,
        "width": 23,
        "x": 1,
        "y": 22,
        "z": null
       },
       "resultIndex": null
      },
      {
       "dashboardResultIndex": null,
       "elementNUID": "d17fae88-46d3-487b-bb6f-bdeb7dbd76be",
       "elementType": "command",
       "guid": "67cb0177-8fe5-4e15-81aa-68bd63f11db3",
       "options": {
        "autoScaleImg": false,
        "scale": 0,
        "showTitle": true,
        "title": "Count of JSON messages published to EventHub",
        "titleAlign": "center"
       },
       "position": {
        "height": 4,
        "width": 12,
        "x": 0,
        "y": 8,
        "z": null
       },
       "resultIndex": null
      },
      {
       "dashboardResultIndex": 0,
       "elementNUID": "8ddd6d7a-03e6-455e-a1c4-81ee4ce44851",
       "elementType": "command",
       "guid": "b192dafd-48c2-4794-bd6f-2d2a16b42992",
       "options": {
        "autoScaleImg": false,
        "scale": 0,
        "showTitle": true,
        "title": "Gold JSON table (DLT output)",
        "titleAlign": "center"
       },
       "position": {
        "height": 6,
        "width": 12,
        "x": 0,
        "y": 16,
        "z": null
       },
       "resultIndex": null
      },
      {
       "dashboardResultIndex": null,
       "elementNUID": "6518f3f2-3a3e-4cc1-a248-274deb995b3d",
       "elementType": "command",
       "guid": "b7caf531-a1c6-4da8-b3ae-7631ef56bd18",
       "options": {
        "autoScaleImg": false,
        "scale": 0,
        "showTitle": true,
        "title": "Count of HTML messages published to EventHub",
        "titleAlign": "center"
       },
       "position": {
        "height": 4,
        "width": 12,
        "x": 0,
        "y": 4,
        "z": null
       },
       "resultIndex": null
      },
      {
       "dashboardResultIndex": null,
       "elementNUID": "db100c55-8290-48c3-8ae5-94e62f5bec66",
       "elementType": "command",
       "guid": "c00158f6-51b5-495a-bf7d-d2d8354bea35",
       "options": {
        "autoScaleImg": false,
        "scale": 0,
        "showTitle": true,
        "title": "Count of A360 messages acknowledged by EventHub",
        "titleAlign": "center"
       },
       "position": {
        "height": 4,
        "width": 12,
        "x": 12,
        "y": 12,
        "z": null
       },
       "resultIndex": null
      },
      {
       "dashboardResultIndex": null,
       "elementNUID": "fd8639a8-5ed7-4585-9b01-3ce52414c647",
       "elementType": "command",
       "guid": "e6ca093d-7989-4703-a2d4-e319672026e8",
       "options": {
        "autoScaleImg": false,
        "scale": 0,
        "showTitle": true,
        "title": "Count of JSON messages acknowledged by EventHub",
        "titleAlign": "center"
       },
       "position": {
        "height": 4,
        "width": 12,
        "x": 12,
        "y": 8,
        "z": null
       },
       "resultIndex": null
      },
      {
       "dashboardResultIndex": 0,
       "elementNUID": "1cbe0ebd-6f02-4e4f-a797-882cd5e51226",
       "elementType": "command",
       "guid": "f98e42ad-c1fd-4757-9af2-6bb914689bc7",
       "options": {
        "autoScaleImg": false,
        "scale": 0,
        "showTitle": true,
        "title": "Gold HTML table (DLT output)",
        "titleAlign": "center"
       },
       "position": {
        "height": 6,
        "width": 12,
        "x": 12,
        "y": 16,
        "z": null
       },
       "resultIndex": null
      }
     ],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "2d853444-7cde-42cc-97df-b7a5a2a06fb2",
     "origId": 7069923958290076,
     "title": "json_html_a360_acknowledge_dashboard",
     "version": "DashboardViewV1",
     "width": 1440
    }
   ],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5296736266766919,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ariafta_a360_acknowledge",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
