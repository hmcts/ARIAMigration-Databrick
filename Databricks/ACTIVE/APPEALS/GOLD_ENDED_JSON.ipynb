{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65cb672e-fad4-41c9-955b-9e447b8ff7f6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Python Wheel"
    }
   },
   "outputs": [],
   "source": [
    "%pip install /dbfs/FileStore/packages/shared_functions-0.6.6-py3-none-any.whl\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc4f34c6-1b52-4600-a8bd-ecf5f1539523",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Active Appeals Ended State (Gold)\n",
    "<table style='float:left;'>\n",
    "   <tbody>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><b>Name: </b></td>\n",
    "         <td>GOLD_ACTIVE_APPEALS_ENDED</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><b>Description: </b></td>\n",
    "         <td>Notebook to load data for the Ended state based on given mappings.</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><b>First Created: </b></td>\n",
    "         <td>Feb-2026</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <th style='text-align: left;'><b>Changelog (JIRA ref/initials/date):</b></th>\n",
    "         <th>Comments</th>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td style='text-align: left;'><a href=\"https://tools.hmcts.net/jira/browse/ARIADM-1481\">ARIADM-1481</a>/MU/JAN-2026</td>\n",
    "         <td>Implementing mappings for the Ended state.</td>\n",
    "      </tr>\n",
    "   </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b74449b-e058-46d3-a261-7cb376b3c009",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import shared_functions.paymentPending as PP\n",
    "import shared_functions.appealSubmitted as APS\n",
    "import shared_functions.AwaitingEvidenceRespondant_a as AERa\n",
    "import shared_functions.listing as L\n",
    "import shared_functions.listing_dq_rules as L_DQRules\n",
    "import shared_functions.prepareForHearing as PFH\n",
    "import shared_functions.prepareforhearing_dq_rules as PFH_DQRules\n",
    "import shared_functions.decision as D\n",
    "import shared_functions.decision_dq_rules as D_DQRules\n",
    "import shared_functions.decided_a as DA\n",
    "import shared_functions.decided_a_dq_rules as DA_DQRules\n",
    "import shared_functions.ftpa_submitted_a as FSA\n",
    "import shared_functions.ftpa_submitted_a_dq_rules as FSA_DQRules\n",
    "import shared_functions.ended as E\n",
    "import shared_functions.ended_dq_rules as E_DQRules\n",
    "from shared_functions.DQRules import base_DQRules, build_rule_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7831545c-1e19-4244-ab14-25869bbd78f7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import packages"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e251edd4-ffe0-47d2-9c90-2add21a1af59",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Assign configs"
    }
   },
   "outputs": [],
   "source": [
    "config = spark.read.option(\"multiline\", \"true\").json(\"dbfs:/configs/config.json\")\n",
    "env_name = config.first()[\"env\"].strip().lower()\n",
    "lz_key = config.first()[\"lz_key\"].strip().lower()\n",
    "\n",
    "print(f\"env_code: {lz_key}\")  # This won't be redacted\n",
    "print(f\"env_name: {env_name}\")  # This won't be redacted\n",
    "\n",
    "KeyVault_name = f\"ingest{lz_key}-meta002-{env_name}\"\n",
    "print(f\"KeyVault_name: {KeyVault_name}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36f0c0bd-2026-4b2c-8800-f4732e142615",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Assign OAuth"
    }
   },
   "outputs": [],
   "source": [
    "# Service principal credentials\n",
    "client_id = dbutils.secrets.get(KeyVault_name, \"SERVICE-PRINCIPLE-CLIENT-ID\")\n",
    "client_secret = dbutils.secrets.get(KeyVault_name, \"SERVICE-PRINCIPLE-CLIENT-SECRET\")\n",
    "tenant_id = dbutils.secrets.get(KeyVault_name, \"SERVICE-PRINCIPLE-TENANT-ID\")\n",
    "\n",
    "# Storage account names\n",
    "curated_storage = f\"ingest{lz_key}curated{env_name}\"\n",
    "checkpoint_storage = f\"ingest{lz_key}xcutting{env_name}\"\n",
    "raw_storage = f\"ingest{lz_key}raw{env_name}\"\n",
    "landing_storage = f\"ingest{lz_key}landing{env_name}\"\n",
    "external_storage = f\"ingest{lz_key}external{env_name}\"\n",
    "\n",
    "\n",
    "# Spark config for curated storage (Delta table)\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{curated_storage}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{curated_storage}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{curated_storage}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{curated_storage}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{curated_storage}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n",
    "\n",
    "# Spark config for checkpoint storage\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{checkpoint_storage}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{checkpoint_storage}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{checkpoint_storage}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{checkpoint_storage}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{checkpoint_storage}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n",
    "\n",
    "# Spark config for checkpoint storage\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{raw_storage}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{raw_storage}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{raw_storage}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{raw_storage}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{raw_storage}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n",
    "\n",
    "# Spark config for checkpoint storage\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{landing_storage}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{landing_storage}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{landing_storage}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{landing_storage}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{landing_storage}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n",
    "\n",
    "\n",
    "# Spark config for checkpoint storage\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{external_storage}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{external_storage}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{external_storage}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{external_storage}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{external_storage}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e169fc23-7079-4102-8017-e009060ec361",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Assign Paths"
    }
   },
   "outputs": [],
   "source": [
    "AppealState = \"ended\"\n",
    "output_name = \"ended\"\n",
    "\n",
    "# Setting variables for use in subsequent cells\n",
    "bronze_path = f\"abfss://bronze@ingest{lz_key}curated{env_name}.dfs.core.windows.net/ARIADM/ACTIVE/CCD/APPEALS/\"\n",
    "silver_path = f\"abfss://silver@ingest{lz_key}curated{env_name}.dfs.core.windows.net/ARIADM/ACTIVE/CCD/APPEALS/\"\n",
    "audit_path = f\"abfss://silver@ingest{lz_key}curated{env_name}.dfs.core.windows.net/ARIADM/ACTIVE/CCD/APPEALS/AUDIT/{AppealState}\"\n",
    "gold_outputs = f\"ARIADM/ACTIVE/CCD/APPEALS/{AppealState}\"\n",
    "\n",
    "# Print all variables\n",
    "variables = {\n",
    "    # \"read_hive\": read_hive,\n",
    "    \n",
    "    \"bronze_path\": bronze_path,\n",
    "    \"silver_path\": silver_path,\n",
    "    \"audit_path\": audit_path,\n",
    "    \"gold_outputs\": gold_outputs,\n",
    "    \"key_vault\": KeyVault_name,\n",
    "    \"AppealState\": AppealState\n",
    "}\n",
    "\n",
    "display(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d30465e-ae52-4a05-9eab-bba6e0964456",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read in tables"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "silver_m1 = spark.table(\"hive_metastore.ariadm_active_appeals.silver_appealcase_detail\").filter(col(\"dv_targetState\") == lit(AppealState)).distinct()\n",
    "silver_m2 = spark.table(\"hive_metastore.ariadm_active_appeals.silver_caseapplicant_detail\") \n",
    "silver_m3 = spark.table(\"hive_metastore.ariadm_active_appeals.silver_status_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "silver_m4 = spark.table(\"hive_metastore.ariadm_active_appeals.silver_transaction_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "silver_m5 = spark.table(\"hive_metastore.ariadm_active_appeals.silver_link_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "silver_m6 = spark.table(\"hive_metastore.ariadm_active_appeals.silver_adjudicator_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "silver_c = spark.table(\"hive_metastore.ariadm_active_appeals.silver_appealcategory_detail\")\n",
    "silver_h = spark.table(\"hive_metastore.ariadm_active_appeals.silver_history_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "\n",
    "bronze_remissions_lookup_df = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_remissions\").distinct()\n",
    "bronze_countryFromAddress = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_countries_countryFromAddress\")\n",
    "bronze_HORef_cleansing = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_HORef_cleansing\")\n",
    "bronze_hearing_centres = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_hearing_centres\")\n",
    "bronze_derive_hearing_centres = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_derive_hearing_centres\")\n",
    "bronze_interpreter_languages = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_interpreter_languages\")\n",
    "bronze_listing_location = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_listing_location\")\n",
    "bronze_ended_states = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_ended_states\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "659794bc-4ee7-4c06-9b49-c722683888ff",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: AppealType"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = PP.appealType(silver_m1)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1bfe0c7-33ea-435f-a6ac-6a0c1ea44dca",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: caseData"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = PP.caseData(silver_m1, silver_m2, silver_m3, silver_h, bronze_hearing_centres, bronze_derive_hearing_centres)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7e0ce82-5fc6-447e-8766-1ed43cbc3885",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function flagsLabels"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = PP.flagsLabels(silver_m1, silver_m2, silver_c)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d148c5d9-d290-4ffd-9659-73b56c3d0d94",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: legalRepDetails"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = PP.legalRepDetails(silver_m1,bronze_countryFromAddress)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4280437-d43a-4e88-8612-c1815ea9ff9b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: appellantDetails"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = AERa.appellantDetails(silver_m1, silver_m2, silver_c, bronze_countryFromAddress,bronze_HORef_cleansing)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25f86a21-304d-47ab-a385-5a4d6162ca2f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: homeOfficeDetails"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = PP.homeOfficeDetails(silver_m1, silver_m2, silver_c, bronze_HORef_cleansing)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd6c6c7d-0b83-4885-aa92-67a57792bbda",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: paymentType"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = APS.paymentType(silver_m1, silver_m4)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89d0182e-789e-41ed-9ab9-332fafb77900",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: PartyID"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = PP.partyID(silver_m1, silver_m3, silver_c)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eab929a0-fcdf-49d9-9132-ac3f17a7b407",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: remissionTypes"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = APS.remissionTypes(silver_m1, bronze_remissions_lookup_df, silver_m4)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d80dfab-2797-4893-8f3a-e3bcb57bb3d3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: sponsorDetails"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = PP.sponsorDetails(silver_m1, silver_c)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaa130d9-e819-46d0-b6bf-a10beab9112f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: hearingRequirements"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = E.hearingRequirements(silver_m1, silver_m3, silver_c, bronze_interpreter_languages)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19921c7b-4c43-4878-96a8-3f8738309915",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: GeneralFunctions"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = E.general(silver_m1, silver_m2, silver_m3, silver_h, bronze_hearing_centres, bronze_derive_hearing_centres)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcef7ae8-c0da-4d0a-aee4-1137a3a15e12",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: GeneralDefault - Default Values"
    }
   },
   "outputs": [],
   "source": [
    "df = E.generalDefault(silver_m1,silver_m3)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19c8b8f5-a4c2-4edd-b7de-ae4a253b7007",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d457be5-e5be-485d-8603-197482ea366e",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1770930052960}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "Function: Documents"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = E.documents(silver_m1,silver_m3)\n",
    "display(df_audit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c6309c9-7259-4cfc-9365-7d8410be94ad",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: ftpa"
    }
   },
   "outputs": [],
   "source": [
    "df,df_audit = E.ftpa(silver_m3, silver_c)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f22d591-629e-42ae-97ef-ac80f9d3fd1e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: hearingActuals"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = E.hearingActuals(silver_m3)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05955428-cd9a-4bee-9696-f32f831e55bc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function substantiveDecision"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = E.substantiveDecision(silver_m1,silver_m3)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b30f020-2a1e-4505-a377-d9e7447805bb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: hearingResponse"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = E.hearingResponse(silver_m1, silver_m3, silver_m6)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "334bc8c7-098f-4224-846a-3ab20001cab3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function hearingDetails"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = E.hearingDetails(silver_m1,silver_m3,bronze_listing_location)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "194d6f37-aad3-4aa1-b5ce-a4dea0d8ccac",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: ended"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = E.ended(silver_m3,bronze_ended_states)\n",
    "# df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cf99f49-6cf0-45b8-9cfd-8077c057bd86",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: caseState"
    }
   },
   "outputs": [],
   "source": [
    "df, df_audit = PP.caseState(silver_m1, \"ended\")\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fab959d-e02d-4462-9bf3-9066581c18f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5552c83b-7c45-4994-a403-1b94dc87827f",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765273264588}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "Function: Ended"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, StructType, ArrayType, MapType\n",
    "from pyspark.sql.functions import col, lit, to_json, struct, concat, regexp_replace\n",
    "from datetime import datetime\n",
    "\n",
    "def mainEnded(silver_segmentation, silver_m1, silver_m2, silver_m3, silver_m6, silver_c, silver_h, bronze_remissions, bronze_countryFromAddress, bronze_HORef_cleansing, bronze_hearing_centres, bronze_derive_hearing_centres, bronze_interpreter_languages, bronze_listing_location,bronze_ended_states):\n",
    "    AppealState = \"ended\"\n",
    "    \n",
    "    # Aggregate details\n",
    "    appealType_df, appealType_df_audit = PP.appealType(silver_m1)\n",
    "    caseData_df, caseData_df_audit = PP.caseData(silver_m1, silver_m2, silver_m3, silver_h, bronze_hearing_centres, bronze_derive_hearing_centres)\n",
    "    flagsLabels_df, flagsLabels_df_audit = PP.flagsLabels(silver_m1, silver_m2, silver_c)\n",
    "    appellantDetails_df, appellantDetails_df_audit = AERa.appellantDetails(silver_m1, silver_m2, silver_c, bronze_countryFromAddress,bronze_HORef_cleansing)\n",
    "    legalRepDetails_df, legalRepDetails_df_audit = PP.legalRepDetails(silver_m1,bronze_countryFromAddress)\n",
    "    partyID_df, partyID_df_audit = PP.partyID(silver_m1, silver_m3, silver_c)\n",
    "    payment_df, payment_df_audit = APS.paymentType(silver_m1, silver_m4)\n",
    "    homeOfficeDetails_df, homeOfficeDetails_df_audit = PP.homeOfficeDetails(silver_m1, silver_m2, silver_c, bronze_HORef_cleansing)\n",
    "    remissionTypes_df, remissionTypes_df_audit = APS.remissionTypes(silver_m1, bronze_remissions, silver_m4)\n",
    "    sponsorDetails_df, sponsorDetails_df_audit = PP.sponsorDetails(silver_m1, silver_c)\n",
    "    general_df, general_df_audit = FSA.general(silver_m1, silver_m2, silver_m3, silver_h, bronze_hearing_centres, bronze_derive_hearing_centres)\n",
    "    generalDefault_df = FSA.generalDefault(silver_m1)\n",
    "    documents_df, documents_df_audit = FSA.documents(silver_m1,silver_m3)\n",
    "    hearingResponse_df, hearingResponse_df_audit = PFH.hearingResponse(silver_m1, silver_m3, silver_m6)\n",
    "    hearingDetails_df, hearingDetails_df_audit = D.hearingDetails(silver_m1,silver_m3,bronze_listing_location)\n",
    "    caseState_df, caseState_df_audit = PP.caseState(silver_m1, AppealState)\n",
    "    hearingRequirements_df, hearingRequirements_df_audit = L.hearingRequirements(silver_m1, silver_m3, silver_c, bronze_interpreter_languages)\n",
    "    substantiveDecision_df, substantiveDecision_df_audit = DA.substantiveDecision(silver_m1,silver_m3)\n",
    "    hearingActuals_df, hearingActuals_df_audit = DA.hearingActuals(silver_m3)\n",
    "    ftpa_df, ftpa_df_audit = FSA.ftpa(silver_m3,silver_c)\n",
    "    ended_df, ended_df_audit = E.ended(silver_m3,bronze_ended_states)\n",
    "\n",
    "    silver_segmentation_df = silver_segmentation\n",
    "\n",
    "    # Join all aggregated data with Appeal Case Details\n",
    "    df_combined = (\n",
    "        silver_segmentation_df\n",
    "            .join(appealType_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(caseData_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(flagsLabels_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(appellantDetails_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(legalRepDetails_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(sponsorDetails_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(partyID_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(payment_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(remissionTypes_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(homeOfficeDetails_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(caseState_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(hearingRequirements_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(general_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(generalDefault_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(documents_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(hearingResponse_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(hearingDetails_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(substantiveDecision_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(hearingActuals_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(ftpa_df, on=\"CaseNo\", how=\"left\")\n",
    "            .join(ended_df, on=\"CaseNo\", how=\"left\")\n",
    "    )\n",
    "\n",
    "    # Join all aggregated data with Appeal Case Details\n",
    "    df_combined_audit = (\n",
    "        silver_segmentation_df.join(appealType_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(caseData_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(flagsLabels_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(appellantDetails_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(legalRepDetails_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(sponsorDetails_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(partyID_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(payment_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(remissionTypes_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(homeOfficeDetails_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(caseState_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(hearingRequirements_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(general_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(documents_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(hearingResponse_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(hearingDetails_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(substantiveDecision_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(hearingActuals_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(ftpa_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "            .join(ended_df_audit, on=\"CaseNo\", how=\"left\")\n",
    "    )\n",
    "\n",
    "    Datetime_name = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "    # Create JSON and filename and omit columns that are with null values\n",
    "    df_final = df_combined.withColumn(\n",
    "        \"JSON_Content\", to_json(struct(*df_combined.drop(col(\"CaseNo\")).columns))\n",
    "    ).withColumn(\n",
    "        \"JSON_File_name\", concat(lit(f\"{gold_outputs}/{Datetime_name}/JSON/APPEALS_\"), regexp_replace(col(\"CaseNo\"), \"/\", \"_\"), lit(\".json\"))\n",
    "    )\n",
    "    \n",
    "    return df_final, df_combined_audit\n",
    "\n",
    "########### Test ##########\n",
    "\n",
    "# silver_m1 = spark.table(\"ariadm_active_appeals.silver_appealcase_detail\").filter(col(\"dv_targetState\") == lit(AppealState)).distinct()\n",
    "# silver_m2 =  spark.table(\"ariadm_active_appeals.silver_caseapplicant_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "# silver_m3 = spark.table(\"ariadm_active_appeals.silver_status_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "# silver_c = spark.table(\"ariadm_active_appeals.silver_appealcategory_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "# bronze_remissions = spark.table(\"ariadm_active_appeals.bronze_remissions\").distinct()\n",
    "# silver_segmentation = spark.table(\"ariadm_active_appeals.stg_segmentation_states\").filter(col(\"TargetState\") == lit(AppealState))\n",
    "\n",
    "# bronze_countryFromAddress = spark.table(\"ariadm_active_appeals.bronze_countries_countryFromAddress\").withColumn(\"lu_countryGovUkOocAdminJ\", col(\"countryGovUkOocAdminJ\"))\n",
    "\n",
    "# bronze_HORef_cleansing = spark.table(\"ariadm_active_appeals.bronze_HORef_cleansing\")\n",
    "# bronze_interpreter_languages = spark.table(\"ariadm_active_appeals.bronze_interpreter_languages\")\n",
    "\n",
    "# df_final, df_audit = mainEnded(silver_segmentation, silver_m1, silver_m2, silver_m3, silver_m6, silver_c, silver_h, bronze_remissions, bronze_countryFromAddress, bronze_HORef_cleansing, bronze_hearing_centres, bronze_derive_hearing_centres, bronze_interpreter_languages,bronze_listing_location,bronze_ended_states)\n",
    "\n",
    "# display(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1e06424-6966-4125-9563-3d73261b37c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Function: Upload  and Blob Client Connection Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bd38396-bc28-4971-84ae-805bfd07e775",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Secret Retrieval for Database Connection"
    }
   },
   "outputs": [],
   "source": [
    "secret = dbutils.secrets.get(KeyVault_name, f\"CURATED-{env_name}-SAS-TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5169b7b1-135d-4de4-a228-a25b02b66f97",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Azure Blob Storage Connection Setup in Python"
    }
   },
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "import os\n",
    "\n",
    "# Set up the BlobServiceClient with your connection string\n",
    "connection_string = secret\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "# Specify the container name\n",
    "container_name = \"gold\"\n",
    "container_client = blob_service_client.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd8881aa-9b58-41e1-ad05-93d0230af4c5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Function: Format Dates for UploadBlob Storage"
    }
   },
   "outputs": [],
   "source": [
    "# Upload HTML to Azure Blob Storage\n",
    "def upload_to_blob(file_name, file_content):\n",
    "    try:\n",
    "        # blob_client = container_client.get_blob_client(f\"{gold_outputs}/HTML/{file_name}\")\n",
    "        blob_client = container_client.get_blob_client(f\"{file_name}\")\n",
    "        blob_client.upload_blob(file_content, overwrite=True)\n",
    "        return \"success\"\n",
    "    except Exception as e:\n",
    "        return f\"error: {str(e)}\"\n",
    "\n",
    "# Register the upload function as a UDF\n",
    "upload_udf = udf(upload_to_blob)\n",
    "\n",
    "# df_with_upload_status = df_final.withColumn(\n",
    "#     \"Status\", upload_udf(col(\"JSON_File_name\"), col(\"JSON_Content\"))\n",
    "# )\n",
    "\n",
    "# display(df_with_upload_status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db97feb8-762a-40b6-8cb9-5afa8f134fe3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Gold Outputs and Tracking DLT Table Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68b88c16-e4c6-4ba2-81c9-7f755c89ae30",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Combine Validation Checks into String"
    }
   },
   "outputs": [],
   "source": [
    "checks = {}\n",
    "checks = base_DQRules()\n",
    "checks = L_DQRules.add_checks(checks)\n",
    "checks = PFH_DQRules.add_checks(checks)\n",
    "checks = D_DQRules.add_checks(checks)\n",
    "checks = DA_DQRules.add_checks(checks)\n",
    "checks = FSA_DQRules.add_checks(checks)\n",
    "checks = E_DQRules.add_checks(checks)\n",
    "dq_rules = build_rule_expression(checks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3d01276-8aa3-40b8-9143-07edd5e2f8bc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Transformation: stg_main_ended_validation"
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, lit, expr\n",
    "from pyspark.sql import Window\n",
    "\n",
    "@dlt.table(\n",
    "    name=f\"stg_main_{output_name}_validation\",\n",
    "    comment=\"DLT table running ended to generate a JSON_Content column for CCD validation. Applies DLT expectations on CCD, adding is_valid to flag validation results.\",\n",
    "    path=f\"{audit_path}/stg_main_{output_name}_validation\"\n",
    ")\n",
    "@dlt.expect_all(checks)\n",
    "def stg_main_ended_validation():\n",
    "    try:\n",
    "        silver_m1 = dlt.read(\"silver_appealcase_detail\").filter(col(\"dv_targetState\") == lit(AppealState)).distinct()\n",
    "        silver_m2 = dlt.read(\"silver_caseapplicant_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_m3 = dlt.read(\"silver_status_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_m6 = dlt.read(\"silver_adjudicator_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_c = dlt.read(\"silver_appealcategory_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_h = dlt.read(\"silver_history_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        bronze_countries_postal_lookup_df = dlt.read(\"bronze_countries_postal\").distinct()\n",
    "        bronze_remissions = dlt.read(\"bronze_remissions\").distinct()\n",
    "        bronze_countryFromAddress = dlt.read(\"bronze_countries_countryFromAddress\")\n",
    "        bronze_HORef_cleansing = dlt.read(\"bronze_HORef_cleansing\")\n",
    "        bronze_hearing_centres = dlt.read(\"bronze_hearing_centres\")\n",
    "        bronze_derive_hearing_centres = dlt.read(\"bronze_derive_hearing_centres\")\n",
    "        bronze_interpreter_languages = dlt.read(\"bronze_interpreter_languages\")\n",
    "        bronze_listing_location = spark.table(\"bronze_listing_location\")\n",
    "        bronze_ended_states = spark.table(\"bronze_ended_states\")\n",
    "        silver_segmentation = dlt.read(\"stg_segmentation_states\").filter(col(\"TargetState\") == lit(AppealState))\n",
    "        \n",
    "    except:\n",
    "        silver_m1 = spark.table(\"hive_metastore.ariadm_active_appeals.silver_appealcase_detail\").filter(col(\"dv_targetState\") == lit(AppealState)).distinct()\n",
    "        silver_m2 = spark.table(\"hive_metastore.ariadm_active_appeals.silver_caseapplicant_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_m3 = spark.table(\"hive_metastore.ariadm_active_appeals.silver_status_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_m6 = spark.table(\"hive_metastore.ariadm_active_appeals.silver_adjudicator_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_c = spark.table(\"hive_metastore.ariadm_active_appeals.silver_appealcategory_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_h = spark.table(\"hive_metastore.ariadm_active_appeals.silver_history_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        bronze_countries_postal_lookup_df = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_countries_postal\").distinct() \n",
    "        bronze_remissions = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_remissions\").distinct()\n",
    "        bronze_countryFromAddress = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_countries_countryFromAddress\")\n",
    "        bronze_HORef_cleansing = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_HORef_cleansing\")\n",
    "        bronze_hearing_centres = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_hearing_centres\")\n",
    "        bronze_derive_hearing_centres = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_derive_hearing_centres\")\n",
    "        bronze_interpreter_languages = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_interpreter_languages\")\n",
    "        bronze_listing_location = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_listing_location\")\n",
    "        bronze_ended_states = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_ended_states\")\n",
    "        silver_segmentation = spark.table(\"hive_metastore.ariadm_active_appeals.stg_segmentation_states\").filter(col(\"TargetState\") == lit(AppealState))\n",
    "\n",
    "    df_final, df_audit = mainEnded(silver_segmentation, silver_m1, silver_m2, silver_m3, silver_m6, silver_c, silver_h, bronze_remissions, bronze_countryFromAddress, bronze_HORef_cleansing, bronze_hearing_centres, bronze_derive_hearing_centres, bronze_interpreter_languages,bronze_listing_location,bronze_ended_states)\n",
    "\n",
    "    valid_representation = silver_m1.select(col(\"CaseNo\"), col(\"dv_representation\"),col(\"dv_CCDAppealType\"),col(\"CaseRep_Address5\"), col(\"CaseRep_Postcode\"),col(\"MainRespondentId\"), col(\"lu_appealType\"), col(\"HORef\"),col(\"Sponsor_Authorisation\"),col(\"Sponsor_Name\"),col(\"RepresentativeId\")) \n",
    "    valid_appealant_address = silver_m2.select(col(\"CaseNo\"), col(\"Appellant_Address1\"), col(\"Appellant_Address2\"),col(\"Appellant_Address3\"),(\"Appellant_Address4\"), col(\"Appellant_Address5\"), col(\"Appellant_Postcode\"),col(\"Appellant_Email\"),col(\"Appellant_Telephone\"), col(\"FCONumber\"),col(\"Appellant_Name\")).filter(col(\"Relationship\").isNull())\n",
    "    valid_country_list = bronze_countries_postal_lookup_df.select(col(\"countryGovUkOocAdminJ\").alias(\"valid_countryGovUkOocAdminJ\")).distinct()\n",
    "    valid_catagoryid_list = silver_c.groupBy(\"CaseNo\").agg(F.collect_list(\"CategoryId\").alias(\"valid_categoryIdList\"))\n",
    "    valid_HORef_cleansing = bronze_HORef_cleansing.select( col(\"CaseNo\"),coalesce(col(\"HORef\"), col(\"FCONumber\")).alias(\"lu_HORef\"))\n",
    "    valid_reasonDescription = silver_m1.alias(\"m1\").join(bronze_remissions, on=[\"PaymentRemissionReason\",\"PaymentRemissionRequested\"], how=\"left\").select(\"CaseNo\", \"ReasonDescription\",col(\"remissionClaim\").alias(\"lu_remissionClaim\"),col(\"feeRemissionType\").alias(\"lu_feeRemissionType\"))\n",
    "    window_spec = Window.partitionBy(\"CaseNo\").orderBy(desc(\"StatusId\"))\n",
    "    valid_caseStatus = silver_m3.select(col(\"CaseNo\"),col(\"CaseStatus\"), col(\"StatusId\"), col(\"Outcome\"), col(\"AdditionalLanguageId\"), row_number().over(window_spec).alias(\"rn\")).filter(\n",
    "        (col(\"rn\") == 1) & (((col(\"CaseStatus\").isin(37, 38)) & (col(\"Outcome\").isin(0, 27, 37, 39, 40, 50))) | ((col(\"CaseStatus\") == 26) & (col(\"Outcome\").isin(40, 52))))\n",
    "    ).drop(\"rn\")\n",
    "    valid_statusId = valid_caseStatus.select(col(\"CaseNo\"),col(\"CaseStatus\"), col(\"StatusId\"), col(\"Outcome\"))\n",
    "    valid_hearing_requirements = silver_m1.select(col(\"CaseNo\"), col(\"Interpreter\"), col(\"CourtPreference\"), col(\"InCamera\"))\n",
    "    valid_languages = (\n",
    "        silver_m1.alias(\"m1\")\n",
    "            .join(valid_caseStatus.alias(\"m3\"), on=\"CaseNo\", how=\"left\")\n",
    "            .join(bronze_interpreter_languages.alias(\"lu_language\"), on=(col(\"m1.LanguageId\") == col(\"lu_language.LanguageId\")), how=\"left\")\n",
    "            .join(bronze_interpreter_languages.alias(\"lu_additional_language\"), on=(col(\"m3.AdditionalLanguageId\") == col(\"lu_additional_language.LanguageId\")), how=\"left\")\n",
    "            .select(\n",
    "                col(\"CaseNo\"),\n",
    "                col(\"m1.LanguageId\").alias(\"LanguageId\"),\n",
    "                col(\"m3.AdditionalLanguageId\").alias(\"AdditionalLanguageId\"),\n",
    "                col(\"lu_language.appellantInterpreterLanguageCategory\").alias(\"valid_languageCategory\"),\n",
    "                col(\"lu_additional_language.appellantInterpreterLanguageCategory\").alias(\"valid_additionalLanguageCategory\"),\n",
    "                col(\"lu_language.languageCode\").alias(\"valid_languageCode\"),\n",
    "                col(\"lu_additional_language.languageCode\").alias(\"valid_additionalLanguageCode\"),\n",
    "                col(\"lu_language.languageLabel\").alias(\"valid_languageLabel\"),\n",
    "                col(\"lu_additional_language.languageLabel\").alias(\"valid_additionalLanguageLabel\"),\n",
    "                col(\"lu_language.manualEntry\").alias(\"valid_manualEntry\"),\n",
    "                col(\"lu_additional_language.manualEntry\").alias(\"valid_additionalManualEntry\"),\n",
    "                col(\"lu_language.manualEntryDescription\").alias(\"valid_manualEntryDescription\"),\n",
    "                col(\"lu_additional_language.manualEntryDescription\").alias(\"valid_additionalManualEntryDescription\")\n",
    "            )\n",
    "    )\n",
    "    window_spec = Window.partitionBy(\"CaseNo\").orderBy(col(\"StatusId\").desc())\n",
    "    silver_m3_filtered_casestatus = silver_m3.filter(col(\"CaseStatus\").isin(37, 38))\n",
    "    silver_m3_ranked = silver_m3_filtered_casestatus.withColumn(\"row_number\", row_number().over(window_spec))\n",
    "    silver_m3_filtered_casestatus = silver_m3_ranked.filter(col(\"row_number\") == 1).drop(\"row_number\")\n",
    "\n",
    "    df_m3_validation = silver_m3_filtered_casestatus.select(\"CaseNo\", \"HearingCentre\",\"TimeEstimate\",\"HearingDate\",\"HearingType\",\"CourtName\",\"ListType\",\"ListTypeId\",\"StartTime\",\"Judge1FT_Surname\",\"Judge2FT_Surname\",\"Judge3FT_Surname\",\"Judge1FT_Forenames\",\"Judge2FT_Forenames\",\"Judge3FT_Forenames\",\"Judge1FT_Title\",\"Judge2FT_Title\",\"Judge3FT_Title\",\"CourtClerk_Surname\",\"CourtClerk_Forenames\",\"CourtClerk_Title\")\n",
    "    df_m6_validation =silver_m6.drop(\"dv_targetState\")\n",
    "    df_m1_validation = silver_m1.select(\"CaseNo\",\"VisitVisaType\")\n",
    "    df_ll_validation = bronze_listing_location.select(col(\"ListedCentre\"),col(\"locationCode\"),col(\"locationLabel\"),col(\"listCaseHearingCentre\").alias(\"bronz_listCaseHearingCentre\"),col(\"listCaseHearingCentreAddress\").alias(\"bronz_listCaseHearingCentreAddress\"))\n",
    "    valid_preparforhearing = df_m1_validation.join(df_m3_validation, on=\"CaseNo\", how=\"left\").join(df_ll_validation, on=col(\"HearingCentre\") == col(\"ListedCentre\"), how=\"left\").join(df_m6_validation, on=\"CaseNo\", how=\"left\")\n",
    "\n",
    "    valid_preparforhearing = valid_preparforhearing.drop(\"HearingCentre\")\n",
    "    # silver_c_filtered_CategoryId = silver_c.filter(col(\"CategoryId\").isin(37, 38)).select(col(\"CaseNo\"),col(\"CategoryId\")).distinct()\n",
    "    silver_m3_filtered_outcome = silver_m3.filter(col(\"CaseStatus\").isin(37, 38,26) & col(\"Outcome\").isin(1,2))\n",
    "    silver_m3_outcome_ranked = silver_m3_filtered_outcome.withColumn(\"row_number\", row_number().over(window_spec))\n",
    "    silver_m3_outcome_ranked = silver_m3_outcome_ranked.filter(col(\"row_number\") == 1).select(col(\"CaseNo\"), col(\"Outcome\").alias(\"Outcome_SD\")\n",
    "                                ,col(\"HearingDuration\"),col(\"Adj_Determination_Title\"),col(\"Adj_Determination_Forenames\")\n",
    "                                ,col(\"Adj_Determination_Surname\"),col(\"DecisionDate\"))\n",
    "    \n",
    "    silver_m3_filtered_fpta = silver_m3.filter(col(\"CaseStatus\").isin(39))\n",
    "    silver_m3_ftpa_ranked = silver_m3_filtered_fpta.withColumn(\"row_number\", row_number().over(window_spec))\n",
    "    silver_m3_ftpa_ranked = silver_m3_ftpa_ranked.filter(col(\"row_number\") == 1).select(col(\"CaseNo\"),col(\"Party\"),col(\"OutOfTime\"),col(\"DateReceived\"),\n",
    "                                                                                        col(\"Adj_Title\"),col(\"Adj_Forenames\"),col(\"Adj_Surname\")).distinct()\n",
    "    ######################Ended State Columns#######################################\n",
    "\n",
    "    df_ended_dq = (silver_m3.withColumn(\"CaseStatus\", F.col(\"CaseStatus\").cast(\"int\")).withColumn(\"Outcome\", F.col(\"Outcome\").cast(\"int\"))\n",
    "        .withColumn(\"StatusId\", F.col(\"StatusId\").cast(\"long\")))\n",
    "\n",
    "    # 2) Build \"exists in the same case\" flag for sa.CaseStatus IN (10,51,52)\n",
    "    has_10_51_52 = (df_ended_dq.groupBy(\"CaseNo\").agg(F.max(F.when(F.col(\"CaseStatus\").isin(10, 51, 52), F.lit(1)).otherwise(F.lit(0))).alias(\"has_10_51_52_in_case\")))\n",
    "    df_with_flag = df_ended_dq.join(has_10_51_52, on=\"CaseNo\", how=\"left\")\n",
    "\n",
    "    # 3) Apply the full filter equivalent to your SQL WHERE\n",
    "    cond = (((F.col(\"CaseStatus\") == 10) & F.col(\"Outcome\").isin(80, 122, 25, 120, 2, 105, 13)) |\n",
    "        ((F.col(\"CaseStatus\") == 46) & (F.col(\"Outcome\") == 31) & (F.col(\"has_10_51_52_in_case\") == 1)) |\n",
    "        ( (F.col(\"CaseStatus\") == 26) & F.col(\"Outcome\").isin(80, 13, 25)) |\n",
    "        (F.col(\"CaseStatus\").isin(37, 38) & F.col(\"Outcome\").isin(80, 13, 25, 72, 125)) |\n",
    "        ((F.col(\"CaseStatus\") == 39) & (F.col(\"Outcome\") == 25)) |\n",
    "        ((F.col(\"CaseStatus\") == 51) & F.col(\"Outcome\").isin(0, 94, 93)) |\n",
    "        ((F.col(\"CaseStatus\") == 52) & F.col(\"Outcome\").isin(91, 95)) |\n",
    "        ((F.col(\"CaseStatus\") == 36) & F.col(\"Outcome\").isin(1, 2, 25))\n",
    "    )\n",
    "\n",
    "    filtered = df_with_flag.filter(cond)\n",
    "\n",
    "    # 4) For each CaseNo, take the row with the MAX(StatusId) among the filtered rows\n",
    "    w = Window.partitionBy(\"CaseNo\").orderBy(F.col(\"StatusId\").desc())\n",
    "    m3_net_df = (filtered.withColumn(\"rn\", F.row_number().over(w)).filter(F.col(\"rn\") == 1).drop(\"rn\", \"has_10_51_52_in_case\"))\n",
    "\n",
    "    # 5) Build decision_ts robustly and format end date\n",
    "    silver_with_decision_ts = m3_net_df.alias(\"m3\").join(bronze_ended_states.alias(\"es\"), on=[\"CaseStatus\", \"Outcome\"], how=\"left\")\\\n",
    "            .withColumn(\"decision_ts\",F.date_format(F.coalesce(F.to_timestamp(F.col(\"DecisionDate\")), \n",
    "            F.to_timestamp(F.col(\"DecisionDate\"), \"yyyy-MM-dd'T'HH:mm:ss.SSSXXX\"),\n",
    "            F.to_timestamp(F.col(\"DecisionDate\"), \"yyyy-MM-dd'T'HH:mm:ss.SSSX\")), \"dd/MM/yyyy\")\n",
    "    ).select(col(\"CaseNo\"),col(\"decision_ts\"),col(\"m3.CaseStatus\").alias(\"CaseStatus_end\"),col(\"m3.Outcome\").alias(\"Outcome_end\"),col(\"StatusId\").alias(\"StatusId_end\"),col(\"es.endAppealOutcome\").alias(\"endAppealOutcome_end\"),col(\"es.endAppealOutcomeReason\").alias(\"endAppealOutcomeReason_end\"),col(\"es.stateBeforeEndAppeal\").alias(\"stateBeforeEndAppeal_end\"),col(\"Adj_Determination_Title\").alias(\"Adj_Determination_Title_end\"),col(\"Adj_Determination_Forenames\").alias(\"Adj_Determination_Forenames_end\"),col(\"Adj_Determination_Surname\").alias(\"Adj_Determination_Surname_end\"))\n",
    "            \n",
    "##############################################################################################################\n",
    "\n",
    "    df_final = df_final.join(valid_representation, on=\"CaseNo\", how=\"left\"\n",
    "                            ).join(valid_country_list, on=col(\"CaseRep_Address5\") == col(\"valid_countryGovUkOocAdminJ\"), how=\"left\"\n",
    "                            ).join(valid_catagoryid_list, on=\"CaseNo\", how=\"left\"\n",
    "                            ).join(valid_appealant_address, on=\"CaseNo\", how=\"left\"\n",
    "                            ).join(valid_HORef_cleansing, on=\"CaseNo\", how=\"left\"\n",
    "                            ).join(valid_reasonDescription, on=\"CaseNo\", how=\"left\"\n",
    "                            ).join(valid_statusId, on=\"CaseNo\", how=\"left\"\n",
    "                            ).join(valid_hearing_requirements, on=\"CaseNo\", how=\"left\"\n",
    "                            ).join(valid_languages, on=\"CaseNo\", how=\"left\"\n",
    "                            ).join(valid_preparforhearing, on=\"CaseNo\", how=\"left\"\n",
    "                            ).join(silver_m3_outcome_ranked, on=\"CaseNo\", how=\"left\"\n",
    "                            ).join(silver_m3_ftpa_ranked, on=\"CaseNo\", how=\"left\"\n",
    "                            ).join(silver_with_decision_ts, on=\"CaseNo\", how=\"left\")\n",
    "                            \n",
    "    df_final = df_final.withColumn(\"is_valid\", expr(dq_rules))\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3362b255-72e6-4a4f-8b12-170c233128ad",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Transformation: stg_valid_ended_records"
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=f\"stg_valid_{output_name}_records\",\n",
    "    comment=\"Delta Live Gold Table with JSON content.\",\n",
    "    path=f\"{audit_path}/stg_valid_{output_name}_records\"\n",
    ")\n",
    "def stg_valid_ended_records():\n",
    "    \"\"\"\n",
    "    Delta Live Table for creating and uploading JSON content for Appeals.\n",
    "    \"\"\"\n",
    "    # Load source data\n",
    "    df = dlt.read(f\"stg_main_{output_name}_validation\")\n",
    "\n",
    "    df_filtered = df.filter(\n",
    "        (col(\"is_valid\") == True)\n",
    "    )\n",
    "\n",
    "    # Repartition to optimize parallelism\n",
    "    repartitioned_df = df_filtered.repartition(64)\n",
    "\n",
    "    df_with_upload_status = repartitioned_df.filter(~col(\"JSON_content\").like(\"Error%\")).withColumn(\n",
    "        \"Status\", upload_udf(col(\"JSON_File_Name\"), col(\"JSON_content\"))\n",
    "    )\n",
    "\n",
    "    # Return the DataFrame for DLT table creation\n",
    "    return df_with_upload_status.select(\"CaseNo\", \"JSON_content\",col(\"JSON_File_Name\").alias(\"File_Name\"),\"Status\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60bfdf72-3653-4133-ae58-42f66d648a28",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Transformation: stg_invalid_ended_quarantine_records"
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=f\"stg_invalid_{output_name}_quarantine_records\",\n",
    "    comment=\"Quarantined records that failed data quality checks or JSON generation.\",\n",
    "    path=f\"{audit_path}/stg_invalid_{output_name}_quarantine_records\"\n",
    ")\n",
    "def stg_invalid_ended_quarantine_records():\n",
    "\n",
    "    df = dlt.read(f\"stg_main_{output_name}_validation\")\n",
    "\n",
    "    df_filtered = df.filter(\n",
    "        (col(\"is_valid\") != True)\n",
    "    ).withColumn(\"JSON_File_Name\", regexp_replace(col(\"JSON_File_Name\"), \"/JSON/\", \"/INVALID_JSON/\"))\n",
    "\n",
    "    # Repartition to optimize parallelism\n",
    "    repartitioned_df = df_filtered.repartition(64)\n",
    "\n",
    "    df_with_upload_status = repartitioned_df.filter(~col(\"JSON_content\").like(\"Error%\")).withColumn(\n",
    "        \"Status\", upload_udf(col(\"JSON_File_Name\"), col(\"JSON_content\"))\n",
    "    )\n",
    "\n",
    "    return df_with_upload_status.select(\"CaseNo\", \"JSON_content\", col(\"JSON_File_Name\").alias(\"File_Name\"), \"Status\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a81bf947-c500-4014-b228-71862de0a3fc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Transformation: apl_active_ended_cr_audit_table"
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, lit, expr\n",
    "\n",
    "@dlt.table(\n",
    "    name=f\"apl_active_{output_name}_cr_audit_table\",\n",
    "    comment=\"DLT table Covers 4.2 Silver layer LLD requirements: Audits CCD attributes, input field values, derived values, and all columns for validation and traceability.\",\n",
    "    path=f\"{audit_path}/apl_active_{output_name}_cr_audit_table\"\n",
    ")\n",
    "def apl_active_ended_cr_audit_table():\n",
    "    try:\n",
    "        silver_m1 = dlt.read(\"silver_appealcase_detail\").filter(col(\"dv_targetState\") == lit(AppealState)).distinct()\n",
    "        silver_m2 = dlt.read(\"silver_caseapplicant_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        bronze_appealtype_lookup_df = dlt.read(\"bronze_appealtype\").distinct()\n",
    "        bronze_hearing_centres_lookup_df = dlt.read(\"bronze_hearing_centres\").distinct()\n",
    "        silver_m3 = dlt.read(\"silver_status_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_m6 = dlt.read(\"silver_adjudicator_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_c = dlt.read(\"ariadm_active_appeals.silver_appealcategory_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_h = dlt.read(\"silver_history_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        bronze_remission_lookup_df = dlt.read(\"bronze_remissions\").distinct()\n",
    "        bronze_remissions_lookup_df = dlt.read(\"bronze_remissions\").distinct()\n",
    "        bronze_countryFromAddress = dlt.read(\"bronze_countries_countryFromAddress\")\n",
    "        bronze_HORef_cleansing = dlt.read(\"bronze_HORef_cleansing\")\n",
    "        bronze_hearing_centres = dlt.read(\"bronze_hearing_centres\")\n",
    "        bronze_derive_hearing_centres = dlt.read(\"bronze_derive_hearing_centres\")\n",
    "        bronze_interpreter_languages = dlt.read(\"bronze_interpreter_languages\")\n",
    "        bronze_listing_location = spark.table(\"bronze_listing_location\")\n",
    "        bronze_ended_states = spark.table(\"bronze_ended_states\")\n",
    "        silver_segmentation = dlt.read(\"stg_segmentation_states\").filter(col(\"TargetState\") == lit(AppealState))\n",
    "        \n",
    "      \n",
    "    except:\n",
    "        silver_m1 = spark.table(\"hive_metastore.ariadm_active_appeals.silver_appealcase_detail\").filter(col(\"dv_targetState\") == lit(AppealState)).distinct()\n",
    "        silver_m2 = spark.table(\"hive_metastore.ariadm_active_appeals.silver_caseapplicant_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        bronze_appealtype_lookup_df = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_appealtype\").distinct()\n",
    "        bronze_hearing_centres_lookup_df = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_hearing_centres\").distinct()\n",
    "        silver_m3 = spark.table(\"hive_metastore.ariadm_active_appeals.silver_status_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_m6 = spark.table(\"hive_metastore.ariadm_active_appeals.silver_adjudicator_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_c = spark.table(\"hive_metastore.ariadm_active_appeals.silver_appealcategory_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        silver_h = spark.table(\"hive_metastore.ariadm_active_appeals.silver_history_detail\").filter(col(\"dv_targetState\") == lit(AppealState))\n",
    "        bronze_remissions_lookup_df = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_remissions\").distinct()\n",
    "        bronze_countryFromAddress = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_countries_countryFromAddress\")\n",
    "        bronze_HORef_cleansing = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_HORef_cleansing\")\n",
    "        bronze_hearing_centres = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_hearing_centres\")\n",
    "        bronze_derive_hearing_centres = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_derive_hearing_centres\")\n",
    "        bronze_interpreter_languages = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_interpreter_languages\")\n",
    "        bronze_listing_location = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_listing_location\")\n",
    "        bronze_ended_states = spark.table(\"hive_metastore.ariadm_active_appeals.bronze_ended_states\")\n",
    "        silver_segmentation = spark.table(\"hive_metastore.ariadm_active_appeals.stg_segmentation_states\").filter(col(\"TargetState\") == lit(AppealState))\n",
    "\n",
    " \n",
    "    df_final, df_audit = mainEnded(silver_segmentation, silver_m1, silver_m2, silver_m3, silver_m6, silver_c,silver_h, bronze_remissions_lookup_df, bronze_countryFromAddress, bronze_HORef_cleansing, bronze_hearing_centres, bronze_derive_hearing_centres, bronze_interpreter_languages,bronze_listing_location,bronze_ended_states)\n",
    "\n",
    "    return df_audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c065211-f4d5-47d6-9f7f-757fedeaa149",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Exit Notebook"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.exit(\"Notebook completed successfully\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7105280440885876,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "GOLD_ENDED_JSON",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
