{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bee8e7c7-c465-404a-bbc6-9ecb9133168b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "from pyspark.sql.functions import col, decode, split, element_at,udf,input_file_name,regexp_extract,expr\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType, LongType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09e63586-8682-4ebd-a5d7-19f71dd7979b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# time.sleep(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab9e033c-22d9-4fbe-8150-04b21eb7a3ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "expected_schema = StructType([\n",
    "    StructField(\"operation\", StringType(), True),\n",
    "    StructField(\"transaction_id\", StringType(), True),\n",
    "    StructField(\"relation_id\", StringType(), True),\n",
    "    StructField(\"a360_record_id\", StringType(), True),\n",
    "    StructField(\"process_time\", TimestampType(), True),\n",
    "    StructField(\"status\", IntegerType(), True),\n",
    "    StructField(\"input\", StringType(), True),  # Contains nested JSON as a string\n",
    "    StructField(\"exception_description\", StringType(), True),\n",
    "    StructField(\"error_status\", StringType(), True),\n",
    "    StructField(\"a360_file_id\", StringType(), True),\n",
    "    StructField(\"file_size\", LongType(), True),\n",
    "    StructField(\"s_md5\", StringType(), True),\n",
    "    StructField(\"s_sha256\", StringType(), True),\n",
    "    StructField(\"timestamp\", TimestampType(), True),  # may be used as process_time\n",
    "    StructField(\"filename\", StringType(), True),\n",
    "    StructField(\"submission_folder\", StringType(), True),\n",
    "    StructField(\"file_hash\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = spark.read.option(\"multiline\", \"true\").json(\"dbfs:/configs/config.json\")\n",
    "env_name = config.first()[\"env\"].strip().lower()\n",
    "lz_key = config.first()[\"lz_key\"].strip().lower()\n",
    "\n",
    "print(f\"env_code: {lz_key}\")  # This won't be redacted\n",
    "print(f\"env_name: {env_name}\")  # This won't be redacted\n",
    "\n",
    "KeyVault_name = f\"ingest{lz_key}-meta002-{env_name}\"\n",
    "print(f\"KeyVault_name: {KeyVault_name}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "979f2492-9fd3-426c-ae5c-2e9360efa26e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#### Set up Auto Loader job\n",
    "\n",
    "sas_token = dbutils.secrets.get(scope=KeyVault_name, key=\"ARIAFTA-SAS-TOKEN\")\n",
    "storage_account_name = \"a360c2x2555dz\"\n",
    "container_name = \"dropzone\"\n",
    "sub_dir = \"ARIAFTA/response\"\n",
    "\n",
    "input_path = f\"wasbs://{container_name}@{storage_account_name}.blob.core.windows.net/{sub_dir}\"\n",
    "\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.sas.{container_name}.{storage_account_name}.blob.core.windows.net\",\n",
    "    sas_token\n",
    ")\n",
    "\n",
    "# schema_location = \"/mnt/autoLoaderSchema/ARMJOH/response/read_stream\"\n",
    "\n",
    "# Define a file regex that matches files ending with .rsp\n",
    "file_regex = \".*\\\\.rsp$\"\n",
    "\n",
    "output_container_name = \"silver\" \n",
    "\n",
    "output_storage_account_name = f\"ingest{lz_key}curated{env_name}\"\n",
    "\n",
    "output_subdir_amalgamated_responses = \"ARIADM/ARM/response/APPEALS/ARIAFTA/amalgamated_responses\"\n",
    "amalgamated_responses_path = f\"wasbs://{output_container_name}@{output_storage_account_name}.blob.core.windows.net/{output_subdir_amalgamated_responses}\"\n",
    "\n",
    "\n",
    "\n",
    "output_subdir_input_upload = \"ARIADM/ARM/response/APPEALS/ARIAFTA/input_upload\"\n",
    "input_upload_responses_path = f\"wasbs://{output_container_name}@{output_storage_account_name}.blob.core.windows.net/{output_subdir_input_upload}\"\n",
    "\n",
    "\n",
    "output_subdir_create_record_upload = \"ARIADM/ARM/response/APPEALS/ARIAFTA/create_record\"\n",
    "create_record_responses_path = f\"wasbs://{output_container_name}@{output_storage_account_name}.blob.core.windows.net/{output_subdir_create_record_upload}\"\n",
    "\n",
    "\n",
    "output_subdir_upload_file_upload = \"ARIADM/ARM/response/APPEALS/ARIAFTA/upload_file\"\n",
    "upload_file_responses_path = f\"wasbs://{output_container_name}@{output_storage_account_name}.blob.core.windows.net/{output_subdir_upload_file_upload}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c610d091-7f9d-4046-af3c-78995dfd6d91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Service principal credentials\n",
    "client_id = dbutils.secrets.get(KeyVault_name, \"SERVICE-PRINCIPLE-CLIENT-ID\")\n",
    "client_secret = dbutils.secrets.get(KeyVault_name, \"SERVICE-PRINCIPLE-CLIENT-SECRET\")\n",
    "tenant_id = dbutils.secrets.get(KeyVault_name, \"SERVICE-PRINCIPLE-TENANT-ID\")\n",
    "\n",
    "# Storage account names\n",
    "\n",
    "checkpoint_storage = f\"ingest{lz_key}xcutting{env_name}\"\n",
    "\n",
    "\n",
    "# Spark config for checkpoint storage\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{checkpoint_storage}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{checkpoint_storage}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{checkpoint_storage}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{checkpoint_storage}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{checkpoint_storage}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n",
    "\n",
    "check_point_path = f\"abfss://db-rsp-checkpoint@ingest{lz_key}xcutting{env_name}.dfs.core.windows.net/APPEALS/ARIAFTA/RSP/\"\n",
    "\n",
    "schema_location = f\"abfss://db-rsp-checkpoint@inges{lz_key}0xcutting{env_name}.dfs.core.windows.net/APPEALS/ARIAFTA/RSP/schema\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae56f4aa-f4ac-4afa-8ee8-07cc38f64767",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Run autoloader read stream\n",
    "\n",
    "\n",
    "df = (spark.readStream.format(\"cloudFiles\")\n",
    "      .schema(expected_schema)\n",
    "    .option(\"cloudFiles.format\", \"json\")\n",
    "    .option(\"cloudFiles.schemaLocation\", schema_location)\n",
    "    .option(\"multiline\", \"true\")\n",
    "    .option(\"cloudFiles.schemaEvolutionMode\", \"none\")\n",
    "    .option(\"checkpointLocation\", f\"{check_point_path}/rsp_readStream\")\n",
    "    .load(input_path)\n",
    "    .select( \"*\",col(\"_metadata.file_path\").alias(\"_file_path\"),\n",
    "             col(\"_metadata.file_modification_time\").alias(\"_file_modification_time\")\n",
    ")\n",
    "    # .withColumn(\"file_name\", regexp_extract(input_file_name(),\"response\\/(.*)\",1))\n",
    "    .withColumn(\"id\", expr(\"uuid()\")))\n",
    "    \n",
    "# df = df.cache()\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c891b751-4bb9-442a-b1f7-88917480fad0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_cr = df.filter(col(\"operation\")==\"create_record\")\n",
    "df_iu = df.filter(col(\"operation\")==\"input_upload\")\n",
    "df_uf = df.filter(col(\"operation\")==\"upload_new_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6e9063e-f957-4adc-8c4a-5bac501a1f2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### 4 write streams to Silver container in blob storage\n",
    "\n",
    "output_sas = dbutils.secrets.get(scope=KeyVault_name, key=\"CURATED-SAS-TOKEN\")\n",
    "\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.sas.{output_container_name}.{output_storage_account_name}.blob.core.windows.net\",\n",
    "    output_sas\n",
    ")\n",
    "\n",
    "### first save the complete table\n",
    "\n",
    "df_complete = df.writeStream \\\n",
    "    .format(\"delta\")\\\n",
    "        .option(\"checkpointLocation\", f\"{check_point_path}/amalgamated\")\\\n",
    "            .outputMode(\"append\")\\\n",
    "                    .start(amalgamated_responses_path)\n",
    "\n",
    "time.sleep(60)\n",
    "\n",
    "df_complete.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3191c67c-3f1e-4239-86af-f7b144ee5964",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Input upload table\n",
    "\n",
    "df_input_upload = df_iu.select(\"id\",\"operation\",\"timestamp\",\"status\",\"exception_description\",\"error_status\",\"filename\",\"submission_folder\",\"file_hash\",\"_file_path\",\"_file_modification_time\"\n",
    ")\\\n",
    "    .writeStream \\\n",
    "    .format(\"delta\")\\\n",
    "        .option(\"checkpointLocation\", f\"{check_point_path}/input_upload\")\\\n",
    "            .outputMode(\"append\")\\\n",
    "                .start(input_upload_responses_path)\n",
    "time.sleep(60)\n",
    "df_input_upload.stop()     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a3667f2-4712-4983-9e5e-3f46ec36575e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ### Create Record table\n",
    "# df_create_upload = df.select(\"id\",\"operation\",\"transaction_id\",\"relation_id\",\"a360_record_id\",\"process_time\",\"status\",\"input\",\"exception_description\",\"error_status\",\"_file_path\",\"_file_modification_time\"\n",
    "# ).filter(col(\"operation\")==\"create_record\")\\\n",
    "#     .writeStream \\\n",
    "#     .format(\"delta\")\\\n",
    "#         .option(\"checkpointLocation\", f\"{check_point_path}/create_record\")\\\n",
    "#             .outputMode(\"append\")\\\n",
    "#                 .start(create_record_responses_path)\n",
    "\n",
    "### Create Record table\n",
    "df_create_upload = df_cr.select(\"id\",\"operation\",\"transaction_id\",\"relation_id\",\"a360_record_id\",\"process_time\",\"status\",\"input\",\"exception_description\",\"error_status\",\"_file_path\",\"_file_modification_time\"\n",
    ").writeStream \\\n",
    "    .format(\"delta\")\\\n",
    "        .option(\"checkpointLocation\", f\"{check_point_path}/create_record\")\\\n",
    "            .outputMode(\"append\")\\\n",
    "                .start(create_record_responses_path)\n",
    "\n",
    "time.sleep(60)\n",
    "df_create_upload.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0fe45de-b025-41e4-9234-b876390a7889",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### upload file table\n",
    "df_create_upload = df_uf.select(\"id\",\"operation\",\"transaction_id\",\"relation_id\",\"a360_record_id\",\"process_time\",\"status\",\"input\",\"exception_description\",\"error_status\",\"a360_file_id\",\"file_size\",\"s_md5\",\"s_sha256\",\"_file_path\",\"_file_modification_time\"\n",
    ")\\\n",
    "    .writeStream \\\n",
    "    .format(\"delta\")\\\n",
    "        .option(\"checkpointLocation\", f\"{check_point_path}/upload_file\")\\\n",
    "            .outputMode(\"append\")\\\n",
    "                .start(upload_file_responses_path)\n",
    "\n",
    "time.sleep(60)\n",
    "df_create_upload.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d867d8e-6108-413c-ba23-c693480cbe8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_amalgamated_test = spark.read.format(\"delta\").load(amalgamated_responses_path)\n",
    "\n",
    "df_amalgamated_test.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d46ff3dd-e4fc-4f7e-b07b-a51b5dd5d54d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.exit(\"Notebook completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a41af734-f9af-450e-9ef2-fe31e90f14b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96499971-f5f8-4e61-b9bb-e29805c93ecb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "submission"
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.fs.ls(\"/mnt/dropzoneariafta/ARIAFTA/submission/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8b611dc-e6a0-4bf4-add8-5a769dcf3fd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import col, from_unixtime\n",
    "\n",
    "# files_df = spark.createDataFrame(dbutils.fs.ls(\"/mnt/dropzoneariafta/ARIAFTA/submission/\"))\n",
    "# files_df = files_df.withColumn(\"modificationTime\", from_unixtime(col(\"modificationTime\") / 1000).cast(\"timestamp\"))\n",
    "\n",
    "# display(files_df.orderBy(col(\"modificationTime\").desc()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9df8c969-0792-408b-aebc-75e86bb5fdaf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Successfull Responses"
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import col, from_unixtime\n",
    "\n",
    "# files_df = spark.createDataFrame(dbutils.fs.ls(\"/mnt/dropzoneariafta/ARIAFTA/response/\"))\n",
    "# files_df = files_df.withColumn(\"modificationTime\", from_unixtime(col(\"modificationTime\") / 1000).cast(\"timestamp\"))\n",
    "\n",
    "# display(files_df.orderBy(col(\"modificationTime\").desc()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b2cd89a-55b4-46d7-baa6-f38ac4d0a823",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Failed Responses"
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import col, from_unixtime\n",
    "\n",
    "# files_df = spark.createDataFrame(dbutils.fs.ls(\"/mnt/dropzoneariafta/ARIAFTA/response/\"))\n",
    "# files_df = files_df.withColumn(\"modificationTime\", from_unixtime(col(\"modificationTime\") / 1000).cast(\"timestamp\"))\n",
    "# files_df = files_df.filter(col(\"path\").contains(\"_0_\"))\n",
    "\n",
    "# display(files_df.orderBy(col(\"modificationTime\").desc()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3772538-0ad6-4381-91a2-130d1012d7f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Define the paths to the tables\n",
    "# # audit_delta_path = \"/mnt/ingest00curatedsboxsilver/ARIADM/ARM/AUDIT/APPEALS/ARIAFTA/apl_fta_cr_audit_table\"\n",
    "# # ack_path = \"/mnt/ingest00curatedsboxsilver/ARIADM/ARM/AUDIT/APPEALS/ARIAFTA/fta_ack_audit\"\n",
    "# output_subdir_input_upload = \"/mnt/ingest00curatedsboxsilver/ARIADM/ARM/response/APPEALS/ARIAFTA/input_upload\"\n",
    "# output_subdir_create_record_upload = \"/mnt/ingest00curatedsboxsilver/ARIADM/ARM/response/APPEALS/ARIAFTA/create_record\"\n",
    "# output_subdir_upload_file_upload = \"/mnt/ingest00curatedsboxsilver/ARIADM/ARM/response/APPEALS/ARIAFTA/upload_file\"\n",
    "# # output_subdir_amalgamated_responses = \"/mnt/ingest00curatedsboxsilver/ARIADM/ARM/response/APPEALS/ARIAFTA/amalgamated_responses\"\n",
    "\n",
    "# # https://ingest00curatedsbox.blob.core.windows.net/silver/ARIADM/ARM/response/APPEALS/ARIAFTA/create_record/part-00000-27c33bc4-48d2-48fd-9949-e5a0a50c148f-c000.snappy.parquet\n",
    "\n",
    "# # Read the Delta table for joh_cr_audit_table\n",
    "# # df_audit = spark.read.format(\"delta\").load(audit_delta_path)\n",
    "\n",
    "# # # Read the Delta table for joh_ack_audit\n",
    "# # df_ack = spark.read.format(\"delta\").load(ack_path)\n",
    "\n",
    "# # Read the response data for input_upload\n",
    "# df_input_upload = spark.read.format(\"delta\").load(output_subdir_input_upload)\n",
    "\n",
    "# # Read the response data for create_record_upload\n",
    "# df_create_record_upload = spark.read.format(\"delta\").load(output_subdir_create_record_upload)\n",
    "\n",
    "# # Read the response data for upload_file\n",
    "# df_upload_file_upload = spark.read.format(\"delta\").load(output_subdir_upload_file_upload)\n",
    "\n",
    "\n",
    "# # Read the response data for df_amalgamated_responses\n",
    "# # df_amalgamated_responses = spark.read.format(\"delta\").load(output_subdir_amalgamated_responses)\n",
    "\n",
    "# # Display the DataFrames using Databricks display\n",
    "# # display(df_audit)\n",
    "# # display(df_ack)\n",
    "# display(df_input_upload)\n",
    "# display(df_create_record_upload)\n",
    "# display(df_upload_file_upload)\n",
    "# # display(df_amalgamated_responses)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ARIADM_RESPONSE_AUTOLOADER_FTA",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
