parameters:
  pythonVersion: ''
  env: ''
  mainRepositoryName: ''
  databricksInstance: '' # E.g: https://<databricks-instance>.cloud.databricks.com
  databricksClusterId: '' # Target Cluster ID
  wheelName: 'ARIAFUNCITONS-0.0.1-py3-none-any.whl' # (e.g., ARIA_FUNCTIONS-0.1.0-py3-none-any.whl)


steps:
- task: DownloadPipelineArtifact@2
  displayName: 'Download wheel artifact'
  inputs:
    buildType: 'current'
    artifactName: 'python-wheel'
    targetPath: '$(Pipeline.Workspace)/python-wheel'

- task: AzureCLI@2
  displayName: 'Install Databricks CLI and Upload Wheel'
  condition: succeeded()
  env:
    DATABRICKS_TOKEN: $(AUTH-AccessToken-sbox)
  inputs:
    azureSubscription: 'DTS-DATAINGEST-${{ upper(parameters.env) }}'
    scriptType: bash
    scriptLocation: inlineScript
    inlineScript: |
      set -e
      source working_dir/bin/activate
      export PYTHONPATH="${PYTHONPATH}:/./"
      pip install databricks-cli

      # Set Databricks CLI environment variables
      export DATABRICKS_HOST=${{ parameters.databricksInstance }}
      export DATABRICKS_TOKEN=$(DATABRICKS_TOKEN)

      # Upload the wheel file to DBFS
      databricks fs cp ${{ parameters.wheelName }} dbfs:/FileStore/shared_wheels/${{ parameters.wheelName }} --overwrite

      # Install the wheel on the Databricks cluster
      databricks libraries install --cluster-id ${{ parameters.databricksClusterId }} --whl dbfs:/FileStore/shared_wheels/${{ parameters.wheelName }}
    workingDirectory: '$(System.DefaultWorkingDirectory)'

###
## Install Databricks CLI
###
#steps:
#- task: AzureCLI@2
#  displayName: 'Install Libraries on DB Cluster'
#  condition: succeeded()
#  inputs:
#    azureSubscription: 'DTS-DATAINGEST-${{ upper(parameters.env) }}'
#    scriptType: bash
#    scriptLocation: inlineScript
#    inlineScript: |
#      set -x
#      source working_dir/bin/activate
#      export PYTHONPATH="${PYTHONPATH}:/./"
#      pip install databricks-cli
#      databricks configure --token --host ${{ parameters.databricksInstance }}
#      databricks fs cp $(Pipeline.Workspace)/wheel-cache/${{ parameters.wheelName }} dbfs:/FileStore/shared_wheels/${{ parameters.wheelName }}
#      curl -X POST -H "Authorization: Bearer $(DATABRICKS_TOKEN)" \
#           -H "Content-Type: application/json" \
#           -d '{
#                 "cluster_id": "${{ parameters.databricksClusterId }}",
#                 "libraries": [
#                   {
#                     "whl": "dbfs:/FileStore/shared_wheels/${{ parameters.wheelName }}"
#                   }
#                 ]
#               }' \
#           ${{ parameters.databricksInstance }}/api/2.0/libraries/install
#    workingDirectory: '$(System.DefaultWorkingDirectory)'
#  env:
#    DATABRICKS_TOKEN: $(AUTH-AccessToken-sbox)