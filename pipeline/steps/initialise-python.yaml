parameters:
  pythonVersion: ''
  env: ''
  mainRepositoryName: ''
##
# Install python and initialise the .env file
##
steps:
- checkout: self
- task: AzureCLI@2
  displayName: 'Install python ${{ parameters.pythonVersion }}'
  inputs:
    azureSubscription: 'DTS-DATAINGEST-${{ upper(parameters.env) }}'
    scriptType: bash
    scriptLocation: inlineScript
    inlineScript: |
      set -x
      apt-get update
      ACCEPT_EULA=Y apt-get -y install python${{ parameters.pythonVersion }} python3-dev python3-pip
      python${{ parameters.pythonVersion }} --version
      python${{ parameters.pythonVersion }} -m venv working_dir
      source working_dir/bin/activate
      export PYTHONPATH="${PYTHONPATH}:/./"
      python${{ parameters.pythonVersion }} -m pip install -U pip
      echo "Current directory: $(System.DefaultWorkingDirectory)"
      echo "Listing root directory..."
      ls /home/vsts/work/1/s
      echo "Listing contents of ARIAMigration-Databrick..."
      ls /home/vsts/work/1/s/ARIAMigration-Databrick
      echo "Listing contents of pipeline/scripts..."
      ls /home/vsts/work/1/s/ARIAMigration-Databrick/pipeline/scripts/
      echo "Current branch:"
      git branch
      git log --oneline
#      python${{ parameters.pythonVersion }} $(System.DefaultWorkingDirectory)/${{ parameters.mainRepositoryName }}/pipeline/scripts/pipeline_test.py
#      python${{ parameters.pythonVersion }} -m pip install -r $(System.DefaultWorkingDirectory)/${{ parameters.mainRepositoryName }}/requirements.txt
#      python $(System.DefaultWorkingDirectory)/${{ parameters.mainRepositoryName }}/pipeline/scripts/populate_env_file.py --env ${{ parameters.env }}
    workingDirectory: '${{ parameters.mainRepositoryName }}/'